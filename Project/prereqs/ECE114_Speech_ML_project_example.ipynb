{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LoBdJNiyaMoC"
   },
   "source": [
    "Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "t6cfKHA7p3WP",
    "outputId": "90dcb3d6-6b1c-4834-85eb-5b9d08b5b61b"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9a9a89271754>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/gdrive/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vr1CQxtvaQTa"
   },
   "source": [
    "Change Directory to Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "NX_Gzz72p-bH",
    "outputId": "0da83b7a-5701-41a3-aa46-0c542200835b"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/content/gdrive/My Drive/ECE114F19_SpeechMLproj'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b7a43c5553e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#print(os.getcwd())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/gdrive/My Drive/ECE114F19_SpeechMLproj'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ls'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/content/gdrive/My Drive/ECE114F19_SpeechMLproj'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#print(os.getcwd())\n",
    "os.chdir('/content/gdrive/My Drive/ECE114F19_SpeechMLproj')\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gT9QjbtWaWa-"
   },
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "OD-odBBaw613",
    "outputId": "9d449e36-ab02-4c19-954d-d368849116a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (144, 12)\n",
      "Test data shape: (26, 12)\n",
      "Training/Valid target shape: (144, 1)\n",
      "Test target shape: (26, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X=sio.loadmat('feat_vec.mat')\n",
    "y=sio.loadmat('labels')\n",
    "\n",
    "X_data=X['feat_vec']\n",
    "y_data=y['labels']\n",
    "\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test= train_test_split(X_data, y_data, test_size=0.15)\n",
    "\n",
    "X_train, X_val, y_train, y_val= train_test_split(X_train_val, y_train_val, test_size=0.15)\n",
    "\n",
    "\n",
    "\n",
    "print ('Training/Valid data shape: {}'.format(X_train_val.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_val.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7UGP5EPvaYYJ"
   },
   "source": [
    "One-hot encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vQ6w6PHUzh_o",
    "outputId": "31198211-c366-4ab9-ab7e-d61cd0ad7b91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "\n",
    "\n",
    "y_train = onehot_encoder.fit_transform(y_train)\n",
    "y_val = onehot_encoder.fit_transform(y_val)\n",
    "y_test = onehot_encoder.fit_transform(y_test)\n",
    "\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qRV3K8M5acwm"
   },
   "source": [
    "Run Fully Connected (FeedForward) Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pKIRxQRg1PMn",
    "outputId": "836d17ad-22a3-444d-ae5c-ee1f0be230ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 122 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.7928 - accuracy: 0.4754 - val_loss: 0.6884 - val_accuracy: 0.5909\n",
      "Epoch 2/100\n",
      "122/122 [==============================] - 0s 73us/step - loss: 0.7790 - accuracy: 0.4754 - val_loss: 0.6830 - val_accuracy: 0.5909\n",
      "Epoch 3/100\n",
      "122/122 [==============================] - 0s 73us/step - loss: 0.7370 - accuracy: 0.4754 - val_loss: 0.6792 - val_accuracy: 0.5909\n",
      "Epoch 4/100\n",
      "122/122 [==============================] - 0s 73us/step - loss: 0.7676 - accuracy: 0.4590 - val_loss: 0.6773 - val_accuracy: 0.5909\n",
      "Epoch 5/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.7529 - accuracy: 0.4754 - val_loss: 0.6767 - val_accuracy: 0.5909\n",
      "Epoch 6/100\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.7176 - accuracy: 0.4672 - val_loss: 0.6772 - val_accuracy: 0.5909\n",
      "Epoch 7/100\n",
      "122/122 [==============================] - 0s 73us/step - loss: 0.7322 - accuracy: 0.4672 - val_loss: 0.6784 - val_accuracy: 0.5909\n",
      "Epoch 8/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7198 - accuracy: 0.4918 - val_loss: 0.6802 - val_accuracy: 0.5909\n",
      "Epoch 9/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.7207 - accuracy: 0.4590 - val_loss: 0.6826 - val_accuracy: 0.5909\n",
      "Epoch 10/100\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.7147 - accuracy: 0.4344 - val_loss: 0.6855 - val_accuracy: 0.5909\n",
      "Epoch 11/100\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.7056 - accuracy: 0.5082 - val_loss: 0.6883 - val_accuracy: 0.5909\n",
      "Epoch 12/100\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.7164 - accuracy: 0.4016 - val_loss: 0.6911 - val_accuracy: 0.5909\n",
      "Epoch 13/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7034 - accuracy: 0.4836 - val_loss: 0.6940 - val_accuracy: 0.4091\n",
      "Epoch 14/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.7020 - accuracy: 0.4344 - val_loss: 0.6968 - val_accuracy: 0.4091\n",
      "Epoch 15/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6936 - accuracy: 0.5656 - val_loss: 0.6990 - val_accuracy: 0.4091\n",
      "Epoch 16/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6939 - accuracy: 0.5492 - val_loss: 0.7006 - val_accuracy: 0.4091\n",
      "Epoch 17/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.7035 - accuracy: 0.5082 - val_loss: 0.7019 - val_accuracy: 0.4091\n",
      "Epoch 18/100\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6995 - accuracy: 0.5000 - val_loss: 0.7029 - val_accuracy: 0.4091\n",
      "Epoch 19/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6993 - accuracy: 0.4836 - val_loss: 0.7038 - val_accuracy: 0.4091\n",
      "Epoch 20/100\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6860 - accuracy: 0.5738 - val_loss: 0.7048 - val_accuracy: 0.4091\n",
      "Epoch 21/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6837 - accuracy: 0.5738 - val_loss: 0.7057 - val_accuracy: 0.4091\n",
      "Epoch 22/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.7076 - accuracy: 0.4918 - val_loss: 0.7065 - val_accuracy: 0.4091\n",
      "Epoch 23/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.7044 - accuracy: 0.5164 - val_loss: 0.7073 - val_accuracy: 0.4091\n",
      "Epoch 24/100\n",
      "122/122 [==============================] - 0s 81us/step - loss: 0.6968 - accuracy: 0.5246 - val_loss: 0.7078 - val_accuracy: 0.4091\n",
      "Epoch 25/100\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.7037 - accuracy: 0.5000 - val_loss: 0.7082 - val_accuracy: 0.4091\n",
      "Epoch 26/100\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6940 - accuracy: 0.4918 - val_loss: 0.7085 - val_accuracy: 0.4091\n",
      "Epoch 27/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6928 - accuracy: 0.5082 - val_loss: 0.7085 - val_accuracy: 0.4091\n",
      "Epoch 28/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6946 - accuracy: 0.5328 - val_loss: 0.7086 - val_accuracy: 0.4091\n",
      "Epoch 29/100\n",
      "122/122 [==============================] - 0s 73us/step - loss: 0.7046 - accuracy: 0.4426 - val_loss: 0.7089 - val_accuracy: 0.4091\n",
      "Epoch 30/100\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6976 - accuracy: 0.5410 - val_loss: 0.7095 - val_accuracy: 0.4091\n",
      "Epoch 31/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.7112 - accuracy: 0.4836 - val_loss: 0.7103 - val_accuracy: 0.4091\n",
      "Epoch 32/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6929 - accuracy: 0.5164 - val_loss: 0.7106 - val_accuracy: 0.4091\n",
      "Epoch 33/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.7174 - accuracy: 0.4426 - val_loss: 0.7105 - val_accuracy: 0.4091\n",
      "Epoch 34/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6936 - accuracy: 0.5246 - val_loss: 0.7099 - val_accuracy: 0.4091\n",
      "Epoch 35/100\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6759 - accuracy: 0.6066 - val_loss: 0.7092 - val_accuracy: 0.4091\n",
      "Epoch 36/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6953 - accuracy: 0.5164 - val_loss: 0.7085 - val_accuracy: 0.4091\n",
      "Epoch 37/100\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.7043 - accuracy: 0.5082 - val_loss: 0.7077 - val_accuracy: 0.4091\n",
      "Epoch 38/100\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.7114 - accuracy: 0.4508 - val_loss: 0.7068 - val_accuracy: 0.4091\n",
      "Epoch 39/100\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6970 - accuracy: 0.5000 - val_loss: 0.7061 - val_accuracy: 0.4091\n",
      "Epoch 40/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6871 - accuracy: 0.5574 - val_loss: 0.7059 - val_accuracy: 0.4091\n",
      "Epoch 41/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6843 - accuracy: 0.5574 - val_loss: 0.7057 - val_accuracy: 0.4091\n",
      "Epoch 42/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.7116 - accuracy: 0.4672 - val_loss: 0.7056 - val_accuracy: 0.4091\n",
      "Epoch 43/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6979 - accuracy: 0.5246 - val_loss: 0.7055 - val_accuracy: 0.4091\n",
      "Epoch 44/100\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6967 - accuracy: 0.4918 - val_loss: 0.7053 - val_accuracy: 0.4091\n",
      "Epoch 45/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6970 - accuracy: 0.5410 - val_loss: 0.7050 - val_accuracy: 0.4091\n",
      "Epoch 46/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6857 - accuracy: 0.5738 - val_loss: 0.7050 - val_accuracy: 0.4091\n",
      "Epoch 47/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6929 - accuracy: 0.5328 - val_loss: 0.7051 - val_accuracy: 0.4091\n",
      "Epoch 48/100\n",
      "122/122 [==============================] - 0s 73us/step - loss: 0.6965 - accuracy: 0.4836 - val_loss: 0.7054 - val_accuracy: 0.4091\n",
      "Epoch 49/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.7089 - accuracy: 0.4344 - val_loss: 0.7061 - val_accuracy: 0.4091\n",
      "Epoch 50/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6936 - accuracy: 0.4672 - val_loss: 0.7072 - val_accuracy: 0.4091\n",
      "Epoch 51/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7092 - accuracy: 0.4918 - val_loss: 0.7081 - val_accuracy: 0.4091\n",
      "Epoch 52/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7016 - accuracy: 0.4590 - val_loss: 0.7088 - val_accuracy: 0.4091\n",
      "Epoch 53/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.7078 - accuracy: 0.4918 - val_loss: 0.7091 - val_accuracy: 0.4091\n",
      "Epoch 54/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.7038 - accuracy: 0.5328 - val_loss: 0.7092 - val_accuracy: 0.4091\n",
      "Epoch 55/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6936 - accuracy: 0.5164 - val_loss: 0.7088 - val_accuracy: 0.4091\n",
      "Epoch 56/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6802 - accuracy: 0.5738 - val_loss: 0.7084 - val_accuracy: 0.4091\n",
      "Epoch 57/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6914 - accuracy: 0.5000 - val_loss: 0.7078 - val_accuracy: 0.4091\n",
      "Epoch 58/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6931 - accuracy: 0.5410 - val_loss: 0.7069 - val_accuracy: 0.4091\n",
      "Epoch 59/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6941 - accuracy: 0.5410 - val_loss: 0.7061 - val_accuracy: 0.4091\n",
      "Epoch 60/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6947 - accuracy: 0.5164 - val_loss: 0.7059 - val_accuracy: 0.4091\n",
      "Epoch 61/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6891 - accuracy: 0.5328 - val_loss: 0.7055 - val_accuracy: 0.4091\n",
      "Epoch 62/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6990 - accuracy: 0.5328 - val_loss: 0.7049 - val_accuracy: 0.4091\n",
      "Epoch 63/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7004 - accuracy: 0.4672 - val_loss: 0.7042 - val_accuracy: 0.4091\n",
      "Epoch 64/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6875 - accuracy: 0.5492 - val_loss: 0.7038 - val_accuracy: 0.4091\n",
      "Epoch 65/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6994 - accuracy: 0.4836 - val_loss: 0.7033 - val_accuracy: 0.4091\n",
      "Epoch 66/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7090 - accuracy: 0.4180 - val_loss: 0.7031 - val_accuracy: 0.4091\n",
      "Epoch 67/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6930 - accuracy: 0.4918 - val_loss: 0.7036 - val_accuracy: 0.4091\n",
      "Epoch 68/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6958 - accuracy: 0.5082 - val_loss: 0.7046 - val_accuracy: 0.4091\n",
      "Epoch 69/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7022 - accuracy: 0.5082 - val_loss: 0.7057 - val_accuracy: 0.4091\n",
      "Epoch 70/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6935 - accuracy: 0.5246 - val_loss: 0.7067 - val_accuracy: 0.4091\n",
      "Epoch 71/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6969 - accuracy: 0.4836 - val_loss: 0.7074 - val_accuracy: 0.4091\n",
      "Epoch 72/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6889 - accuracy: 0.5410 - val_loss: 0.7081 - val_accuracy: 0.4091\n",
      "Epoch 73/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6945 - accuracy: 0.5574 - val_loss: 0.7091 - val_accuracy: 0.4091\n",
      "Epoch 74/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7032 - accuracy: 0.4836 - val_loss: 0.7097 - val_accuracy: 0.4091\n",
      "Epoch 75/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6958 - accuracy: 0.5164 - val_loss: 0.7101 - val_accuracy: 0.4091\n",
      "Epoch 76/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7061 - accuracy: 0.4918 - val_loss: 0.7106 - val_accuracy: 0.4091\n",
      "Epoch 77/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7065 - accuracy: 0.4918 - val_loss: 0.7104 - val_accuracy: 0.4091\n",
      "Epoch 78/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.7036 - accuracy: 0.4590 - val_loss: 0.7098 - val_accuracy: 0.4091\n",
      "Epoch 79/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6967 - accuracy: 0.5082 - val_loss: 0.7093 - val_accuracy: 0.4091\n",
      "Epoch 80/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6984 - accuracy: 0.5328 - val_loss: 0.7090 - val_accuracy: 0.4091\n",
      "Epoch 81/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6980 - accuracy: 0.5328 - val_loss: 0.7083 - val_accuracy: 0.4091\n",
      "Epoch 82/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.7021 - accuracy: 0.4836 - val_loss: 0.7071 - val_accuracy: 0.4091\n",
      "Epoch 83/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6941 - accuracy: 0.5082 - val_loss: 0.7058 - val_accuracy: 0.4091\n",
      "Epoch 84/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7000 - accuracy: 0.5000 - val_loss: 0.7049 - val_accuracy: 0.4091\n",
      "Epoch 85/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6940 - accuracy: 0.5000 - val_loss: 0.7044 - val_accuracy: 0.4091\n",
      "Epoch 86/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6933 - accuracy: 0.5164 - val_loss: 0.7039 - val_accuracy: 0.4091\n",
      "Epoch 87/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7023 - accuracy: 0.4590 - val_loss: 0.7036 - val_accuracy: 0.4091\n",
      "Epoch 88/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6877 - accuracy: 0.5000 - val_loss: 0.7036 - val_accuracy: 0.4091\n",
      "Epoch 89/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6977 - accuracy: 0.5082 - val_loss: 0.7035 - val_accuracy: 0.4091\n",
      "Epoch 90/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6874 - accuracy: 0.5328 - val_loss: 0.7038 - val_accuracy: 0.4091\n",
      "Epoch 91/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6982 - accuracy: 0.5246 - val_loss: 0.7043 - val_accuracy: 0.4091\n",
      "Epoch 92/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7005 - accuracy: 0.4262 - val_loss: 0.7050 - val_accuracy: 0.4091\n",
      "Epoch 93/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6867 - accuracy: 0.5656 - val_loss: 0.7061 - val_accuracy: 0.4091\n",
      "Epoch 94/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6948 - accuracy: 0.5000 - val_loss: 0.7069 - val_accuracy: 0.4091\n",
      "Epoch 95/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6958 - accuracy: 0.5164 - val_loss: 0.7073 - val_accuracy: 0.4091\n",
      "Epoch 96/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6863 - accuracy: 0.5738 - val_loss: 0.7072 - val_accuracy: 0.4091\n",
      "Epoch 97/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6951 - accuracy: 0.5082 - val_loss: 0.7068 - val_accuracy: 0.4091\n",
      "Epoch 98/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6951 - accuracy: 0.5246 - val_loss: 0.7066 - val_accuracy: 0.4091\n",
      "Epoch 99/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6950 - accuracy: 0.5082 - val_loss: 0.7065 - val_accuracy: 0.4091\n",
      "Epoch 100/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6902 - accuracy: 0.5410 - val_loss: 0.7062 - val_accuracy: 0.4091\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(128, activation='sigmoid', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='sigmoid'))         \n",
    "\n",
    "Adam=optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=100, epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EebZ47qMakj3"
   },
   "source": [
    "Get validation and test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "yuWhLcrO5WFB",
    "outputId": "2c5a638d-d257-45de-8a83-97a219b52a09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 223us/step\n",
      "26/26 [==============================] - 0s 651us/step\n",
      "Validation [loss, accuracy] is  [0.6840943748300726, 0.5909091125835072]\n",
      "Test [loss, accuracy] is  [0.704076546889085, 0.4230769230769231]\n"
     ]
    }
   ],
   "source": [
    "score_val = model.evaluate(X_val, y_val, batch_size=20)\n",
    "score_test = model.evaluate(X_test, y_test, batch_size=20)\n",
    "\n",
    "print('Validation [loss, accuracy] is ', score_val)\n",
    "print('Test [loss, accuracy] is ', score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "89iHOYkaapTo"
   },
   "source": [
    "Get data formatted for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "colab_type": "code",
    "id": "7b397hiNG0pY",
    "outputId": "9d76a759-5637-4fea-dc0a-9da4c7fa323a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170, 12)\n",
      "(170, 1)\n",
      "Training/Valid data shape: (144, 1363, 12)\n",
      "Test data shape: (26, 1363, 12)\n",
      "Training/Valid target shape: (144, 1)\n",
      "Test target shape: (26, 1)\n",
      "(122, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X=sio.loadmat('feat_vec_rnn.mat')\n",
    "y=sio.loadmat('labels')\n",
    "\n",
    "print(X_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "X_data=X['feat_vec_rnn']\n",
    "X_data=np.transpose(X_data, (2, 0, 1))\n",
    "\n",
    "y_data=y['labels']\n",
    "\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test= train_test_split(X_data, y_data, test_size=0.15, random_state = 31)\n",
    "\n",
    "X_train, X_val, y_train, y_val= train_test_split(X_train_val, y_train_val, test_size=0.15, random_state = 21)\n",
    "\n",
    "\n",
    "\n",
    "print ('Training/Valid data shape: {}'.format(X_train_val.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_val.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "y_train = onehot_encoder.fit_transform(y_train)\n",
    "y_val = onehot_encoder.fit_transform(y_val)\n",
    "y_test = onehot_encoder.fit_transform(y_test)\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oXHr6znGasSG"
   },
   "source": [
    "Run LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "colab_type": "code",
    "id": "i3Nd9Djw7rZR",
    "outputId": "590b450e-cb6b-48d2-ca62-0e2dac752d69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170, 1363, 12)\n",
      "(170, 1)\n",
      "Training/Valid data shape: (144, 1363, 12)\n",
      "Test data shape: (26, 1363, 12)\n",
      "Training/Valid target shape: (144, 1)\n",
      "Test target shape: (26, 1)\n",
      "(122, 2)\n",
      "Train on 122 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "122/122 [==============================] - 14s 116ms/step - loss: 2.5359 - accuracy: 0.6066 - val_loss: 2.5138 - val_accuracy: 0.7273\n",
      "Epoch 2/100\n",
      "122/122 [==============================] - 13s 105ms/step - loss: 2.5011 - accuracy: 0.6721 - val_loss: 2.5007 - val_accuracy: 0.7273\n",
      "Epoch 3/100\n",
      "122/122 [==============================] - 13s 103ms/step - loss: 2.4935 - accuracy: 0.6148 - val_loss: 2.4931 - val_accuracy: 0.7273\n",
      "Epoch 4/100\n",
      "122/122 [==============================] - 13s 104ms/step - loss: 2.4799 - accuracy: 0.6639 - val_loss: 2.4865 - val_accuracy: 0.7273\n",
      "Epoch 5/100\n",
      "122/122 [==============================] - 13s 106ms/step - loss: 2.4854 - accuracy: 0.6393 - val_loss: 2.4815 - val_accuracy: 0.7273\n",
      "Epoch 6/100\n",
      "122/122 [==============================] - 15s 119ms/step - loss: 2.4817 - accuracy: 0.5820 - val_loss: 2.4782 - val_accuracy: 0.7273\n",
      "Epoch 7/100\n",
      "122/122 [==============================] - 14s 112ms/step - loss: 2.4709 - accuracy: 0.6230 - val_loss: 2.4756 - val_accuracy: 0.7273\n",
      "Epoch 8/100\n",
      "122/122 [==============================] - 13s 110ms/step - loss: 2.4754 - accuracy: 0.6066 - val_loss: 2.4738 - val_accuracy: 0.7273\n",
      "Epoch 9/100\n",
      "122/122 [==============================] - 14s 119ms/step - loss: 2.4626 - accuracy: 0.6557 - val_loss: 2.4721 - val_accuracy: 0.7273\n",
      "Epoch 10/100\n",
      "122/122 [==============================] - 14s 116ms/step - loss: 2.4660 - accuracy: 0.6393 - val_loss: 2.4703 - val_accuracy: 0.7273\n",
      "Epoch 11/100\n",
      "122/122 [==============================] - 14s 116ms/step - loss: 2.4578 - accuracy: 0.6393 - val_loss: 2.4686 - val_accuracy: 0.7273\n",
      "Epoch 12/100\n",
      "122/122 [==============================] - 14s 113ms/step - loss: 2.4652 - accuracy: 0.6230 - val_loss: 2.4670 - val_accuracy: 0.7273\n",
      "Epoch 13/100\n",
      "122/122 [==============================] - 15s 120ms/step - loss: 2.4797 - accuracy: 0.5902 - val_loss: 2.4657 - val_accuracy: 0.7273\n",
      "Epoch 14/100\n",
      "122/122 [==============================] - 15s 120ms/step - loss: 2.4632 - accuracy: 0.6311 - val_loss: 2.4645 - val_accuracy: 0.7273\n",
      "Epoch 15/100\n",
      "122/122 [==============================] - 13s 108ms/step - loss: 2.4673 - accuracy: 0.5820 - val_loss: 2.4635 - val_accuracy: 0.7273\n",
      "Epoch 16/100\n",
      "122/122 [==============================] - 13s 105ms/step - loss: 2.4555 - accuracy: 0.6230 - val_loss: 2.4624 - val_accuracy: 0.7273\n",
      "Epoch 17/100\n",
      "122/122 [==============================] - 13s 107ms/step - loss: 2.4560 - accuracy: 0.6148 - val_loss: 2.4614 - val_accuracy: 0.7273\n",
      "Epoch 18/100\n",
      "122/122 [==============================] - 14s 114ms/step - loss: 2.4555 - accuracy: 0.5492 - val_loss: 2.4605 - val_accuracy: 0.7273\n",
      "Epoch 19/100\n",
      "122/122 [==============================] - 15s 122ms/step - loss: 2.4605 - accuracy: 0.6230 - val_loss: 2.4598 - val_accuracy: 0.7273\n",
      "Epoch 20/100\n",
      "122/122 [==============================] - 14s 119ms/step - loss: 2.4583 - accuracy: 0.5574 - val_loss: 2.4591 - val_accuracy: 0.7273\n",
      "Epoch 21/100\n",
      "122/122 [==============================] - 14s 111ms/step - loss: 2.4512 - accuracy: 0.6393 - val_loss: 2.4584 - val_accuracy: 0.7273\n",
      "Epoch 22/100\n",
      "122/122 [==============================] - 17s 137ms/step - loss: 2.4492 - accuracy: 0.5902 - val_loss: 2.4577 - val_accuracy: 0.7273\n",
      "Epoch 23/100\n",
      "122/122 [==============================] - 14s 116ms/step - loss: 2.4509 - accuracy: 0.5820 - val_loss: 2.4571 - val_accuracy: 0.7273\n",
      "Epoch 24/100\n",
      "122/122 [==============================] - 14s 113ms/step - loss: 2.4494 - accuracy: 0.6803 - val_loss: 2.4565 - val_accuracy: 0.7273\n",
      "Epoch 25/100\n",
      "122/122 [==============================] - 13s 108ms/step - loss: 2.4378 - accuracy: 0.6721 - val_loss: 2.4558 - val_accuracy: 0.7273\n",
      "Epoch 26/100\n",
      "122/122 [==============================] - 13s 109ms/step - loss: 2.4473 - accuracy: 0.6066 - val_loss: 2.4552 - val_accuracy: 0.7273\n",
      "Epoch 27/100\n",
      "122/122 [==============================] - 14s 113ms/step - loss: 2.4551 - accuracy: 0.5902 - val_loss: 2.4545 - val_accuracy: 0.7273\n",
      "Epoch 28/100\n",
      "122/122 [==============================] - 14s 111ms/step - loss: 2.4398 - accuracy: 0.6230 - val_loss: 2.4539 - val_accuracy: 0.7273\n",
      "Epoch 29/100\n",
      "122/122 [==============================] - 13s 110ms/step - loss: 2.4491 - accuracy: 0.5902 - val_loss: 2.4534 - val_accuracy: 0.7273\n",
      "Epoch 30/100\n",
      "122/122 [==============================] - 14s 111ms/step - loss: 2.4466 - accuracy: 0.6230 - val_loss: 2.4529 - val_accuracy: 0.7273\n",
      "Epoch 31/100\n",
      "122/122 [==============================] - 13s 110ms/step - loss: 2.4463 - accuracy: 0.6066 - val_loss: 2.4523 - val_accuracy: 0.7273\n",
      "Epoch 32/100\n",
      "122/122 [==============================] - 14s 111ms/step - loss: 2.4465 - accuracy: 0.6311 - val_loss: 2.4518 - val_accuracy: 0.7273\n",
      "Epoch 33/100\n",
      "122/122 [==============================] - 13s 110ms/step - loss: 2.4414 - accuracy: 0.6475 - val_loss: 2.4511 - val_accuracy: 0.7273\n",
      "Epoch 34/100\n",
      "122/122 [==============================] - 14s 112ms/step - loss: 2.4408 - accuracy: 0.6803 - val_loss: 2.4505 - val_accuracy: 0.7273\n",
      "Epoch 35/100\n",
      "122/122 [==============================] - 13s 110ms/step - loss: 2.4462 - accuracy: 0.6639 - val_loss: 2.4500 - val_accuracy: 0.7273\n",
      "Epoch 36/100\n",
      "122/122 [==============================] - 13s 110ms/step - loss: 2.4415 - accuracy: 0.6066 - val_loss: 2.4495 - val_accuracy: 0.7273\n",
      "Epoch 37/100\n",
      "122/122 [==============================] - 13s 105ms/step - loss: 2.4401 - accuracy: 0.6148 - val_loss: 2.4490 - val_accuracy: 0.7273\n",
      "Epoch 38/100\n",
      "122/122 [==============================] - 13s 106ms/step - loss: 2.4398 - accuracy: 0.6639 - val_loss: 2.4485 - val_accuracy: 0.7273\n",
      "Epoch 39/100\n",
      "122/122 [==============================] - 13s 108ms/step - loss: 2.4437 - accuracy: 0.6148 - val_loss: 2.4481 - val_accuracy: 0.7273\n",
      "Epoch 40/100\n",
      "122/122 [==============================] - 14s 116ms/step - loss: 2.4231 - accuracy: 0.6393 - val_loss: 2.4476 - val_accuracy: 0.7273\n",
      "Epoch 41/100\n",
      "122/122 [==============================] - 14s 111ms/step - loss: 2.4289 - accuracy: 0.6885 - val_loss: 2.4471 - val_accuracy: 0.7273\n",
      "Epoch 42/100\n",
      "122/122 [==============================] - 14s 115ms/step - loss: 2.4352 - accuracy: 0.6639 - val_loss: 2.4465 - val_accuracy: 0.7273\n",
      "Epoch 43/100\n",
      "122/122 [==============================] - 13s 109ms/step - loss: 2.4470 - accuracy: 0.5820 - val_loss: 2.4461 - val_accuracy: 0.7273\n",
      "Epoch 44/100\n",
      "122/122 [==============================] - 13s 105ms/step - loss: 2.4343 - accuracy: 0.6557 - val_loss: 2.4456 - val_accuracy: 0.7273\n",
      "Epoch 45/100\n",
      "122/122 [==============================] - 13s 106ms/step - loss: 2.4534 - accuracy: 0.5902 - val_loss: 2.4452 - val_accuracy: 0.7273\n",
      "Epoch 46/100\n",
      "122/122 [==============================] - 13s 108ms/step - loss: 2.4435 - accuracy: 0.6311 - val_loss: 2.4448 - val_accuracy: 0.7273\n",
      "Epoch 47/100\n",
      "122/122 [==============================] - 13s 103ms/step - loss: 2.4524 - accuracy: 0.6148 - val_loss: 2.4444 - val_accuracy: 0.7273\n",
      "Epoch 48/100\n",
      "122/122 [==============================] - 13s 106ms/step - loss: 2.4273 - accuracy: 0.6803 - val_loss: 2.4440 - val_accuracy: 0.7273\n",
      "Epoch 49/100\n",
      "122/122 [==============================] - 13s 108ms/step - loss: 2.4261 - accuracy: 0.6311 - val_loss: 2.4436 - val_accuracy: 0.7273\n",
      "Epoch 50/100\n",
      "122/122 [==============================] - 13s 107ms/step - loss: 2.4257 - accuracy: 0.6639 - val_loss: 2.4432 - val_accuracy: 0.7273\n",
      "Epoch 51/100\n",
      "122/122 [==============================] - 13s 105ms/step - loss: 2.4290 - accuracy: 0.5820 - val_loss: 2.4428 - val_accuracy: 0.7273\n",
      "Epoch 52/100\n",
      "122/122 [==============================] - 13s 104ms/step - loss: 2.4392 - accuracy: 0.6393 - val_loss: 2.4424 - val_accuracy: 0.7273\n",
      "Epoch 53/100\n",
      "122/122 [==============================] - 13s 104ms/step - loss: 2.4335 - accuracy: 0.6639 - val_loss: 2.4421 - val_accuracy: 0.7273\n",
      "Epoch 54/100\n",
      "122/122 [==============================] - 12s 102ms/step - loss: 2.4263 - accuracy: 0.6393 - val_loss: 2.4417 - val_accuracy: 0.7273\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 13s 105ms/step - loss: 2.4381 - accuracy: 0.6393 - val_loss: 2.4414 - val_accuracy: 0.7273\n",
      "Epoch 56/100\n",
      "122/122 [==============================] - 13s 109ms/step - loss: 2.4385 - accuracy: 0.6066 - val_loss: 2.4411 - val_accuracy: 0.7273\n",
      "Epoch 57/100\n",
      "122/122 [==============================] - 13s 110ms/step - loss: 2.4412 - accuracy: 0.6148 - val_loss: 2.4408 - val_accuracy: 0.7273\n",
      "Epoch 58/100\n",
      "122/122 [==============================] - 13s 109ms/step - loss: 2.4291 - accuracy: 0.6311 - val_loss: 2.4406 - val_accuracy: 0.7273\n",
      "Epoch 59/100\n",
      "122/122 [==============================] - 13s 104ms/step - loss: 2.4336 - accuracy: 0.6639 - val_loss: 2.4403 - val_accuracy: 0.7273\n",
      "Epoch 60/100\n",
      "122/122 [==============================] - 13s 104ms/step - loss: 2.4263 - accuracy: 0.6475 - val_loss: 2.4400 - val_accuracy: 0.7273\n",
      "Epoch 61/100\n",
      "122/122 [==============================] - 13s 105ms/step - loss: 2.4392 - accuracy: 0.6148 - val_loss: 2.4398 - val_accuracy: 0.7273\n",
      "Epoch 62/100\n",
      "122/122 [==============================] - 13s 105ms/step - loss: 2.4300 - accuracy: 0.6311 - val_loss: 2.4395 - val_accuracy: 0.7273\n",
      "Epoch 63/100\n",
      "122/122 [==============================] - 13s 110ms/step - loss: 2.4237 - accuracy: 0.6639 - val_loss: 2.4392 - val_accuracy: 0.7273\n",
      "Epoch 64/100\n",
      "122/122 [==============================] - 13s 109ms/step - loss: 2.4322 - accuracy: 0.6148 - val_loss: 2.4389 - val_accuracy: 0.7273\n",
      "Epoch 65/100\n",
      "122/122 [==============================] - 13s 110ms/step - loss: 2.4221 - accuracy: 0.6639 - val_loss: 2.4386 - val_accuracy: 0.7273\n",
      "Epoch 66/100\n",
      "122/122 [==============================] - 13s 105ms/step - loss: 2.4297 - accuracy: 0.6557 - val_loss: 2.4384 - val_accuracy: 0.7273\n",
      "Epoch 67/100\n",
      "122/122 [==============================] - 13s 105ms/step - loss: 2.4114 - accuracy: 0.6885 - val_loss: 2.4382 - val_accuracy: 0.7273\n",
      "Epoch 68/100\n",
      "122/122 [==============================] - 13s 108ms/step - loss: 2.4194 - accuracy: 0.6475 - val_loss: 2.4379 - val_accuracy: 0.7273\n",
      "Epoch 69/100\n",
      "122/122 [==============================] - 13s 106ms/step - loss: 2.4305 - accuracy: 0.6393 - val_loss: 2.4377 - val_accuracy: 0.7273\n",
      "Epoch 70/100\n",
      "122/122 [==============================] - 13s 103ms/step - loss: 2.4348 - accuracy: 0.6803 - val_loss: 2.4375 - val_accuracy: 0.7273\n",
      "Epoch 71/100\n",
      "122/122 [==============================] - 13s 104ms/step - loss: 2.4298 - accuracy: 0.6639 - val_loss: 2.4373 - val_accuracy: 0.7273\n",
      "Epoch 72/100\n",
      "122/122 [==============================] - 13s 106ms/step - loss: 2.4385 - accuracy: 0.6393 - val_loss: 2.4371 - val_accuracy: 0.7273\n",
      "Epoch 73/100\n",
      "122/122 [==============================] - 13s 109ms/step - loss: 2.4273 - accuracy: 0.6311 - val_loss: 2.4369 - val_accuracy: 0.7273\n",
      "Epoch 74/100\n",
      "122/122 [==============================] - 13s 108ms/step - loss: 2.4264 - accuracy: 0.6721 - val_loss: 2.4366 - val_accuracy: 0.7273\n",
      "Epoch 75/100\n",
      "122/122 [==============================] - 13s 108ms/step - loss: 2.4251 - accuracy: 0.6803 - val_loss: 2.4364 - val_accuracy: 0.7273\n",
      "Epoch 76/100\n",
      "122/122 [==============================] - 13s 105ms/step - loss: 2.4241 - accuracy: 0.6230 - val_loss: 2.4362 - val_accuracy: 0.7273\n",
      "Epoch 77/100\n",
      "122/122 [==============================] - 13s 104ms/step - loss: 2.4378 - accuracy: 0.6066 - val_loss: 2.4360 - val_accuracy: 0.7273\n",
      "Epoch 78/100\n",
      "122/122 [==============================] - 13s 105ms/step - loss: 2.4269 - accuracy: 0.6393 - val_loss: 2.4358 - val_accuracy: 0.7273\n",
      "Epoch 79/100\n",
      "122/122 [==============================] - 13s 109ms/step - loss: 2.4267 - accuracy: 0.6393 - val_loss: 2.4356 - val_accuracy: 0.7273\n",
      "Epoch 80/100\n",
      "122/122 [==============================] - 13s 107ms/step - loss: 2.4269 - accuracy: 0.6639 - val_loss: 2.4354 - val_accuracy: 0.7273\n",
      "Epoch 81/100\n",
      "122/122 [==============================] - 13s 108ms/step - loss: 2.4209 - accuracy: 0.6311 - val_loss: 2.4352 - val_accuracy: 0.7273\n",
      "Epoch 82/100\n",
      "122/122 [==============================] - 12s 102ms/step - loss: 2.4306 - accuracy: 0.5820 - val_loss: 2.4350 - val_accuracy: 0.7273\n",
      "Epoch 83/100\n",
      "122/122 [==============================] - 13s 104ms/step - loss: 2.4316 - accuracy: 0.6639 - val_loss: 2.4349 - val_accuracy: 0.7273\n",
      "Epoch 84/100\n",
      "122/122 [==============================] - 13s 106ms/step - loss: 2.4445 - accuracy: 0.5820 - val_loss: 2.4347 - val_accuracy: 0.7273\n",
      "Epoch 85/100\n",
      "122/122 [==============================] - 13s 109ms/step - loss: 2.4187 - accuracy: 0.7131 - val_loss: 2.4346 - val_accuracy: 0.7273\n",
      "Epoch 86/100\n",
      "122/122 [==============================] - 13s 110ms/step - loss: 2.4345 - accuracy: 0.6311 - val_loss: 2.4344 - val_accuracy: 0.7273\n",
      "Epoch 87/100\n",
      "122/122 [==============================] - 13s 108ms/step - loss: 2.4169 - accuracy: 0.7131 - val_loss: 2.4342 - val_accuracy: 0.7273\n",
      "Epoch 88/100\n",
      "122/122 [==============================] - 13s 107ms/step - loss: 2.4313 - accuracy: 0.5738 - val_loss: 2.4341 - val_accuracy: 0.7273\n",
      "Epoch 89/100\n",
      "122/122 [==============================] - 13s 105ms/step - loss: 2.4186 - accuracy: 0.6475 - val_loss: 2.4339 - val_accuracy: 0.7273\n",
      "Epoch 90/100\n",
      "122/122 [==============================] - 13s 109ms/step - loss: 2.4319 - accuracy: 0.6475 - val_loss: 2.4338 - val_accuracy: 0.7273\n",
      "Epoch 91/100\n",
      "122/122 [==============================] - 13s 109ms/step - loss: 2.4270 - accuracy: 0.6557 - val_loss: 2.4337 - val_accuracy: 0.7273\n",
      "Epoch 92/100\n",
      "122/122 [==============================] - 13s 106ms/step - loss: 2.4230 - accuracy: 0.6475 - val_loss: 2.4335 - val_accuracy: 0.7273\n",
      "Epoch 93/100\n",
      "122/122 [==============================] - 13s 105ms/step - loss: 2.4294 - accuracy: 0.6148 - val_loss: 2.4334 - val_accuracy: 0.7273\n",
      "Epoch 94/100\n",
      "122/122 [==============================] - 13s 104ms/step - loss: 2.4189 - accuracy: 0.6148 - val_loss: 2.4332 - val_accuracy: 0.7273\n",
      "Epoch 95/100\n",
      "122/122 [==============================] - 13s 106ms/step - loss: 2.4305 - accuracy: 0.6475 - val_loss: 2.4330 - val_accuracy: 0.7273\n",
      "Epoch 96/100\n",
      "122/122 [==============================] - 13s 109ms/step - loss: 2.4320 - accuracy: 0.6311 - val_loss: 2.4329 - val_accuracy: 0.7273\n",
      "Epoch 97/100\n",
      "122/122 [==============================] - 13s 108ms/step - loss: 2.4199 - accuracy: 0.6148 - val_loss: 2.4327 - val_accuracy: 0.7273\n",
      "Epoch 98/100\n",
      "122/122 [==============================] - 13s 109ms/step - loss: 2.4307 - accuracy: 0.5738 - val_loss: 2.4325 - val_accuracy: 0.7273\n",
      "Epoch 99/100\n",
      "122/122 [==============================] - 13s 105ms/step - loss: 2.4202 - accuracy: 0.6393 - val_loss: 2.4323 - val_accuracy: 0.7273\n",
      "Epoch 100/100\n",
      "122/122 [==============================] - 13s 106ms/step - loss: 2.4157 - accuracy: 0.6148 - val_loss: 2.4322 - val_accuracy: 0.7273\n",
      "(170, 1363, 12)\n",
      "(170, 1)\n",
      "Training/Valid data shape: (144, 1363, 12)\n",
      "Test data shape: (26, 1363, 12)\n",
      "Training/Valid target shape: (144, 1)\n",
      "Test target shape: (26, 1)\n",
      "(122, 2)\n",
      "Train on 122 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "122/122 [==============================] - 16s 135ms/step - loss: 2.5546 - accuracy: 0.5328 - val_loss: 2.5694 - val_accuracy: 0.4545\n",
      "Epoch 2/100\n",
      "122/122 [==============================] - 15s 121ms/step - loss: 2.5075 - accuracy: 0.6393 - val_loss: 2.5628 - val_accuracy: 0.4545\n",
      "Epoch 3/100\n",
      "122/122 [==============================] - 14s 118ms/step - loss: 2.5136 - accuracy: 0.5984 - val_loss: 2.5587 - val_accuracy: 0.4545\n",
      "Epoch 4/100\n",
      "122/122 [==============================] - 14s 118ms/step - loss: 2.5202 - accuracy: 0.5820 - val_loss: 2.5551 - val_accuracy: 0.4545\n",
      "Epoch 5/100\n",
      "122/122 [==============================] - 15s 119ms/step - loss: 2.4992 - accuracy: 0.5984 - val_loss: 2.5524 - val_accuracy: 0.4545\n",
      "Epoch 6/100\n",
      "122/122 [==============================] - 14s 118ms/step - loss: 2.5110 - accuracy: 0.5328 - val_loss: 2.5502 - val_accuracy: 0.4545\n",
      "Epoch 7/100\n",
      "122/122 [==============================] - 15s 121ms/step - loss: 2.5026 - accuracy: 0.5656 - val_loss: 2.5482 - val_accuracy: 0.4545\n",
      "Epoch 8/100\n",
      "122/122 [==============================] - 15s 121ms/step - loss: 2.5011 - accuracy: 0.5902 - val_loss: 2.5464 - val_accuracy: 0.4545\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 14s 118ms/step - loss: 2.4905 - accuracy: 0.5984 - val_loss: 2.5450 - val_accuracy: 0.4545\n",
      "Epoch 10/100\n",
      "122/122 [==============================] - 15s 120ms/step - loss: 2.5107 - accuracy: 0.5492 - val_loss: 2.5435 - val_accuracy: 0.4545\n",
      "Epoch 11/100\n",
      "122/122 [==============================] - 15s 123ms/step - loss: 2.4832 - accuracy: 0.5984 - val_loss: 2.5423 - val_accuracy: 0.4545\n",
      "Epoch 12/100\n",
      "122/122 [==============================] - 15s 122ms/step - loss: 2.5007 - accuracy: 0.5492 - val_loss: 2.5412 - val_accuracy: 0.4545\n",
      "Epoch 13/100\n",
      "122/122 [==============================] - 15s 120ms/step - loss: 2.5007 - accuracy: 0.5410 - val_loss: 2.5402 - val_accuracy: 0.4545\n",
      "Epoch 14/100\n",
      "122/122 [==============================] - 15s 123ms/step - loss: 2.4830 - accuracy: 0.6311 - val_loss: 2.5393 - val_accuracy: 0.4545\n",
      "Epoch 15/100\n",
      "122/122 [==============================] - 15s 120ms/step - loss: 2.4871 - accuracy: 0.5738 - val_loss: 2.5385 - val_accuracy: 0.4545\n",
      "Epoch 16/100\n",
      "122/122 [==============================] - 15s 119ms/step - loss: 2.4770 - accuracy: 0.6066 - val_loss: 2.5379 - val_accuracy: 0.4545\n",
      "Epoch 17/100\n",
      "122/122 [==============================] - 15s 119ms/step - loss: 2.4918 - accuracy: 0.5738 - val_loss: 2.5372 - val_accuracy: 0.4545\n",
      "Epoch 18/100\n",
      "122/122 [==============================] - 15s 121ms/step - loss: 2.4688 - accuracy: 0.6475 - val_loss: 2.5366 - val_accuracy: 0.4545\n",
      "Epoch 19/100\n",
      "122/122 [==============================] - 15s 121ms/step - loss: 2.4918 - accuracy: 0.4918 - val_loss: 2.5360 - val_accuracy: 0.4545\n",
      "Epoch 20/100\n",
      "122/122 [==============================] - 14s 119ms/step - loss: 2.4570 - accuracy: 0.6885 - val_loss: 2.5355 - val_accuracy: 0.4545\n",
      "Epoch 21/100\n",
      "122/122 [==============================] - 15s 120ms/step - loss: 2.4735 - accuracy: 0.5984 - val_loss: 2.5350 - val_accuracy: 0.4545\n",
      "Epoch 22/100\n",
      "122/122 [==============================] - 15s 124ms/step - loss: 2.4731 - accuracy: 0.6311 - val_loss: 2.5344 - val_accuracy: 0.4545\n",
      "Epoch 23/100\n",
      "122/122 [==============================] - 15s 121ms/step - loss: 2.4748 - accuracy: 0.6066 - val_loss: 2.5339 - val_accuracy: 0.4545\n",
      "Epoch 24/100\n",
      "122/122 [==============================] - 14s 118ms/step - loss: 2.4688 - accuracy: 0.6393 - val_loss: 2.5334 - val_accuracy: 0.4545\n",
      "Epoch 25/100\n",
      "122/122 [==============================] - 15s 119ms/step - loss: 2.4817 - accuracy: 0.5738 - val_loss: 2.5329 - val_accuracy: 0.4545\n",
      "Epoch 26/100\n",
      "122/122 [==============================] - 15s 123ms/step - loss: 2.4795 - accuracy: 0.5820 - val_loss: 2.5324 - val_accuracy: 0.4545\n",
      "Epoch 27/100\n",
      "122/122 [==============================] - 15s 122ms/step - loss: 2.4726 - accuracy: 0.5820 - val_loss: 2.5319 - val_accuracy: 0.4545\n",
      "Epoch 28/100\n",
      "122/122 [==============================] - 15s 124ms/step - loss: 2.4731 - accuracy: 0.5984 - val_loss: 2.5315 - val_accuracy: 0.4545\n",
      "Epoch 29/100\n",
      "122/122 [==============================] - 14s 118ms/step - loss: 2.4890 - accuracy: 0.5738 - val_loss: 2.5311 - val_accuracy: 0.4545\n",
      "Epoch 30/100\n",
      "122/122 [==============================] - 15s 122ms/step - loss: 2.4782 - accuracy: 0.5656 - val_loss: 2.5306 - val_accuracy: 0.4545\n",
      "Epoch 31/100\n",
      "122/122 [==============================] - 15s 123ms/step - loss: 2.4756 - accuracy: 0.5984 - val_loss: 2.5302 - val_accuracy: 0.4545\n",
      "Epoch 32/100\n",
      "122/122 [==============================] - 15s 125ms/step - loss: 2.4700 - accuracy: 0.6148 - val_loss: 2.5297 - val_accuracy: 0.4545\n",
      "Epoch 33/100\n",
      "122/122 [==============================] - 14s 119ms/step - loss: 2.4796 - accuracy: 0.5738 - val_loss: 2.5293 - val_accuracy: 0.4545\n",
      "Epoch 34/100\n",
      "122/122 [==============================] - 15s 121ms/step - loss: 2.4765 - accuracy: 0.5820 - val_loss: 2.5288 - val_accuracy: 0.4545\n",
      "Epoch 35/100\n",
      "122/122 [==============================] - 15s 123ms/step - loss: 2.4752 - accuracy: 0.6311 - val_loss: 2.5284 - val_accuracy: 0.4545\n",
      "Epoch 36/100\n",
      "122/122 [==============================] - 15s 125ms/step - loss: 2.4792 - accuracy: 0.5902 - val_loss: 2.5280 - val_accuracy: 0.4545\n",
      "Epoch 37/100\n",
      "122/122 [==============================] - 15s 121ms/step - loss: 2.4759 - accuracy: 0.5902 - val_loss: 2.5276 - val_accuracy: 0.4545\n",
      "Epoch 38/100\n",
      "122/122 [==============================] - 15s 121ms/step - loss: 2.4871 - accuracy: 0.5492 - val_loss: 2.5272 - val_accuracy: 0.4545\n",
      "Epoch 39/100\n",
      "122/122 [==============================] - 15s 124ms/step - loss: 2.4775 - accuracy: 0.5656 - val_loss: 2.5268 - val_accuracy: 0.4545\n",
      "Epoch 40/100\n",
      "122/122 [==============================] - 15s 125ms/step - loss: 2.4742 - accuracy: 0.5738 - val_loss: 2.5264 - val_accuracy: 0.4545\n",
      "Epoch 41/100\n",
      "122/122 [==============================] - 14s 119ms/step - loss: 2.4596 - accuracy: 0.5984 - val_loss: 2.5260 - val_accuracy: 0.4545\n",
      "Epoch 42/100\n",
      "122/122 [==============================] - 15s 120ms/step - loss: 2.4650 - accuracy: 0.5820 - val_loss: 2.5256 - val_accuracy: 0.4545\n",
      "Epoch 43/100\n",
      "122/122 [==============================] - 15s 124ms/step - loss: 2.4676 - accuracy: 0.5492 - val_loss: 2.5253 - val_accuracy: 0.4545\n",
      "Epoch 44/100\n",
      "122/122 [==============================] - 15s 124ms/step - loss: 2.4657 - accuracy: 0.6066 - val_loss: 2.5249 - val_accuracy: 0.4545\n",
      "Epoch 45/100\n",
      "122/122 [==============================] - 15s 123ms/step - loss: 2.4742 - accuracy: 0.5984 - val_loss: 2.5245 - val_accuracy: 0.4545\n",
      "Epoch 46/100\n",
      "122/122 [==============================] - 14s 118ms/step - loss: 2.4641 - accuracy: 0.6148 - val_loss: 2.5241 - val_accuracy: 0.4545\n",
      "Epoch 47/100\n",
      "122/122 [==============================] - 15s 120ms/step - loss: 2.4608 - accuracy: 0.5820 - val_loss: 2.5237 - val_accuracy: 0.4545\n",
      "Epoch 48/100\n",
      "122/122 [==============================] - 15s 125ms/step - loss: 2.4695 - accuracy: 0.6066 - val_loss: 2.5233 - val_accuracy: 0.4545\n",
      "Epoch 49/100\n",
      "122/122 [==============================] - 15s 123ms/step - loss: 2.4630 - accuracy: 0.6148 - val_loss: 2.5230 - val_accuracy: 0.4545\n",
      "Epoch 50/100\n",
      "122/122 [==============================] - 15s 119ms/step - loss: 2.4720 - accuracy: 0.5820 - val_loss: 2.5226 - val_accuracy: 0.4545\n",
      "Epoch 51/100\n",
      "122/122 [==============================] - 15s 123ms/step - loss: 2.4647 - accuracy: 0.6066 - val_loss: 2.5223 - val_accuracy: 0.4545\n",
      "Epoch 52/100\n",
      "122/122 [==============================] - 15s 119ms/step - loss: 2.4553 - accuracy: 0.6311 - val_loss: 2.5220 - val_accuracy: 0.4545\n",
      "Epoch 53/100\n",
      "122/122 [==============================] - 15s 122ms/step - loss: 2.4467 - accuracy: 0.6475 - val_loss: 2.5217 - val_accuracy: 0.4545\n",
      "Epoch 54/100\n",
      "122/122 [==============================] - 15s 122ms/step - loss: 2.4651 - accuracy: 0.5656 - val_loss: 2.5214 - val_accuracy: 0.4545\n",
      "Epoch 55/100\n",
      "122/122 [==============================] - 14s 118ms/step - loss: 2.4487 - accuracy: 0.5984 - val_loss: 2.5212 - val_accuracy: 0.4545\n",
      "Epoch 56/100\n",
      "122/122 [==============================] - 15s 119ms/step - loss: 2.4722 - accuracy: 0.5820 - val_loss: 2.5209 - val_accuracy: 0.4545\n",
      "Epoch 57/100\n",
      "122/122 [==============================] - 14s 119ms/step - loss: 2.4531 - accuracy: 0.5820 - val_loss: 2.5206 - val_accuracy: 0.4545\n",
      "Epoch 58/100\n",
      "122/122 [==============================] - 15s 123ms/step - loss: 2.4472 - accuracy: 0.6393 - val_loss: 2.5203 - val_accuracy: 0.4545\n",
      "Epoch 59/100\n",
      "122/122 [==============================] - 15s 124ms/step - loss: 2.4510 - accuracy: 0.6066 - val_loss: 2.5201 - val_accuracy: 0.4545\n",
      "Epoch 60/100\n",
      "122/122 [==============================] - 15s 125ms/step - loss: 2.4500 - accuracy: 0.6885 - val_loss: 2.5198 - val_accuracy: 0.4545\n",
      "Epoch 61/100\n",
      "122/122 [==============================] - 15s 119ms/step - loss: 2.4546 - accuracy: 0.6230 - val_loss: 2.5196 - val_accuracy: 0.4545\n",
      "Epoch 62/100\n",
      "122/122 [==============================] - 15s 121ms/step - loss: 2.4493 - accuracy: 0.6311 - val_loss: 2.5194 - val_accuracy: 0.4545\n",
      "Epoch 63/100\n",
      "122/122 [==============================] - 15s 125ms/step - loss: 2.4638 - accuracy: 0.6066 - val_loss: 2.5191 - val_accuracy: 0.4545\n",
      "Epoch 64/100\n",
      "122/122 [==============================] - 15s 123ms/step - loss: 2.4598 - accuracy: 0.5984 - val_loss: 2.5189 - val_accuracy: 0.4545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "122/122 [==============================] - 15s 120ms/step - loss: 2.4655 - accuracy: 0.5984 - val_loss: 2.5187 - val_accuracy: 0.4545\n",
      "Epoch 66/100\n",
      "122/122 [==============================] - 15s 119ms/step - loss: 2.4611 - accuracy: 0.6148 - val_loss: 2.5184 - val_accuracy: 0.4545\n",
      "Epoch 67/100\n",
      "122/122 [==============================] - 15s 120ms/step - loss: 2.4638 - accuracy: 0.5820 - val_loss: 2.5182 - val_accuracy: 0.4545\n",
      "Epoch 68/100\n",
      "122/122 [==============================] - 15s 125ms/step - loss: 2.4590 - accuracy: 0.5984 - val_loss: 2.5180 - val_accuracy: 0.4545\n",
      "Epoch 69/100\n",
      "122/122 [==============================] - 15s 122ms/step - loss: 2.4715 - accuracy: 0.5328 - val_loss: 2.5178 - val_accuracy: 0.4545\n",
      "Epoch 70/100\n",
      "122/122 [==============================] - 14s 119ms/step - loss: 2.4628 - accuracy: 0.5656 - val_loss: 2.5176 - val_accuracy: 0.4545\n",
      "Epoch 71/100\n",
      "122/122 [==============================] - 15s 120ms/step - loss: 2.4611 - accuracy: 0.5492 - val_loss: 2.5174 - val_accuracy: 0.4545\n",
      "Epoch 72/100\n",
      "122/122 [==============================] - 15s 124ms/step - loss: 2.4503 - accuracy: 0.6393 - val_loss: 2.5173 - val_accuracy: 0.4545\n",
      "Epoch 73/100\n",
      "122/122 [==============================] - 15s 123ms/step - loss: 2.4478 - accuracy: 0.6311 - val_loss: 2.5171 - val_accuracy: 0.4545\n",
      "Epoch 74/100\n",
      "122/122 [==============================] - 14s 118ms/step - loss: 2.4645 - accuracy: 0.5902 - val_loss: 2.5169 - val_accuracy: 0.4545\n",
      "Epoch 75/100\n",
      "122/122 [==============================] - 15s 120ms/step - loss: 2.4431 - accuracy: 0.6639 - val_loss: 2.5168 - val_accuracy: 0.4545\n",
      "Epoch 76/100\n",
      "122/122 [==============================] - 15s 125ms/step - loss: 2.4574 - accuracy: 0.6066 - val_loss: 2.5166 - val_accuracy: 0.4545\n",
      "Epoch 77/100\n",
      "122/122 [==============================] - 15s 124ms/step - loss: 2.4532 - accuracy: 0.6066 - val_loss: 2.5164 - val_accuracy: 0.4545\n",
      "Epoch 78/100\n",
      "122/122 [==============================] - 14s 118ms/step - loss: 2.4599 - accuracy: 0.5984 - val_loss: 2.5163 - val_accuracy: 0.4545\n",
      "Epoch 79/100\n",
      "122/122 [==============================] - 15s 121ms/step - loss: 2.4527 - accuracy: 0.5984 - val_loss: 2.5161 - val_accuracy: 0.4545\n",
      "Epoch 80/100\n",
      "122/122 [==============================] - 15s 121ms/step - loss: 2.4642 - accuracy: 0.5738 - val_loss: 2.5159 - val_accuracy: 0.4545\n",
      "Epoch 81/100\n",
      "122/122 [==============================] - 15s 125ms/step - loss: 2.4753 - accuracy: 0.4918 - val_loss: 2.5157 - val_accuracy: 0.4545\n",
      "Epoch 82/100\n",
      "122/122 [==============================] - 15s 125ms/step - loss: 2.4557 - accuracy: 0.5738 - val_loss: 2.5155 - val_accuracy: 0.4545\n",
      "Epoch 83/100\n",
      "122/122 [==============================] - 15s 123ms/step - loss: 2.4386 - accuracy: 0.6230 - val_loss: 2.5154 - val_accuracy: 0.4545\n",
      "Epoch 84/100\n",
      "122/122 [==============================] - 14s 118ms/step - loss: 2.4604 - accuracy: 0.6066 - val_loss: 2.5152 - val_accuracy: 0.4545\n",
      "Epoch 85/100\n",
      "122/122 [==============================] - 15s 121ms/step - loss: 2.4662 - accuracy: 0.5656 - val_loss: 2.5150 - val_accuracy: 0.4545\n",
      "Epoch 86/100\n",
      "122/122 [==============================] - 15s 124ms/step - loss: 2.4624 - accuracy: 0.5738 - val_loss: 2.5148 - val_accuracy: 0.4545\n",
      "Epoch 87/100\n",
      "122/122 [==============================] - 15s 124ms/step - loss: 2.4396 - accuracy: 0.5902 - val_loss: 2.5147 - val_accuracy: 0.4545\n",
      "Epoch 88/100\n",
      "122/122 [==============================] - 15s 120ms/step - loss: 2.4560 - accuracy: 0.5984 - val_loss: 2.5145 - val_accuracy: 0.4545\n",
      "Epoch 89/100\n",
      "122/122 [==============================] - 15s 121ms/step - loss: 2.4565 - accuracy: 0.5902 - val_loss: 2.5144 - val_accuracy: 0.4545\n",
      "Epoch 90/100\n",
      "122/122 [==============================] - 15s 124ms/step - loss: 2.4603 - accuracy: 0.5902 - val_loss: 2.5142 - val_accuracy: 0.4545\n",
      "Epoch 91/100\n",
      "122/122 [==============================] - 15s 124ms/step - loss: 2.4653 - accuracy: 0.5656 - val_loss: 2.5140 - val_accuracy: 0.4545\n",
      "Epoch 92/100\n",
      "122/122 [==============================] - 14s 118ms/step - loss: 2.4371 - accuracy: 0.6393 - val_loss: 2.5139 - val_accuracy: 0.4545\n",
      "Epoch 93/100\n",
      "122/122 [==============================] - 15s 119ms/step - loss: 2.4558 - accuracy: 0.6148 - val_loss: 2.5137 - val_accuracy: 0.4545\n",
      "Epoch 94/100\n",
      "122/122 [==============================] - 15s 122ms/step - loss: 2.4379 - accuracy: 0.6066 - val_loss: 2.5136 - val_accuracy: 0.4545\n",
      "Epoch 95/100\n",
      "122/122 [==============================] - 15s 125ms/step - loss: 2.4502 - accuracy: 0.5820 - val_loss: 2.5134 - val_accuracy: 0.4545\n",
      "Epoch 96/100\n",
      "122/122 [==============================] - 15s 124ms/step - loss: 2.4426 - accuracy: 0.6230 - val_loss: 2.5133 - val_accuracy: 0.4545\n",
      "Epoch 97/100\n",
      "122/122 [==============================] - 15s 122ms/step - loss: 2.4423 - accuracy: 0.6639 - val_loss: 2.5132 - val_accuracy: 0.4545\n",
      "Epoch 98/100\n",
      "122/122 [==============================] - 15s 119ms/step - loss: 2.4475 - accuracy: 0.5984 - val_loss: 2.5130 - val_accuracy: 0.4545\n",
      "Epoch 99/100\n",
      "122/122 [==============================] - 14s 119ms/step - loss: 2.4498 - accuracy: 0.6393 - val_loss: 2.5129 - val_accuracy: 0.4545\n",
      "Epoch 100/100\n",
      "122/122 [==============================] - 14s 118ms/step - loss: 2.4612 - accuracy: 0.5656 - val_loss: 2.5128 - val_accuracy: 0.4545\n",
      "(170, 1363, 12)\n",
      "(170, 1)\n",
      "Training/Valid data shape: (144, 1363, 12)\n",
      "Test data shape: (26, 1363, 12)\n",
      "Training/Valid target shape: (144, 1)\n",
      "Test target shape: (26, 1)\n",
      "(122, 2)\n",
      "Train on 122 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "122/122 [==============================] - 18s 150ms/step - loss: 2.8247 - accuracy: 0.5984 - val_loss: 2.8079 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "122/122 [==============================] - 17s 137ms/step - loss: 2.7920 - accuracy: 0.5574 - val_loss: 2.7891 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "122/122 [==============================] - 17s 136ms/step - loss: 2.7814 - accuracy: 0.5984 - val_loss: 2.7805 - val_accuracy: 0.5455\n",
      "Epoch 4/100\n",
      "122/122 [==============================] - 16s 130ms/step - loss: 2.7728 - accuracy: 0.5984 - val_loss: 2.7736 - val_accuracy: 0.5455\n",
      "Epoch 5/100\n",
      "122/122 [==============================] - 16s 129ms/step - loss: 2.7678 - accuracy: 0.6230 - val_loss: 2.7678 - val_accuracy: 0.5455\n",
      "Epoch 6/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 2.7568 - accuracy: 0.5984 - val_loss: 2.7633 - val_accuracy: 0.5455\n",
      "Epoch 7/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 2.7507 - accuracy: 0.6148 - val_loss: 2.7599 - val_accuracy: 0.5909\n",
      "Epoch 8/100\n",
      "122/122 [==============================] - 16s 130ms/step - loss: 2.7509 - accuracy: 0.6066 - val_loss: 2.7568 - val_accuracy: 0.5909\n",
      "Epoch 9/100\n",
      "122/122 [==============================] - 17s 135ms/step - loss: 2.7565 - accuracy: 0.6311 - val_loss: 2.7537 - val_accuracy: 0.5909\n",
      "Epoch 10/100\n",
      "122/122 [==============================] - 17s 136ms/step - loss: 2.7574 - accuracy: 0.5492 - val_loss: 2.7510 - val_accuracy: 0.5909\n",
      "Epoch 11/100\n",
      "122/122 [==============================] - 16s 130ms/step - loss: 2.7479 - accuracy: 0.6393 - val_loss: 2.7485 - val_accuracy: 0.5909\n",
      "Epoch 12/100\n",
      "122/122 [==============================] - 16s 128ms/step - loss: 2.7443 - accuracy: 0.5902 - val_loss: 2.7462 - val_accuracy: 0.5909\n",
      "Epoch 13/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 2.7442 - accuracy: 0.5984 - val_loss: 2.7440 - val_accuracy: 0.5909\n",
      "Epoch 14/100\n",
      "122/122 [==============================] - 17s 137ms/step - loss: 2.7495 - accuracy: 0.5738 - val_loss: 2.7422 - val_accuracy: 0.5909\n",
      "Epoch 15/100\n",
      "122/122 [==============================] - 17s 136ms/step - loss: 2.7431 - accuracy: 0.5984 - val_loss: 2.7405 - val_accuracy: 0.5909\n",
      "Epoch 16/100\n",
      "122/122 [==============================] - 17s 136ms/step - loss: 2.7376 - accuracy: 0.6393 - val_loss: 2.7391 - val_accuracy: 0.5909\n",
      "Epoch 17/100\n",
      "122/122 [==============================] - 16s 130ms/step - loss: 2.7417 - accuracy: 0.5656 - val_loss: 2.7378 - val_accuracy: 0.5909\n",
      "Epoch 18/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 2.7355 - accuracy: 0.5902 - val_loss: 2.7366 - val_accuracy: 0.5909\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 17s 137ms/step - loss: 2.7356 - accuracy: 0.6148 - val_loss: 2.7355 - val_accuracy: 0.5909\n",
      "Epoch 20/100\n",
      "122/122 [==============================] - 17s 136ms/step - loss: 2.7335 - accuracy: 0.6148 - val_loss: 2.7342 - val_accuracy: 0.5909\n",
      "Epoch 21/100\n",
      "122/122 [==============================] - 16s 130ms/step - loss: 2.7278 - accuracy: 0.6393 - val_loss: 2.7330 - val_accuracy: 0.5909\n",
      "Epoch 22/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 2.7311 - accuracy: 0.6475 - val_loss: 2.7318 - val_accuracy: 0.5909\n",
      "Epoch 23/100\n",
      "122/122 [==============================] - 16s 134ms/step - loss: 2.7296 - accuracy: 0.6066 - val_loss: 2.7307 - val_accuracy: 0.5909\n",
      "Epoch 24/100\n",
      "122/122 [==============================] - 17s 137ms/step - loss: 2.7415 - accuracy: 0.5984 - val_loss: 2.7296 - val_accuracy: 0.5909\n",
      "Epoch 25/100\n",
      "122/122 [==============================] - 17s 135ms/step - loss: 2.7340 - accuracy: 0.5574 - val_loss: 2.7286 - val_accuracy: 0.5909\n",
      "Epoch 26/100\n",
      "122/122 [==============================] - 16s 134ms/step - loss: 2.7236 - accuracy: 0.6639 - val_loss: 2.7276 - val_accuracy: 0.5909\n",
      "Epoch 27/100\n",
      "122/122 [==============================] - 17s 138ms/step - loss: 2.7286 - accuracy: 0.5656 - val_loss: 2.7267 - val_accuracy: 0.5909\n",
      "Epoch 28/100\n",
      "122/122 [==============================] - 17s 137ms/step - loss: 2.7224 - accuracy: 0.5820 - val_loss: 2.7258 - val_accuracy: 0.5909\n",
      "Epoch 29/100\n",
      "122/122 [==============================] - 16s 130ms/step - loss: 2.7199 - accuracy: 0.6393 - val_loss: 2.7251 - val_accuracy: 0.5909\n",
      "Epoch 30/100\n",
      "122/122 [==============================] - 16s 129ms/step - loss: 2.7305 - accuracy: 0.5902 - val_loss: 2.7244 - val_accuracy: 0.5909\n",
      "Epoch 31/100\n",
      "122/122 [==============================] - 16s 129ms/step - loss: 2.7287 - accuracy: 0.5656 - val_loss: 2.7238 - val_accuracy: 0.5909\n",
      "Epoch 32/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 2.7256 - accuracy: 0.5984 - val_loss: 2.7232 - val_accuracy: 0.5909\n",
      "Epoch 33/100\n",
      "122/122 [==============================] - 16s 134ms/step - loss: 2.7296 - accuracy: 0.5656 - val_loss: 2.7226 - val_accuracy: 0.5909\n",
      "Epoch 34/100\n",
      "122/122 [==============================] - 16s 129ms/step - loss: 2.7223 - accuracy: 0.5902 - val_loss: 2.7219 - val_accuracy: 0.5909\n",
      "Epoch 35/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 2.7331 - accuracy: 0.5738 - val_loss: 2.7212 - val_accuracy: 0.5909\n",
      "Epoch 36/100\n",
      "122/122 [==============================] - 17s 136ms/step - loss: 2.7276 - accuracy: 0.6066 - val_loss: 2.7206 - val_accuracy: 0.5909\n",
      "Epoch 37/100\n",
      "122/122 [==============================] - 17s 139ms/step - loss: 2.7272 - accuracy: 0.6311 - val_loss: 2.7200 - val_accuracy: 0.5909\n",
      "Epoch 38/100\n",
      "122/122 [==============================] - 17s 139ms/step - loss: 2.7200 - accuracy: 0.6311 - val_loss: 2.7193 - val_accuracy: 0.5909\n",
      "Epoch 39/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 2.7267 - accuracy: 0.6230 - val_loss: 2.7187 - val_accuracy: 0.5909\n",
      "Epoch 40/100\n",
      "122/122 [==============================] - 16s 129ms/step - loss: 2.7178 - accuracy: 0.6475 - val_loss: 2.7181 - val_accuracy: 0.5909\n",
      "Epoch 41/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 2.7272 - accuracy: 0.5574 - val_loss: 2.7175 - val_accuracy: 0.5909\n",
      "Epoch 42/100\n",
      "122/122 [==============================] - 17s 138ms/step - loss: 2.7236 - accuracy: 0.5902 - val_loss: 2.7170 - val_accuracy: 0.5909\n",
      "Epoch 43/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 2.7203 - accuracy: 0.6148 - val_loss: 2.7165 - val_accuracy: 0.5909\n",
      "Epoch 44/100\n",
      "122/122 [==============================] - 17s 139ms/step - loss: 2.7383 - accuracy: 0.5492 - val_loss: 2.7160 - val_accuracy: 0.5909\n",
      "Epoch 45/100\n",
      "122/122 [==============================] - 17s 139ms/step - loss: 2.7162 - accuracy: 0.6721 - val_loss: 2.7155 - val_accuracy: 0.5909\n",
      "Epoch 46/100\n",
      "122/122 [==============================] - 17s 136ms/step - loss: 2.7195 - accuracy: 0.6066 - val_loss: 2.7150 - val_accuracy: 0.5909\n",
      "Epoch 47/100\n",
      "122/122 [==============================] - 16s 134ms/step - loss: 2.7177 - accuracy: 0.6230 - val_loss: 2.7146 - val_accuracy: 0.5909\n",
      "Epoch 48/100\n",
      "122/122 [==============================] - 17s 139ms/step - loss: 2.7127 - accuracy: 0.5902 - val_loss: 2.7143 - val_accuracy: 0.5909\n",
      "Epoch 49/100\n",
      "122/122 [==============================] - 16s 135ms/step - loss: 2.7128 - accuracy: 0.6066 - val_loss: 2.7139 - val_accuracy: 0.5909\n",
      "Epoch 50/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 2.7256 - accuracy: 0.5656 - val_loss: 2.7136 - val_accuracy: 0.5909\n",
      "Epoch 51/100\n",
      "122/122 [==============================] - 16s 134ms/step - loss: 2.7203 - accuracy: 0.5984 - val_loss: 2.7133 - val_accuracy: 0.5909\n",
      "Epoch 52/100\n",
      "122/122 [==============================] - 17s 138ms/step - loss: 2.7193 - accuracy: 0.5984 - val_loss: 2.7130 - val_accuracy: 0.5909\n",
      "Epoch 53/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 2.7132 - accuracy: 0.6148 - val_loss: 2.7127 - val_accuracy: 0.5909\n",
      "Epoch 54/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 2.7109 - accuracy: 0.5820 - val_loss: 2.7123 - val_accuracy: 0.5909\n",
      "Epoch 55/100\n",
      "122/122 [==============================] - 16s 134ms/step - loss: 2.7099 - accuracy: 0.6066 - val_loss: 2.7120 - val_accuracy: 0.5909\n",
      "Epoch 56/100\n",
      "122/122 [==============================] - 16s 135ms/step - loss: 2.7068 - accuracy: 0.6066 - val_loss: 2.7117 - val_accuracy: 0.5909\n",
      "Epoch 57/100\n",
      "122/122 [==============================] - 16s 134ms/step - loss: 2.7100 - accuracy: 0.6148 - val_loss: 2.7113 - val_accuracy: 0.5909\n",
      "Epoch 58/100\n",
      "122/122 [==============================] - 16s 134ms/step - loss: 2.7156 - accuracy: 0.5738 - val_loss: 2.7109 - val_accuracy: 0.5909\n",
      "Epoch 59/100\n",
      "122/122 [==============================] - 16s 135ms/step - loss: 2.7150 - accuracy: 0.6066 - val_loss: 2.7106 - val_accuracy: 0.5909\n",
      "Epoch 60/100\n",
      "122/122 [==============================] - 17s 137ms/step - loss: 2.7106 - accuracy: 0.5820 - val_loss: 2.7102 - val_accuracy: 0.5909\n",
      "Epoch 61/100\n",
      "122/122 [==============================] - 17s 136ms/step - loss: 2.7103 - accuracy: 0.6066 - val_loss: 2.7098 - val_accuracy: 0.5909\n",
      "Epoch 62/100\n",
      "122/122 [==============================] - 16s 134ms/step - loss: 2.7045 - accuracy: 0.6311 - val_loss: 2.7094 - val_accuracy: 0.5909\n",
      "Epoch 63/100\n",
      "122/122 [==============================] - 16s 134ms/step - loss: 2.7163 - accuracy: 0.5656 - val_loss: 2.7090 - val_accuracy: 0.5909\n",
      "Epoch 64/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 2.7150 - accuracy: 0.5656 - val_loss: 2.7086 - val_accuracy: 0.5909\n",
      "Epoch 65/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 2.7091 - accuracy: 0.6393 - val_loss: 2.7083 - val_accuracy: 0.5909\n",
      "Epoch 66/100\n",
      "122/122 [==============================] - 16s 134ms/step - loss: 2.7075 - accuracy: 0.6066 - val_loss: 2.7080 - val_accuracy: 0.5909\n",
      "Epoch 67/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 2.7115 - accuracy: 0.5984 - val_loss: 2.7076 - val_accuracy: 0.5909\n",
      "Epoch 68/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 2.7200 - accuracy: 0.6230 - val_loss: 2.7072 - val_accuracy: 0.5909\n",
      "Epoch 69/100\n",
      "122/122 [==============================] - 16s 135ms/step - loss: 2.7000 - accuracy: 0.5984 - val_loss: 2.7068 - val_accuracy: 0.5909\n",
      "Epoch 70/100\n",
      "122/122 [==============================] - 16s 134ms/step - loss: 2.7179 - accuracy: 0.6066 - val_loss: 2.7065 - val_accuracy: 0.5909\n",
      "Epoch 71/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 2.6999 - accuracy: 0.6475 - val_loss: 2.7062 - val_accuracy: 0.5909\n",
      "Epoch 72/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 2.7096 - accuracy: 0.6393 - val_loss: 2.7059 - val_accuracy: 0.5909\n",
      "Epoch 73/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 2.7100 - accuracy: 0.5738 - val_loss: 2.7056 - val_accuracy: 0.5909\n",
      "Epoch 74/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 2.7193 - accuracy: 0.5820 - val_loss: 2.7053 - val_accuracy: 0.5909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 2.7039 - accuracy: 0.6148 - val_loss: 2.7050 - val_accuracy: 0.5909\n",
      "Epoch 76/100\n",
      "122/122 [==============================] - 16s 134ms/step - loss: 2.7103 - accuracy: 0.5902 - val_loss: 2.7047 - val_accuracy: 0.5909\n",
      "Epoch 77/100\n",
      "122/122 [==============================] - 17s 136ms/step - loss: 2.7102 - accuracy: 0.5984 - val_loss: 2.7045 - val_accuracy: 0.5909\n",
      "Epoch 78/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 2.7160 - accuracy: 0.5656 - val_loss: 2.7042 - val_accuracy: 0.5909\n",
      "Epoch 79/100\n",
      "122/122 [==============================] - 16s 135ms/step - loss: 2.7084 - accuracy: 0.6311 - val_loss: 2.7040 - val_accuracy: 0.5909\n",
      "Epoch 80/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 2.7116 - accuracy: 0.5984 - val_loss: 2.7038 - val_accuracy: 0.5909\n",
      "Epoch 81/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 2.7120 - accuracy: 0.6066 - val_loss: 2.7035 - val_accuracy: 0.5909\n",
      "Epoch 82/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 2.7147 - accuracy: 0.5410 - val_loss: 2.7033 - val_accuracy: 0.5909\n",
      "Epoch 83/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 2.7036 - accuracy: 0.6311 - val_loss: 2.7031 - val_accuracy: 0.5909\n",
      "Epoch 84/100\n",
      "122/122 [==============================] - 16s 134ms/step - loss: 2.7023 - accuracy: 0.6066 - val_loss: 2.7029 - val_accuracy: 0.5909\n",
      "Epoch 85/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 2.7047 - accuracy: 0.6148 - val_loss: 2.7028 - val_accuracy: 0.5909\n",
      "Epoch 86/100\n",
      "122/122 [==============================] - 16s 134ms/step - loss: 2.7028 - accuracy: 0.6311 - val_loss: 2.7025 - val_accuracy: 0.5909\n",
      "Epoch 87/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 2.7032 - accuracy: 0.6148 - val_loss: 2.7023 - val_accuracy: 0.5909\n",
      "Epoch 88/100\n",
      "122/122 [==============================] - 16s 134ms/step - loss: 2.7024 - accuracy: 0.5902 - val_loss: 2.7020 - val_accuracy: 0.5909\n",
      "Epoch 89/100\n",
      "122/122 [==============================] - 16s 134ms/step - loss: 2.7172 - accuracy: 0.5902 - val_loss: 2.7018 - val_accuracy: 0.5909\n",
      "Epoch 90/100\n",
      "122/122 [==============================] - 17s 136ms/step - loss: 2.7084 - accuracy: 0.5902 - val_loss: 2.7016 - val_accuracy: 0.5909\n",
      "Epoch 91/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 2.7044 - accuracy: 0.5984 - val_loss: 2.7014 - val_accuracy: 0.5909\n",
      "Epoch 92/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 2.6923 - accuracy: 0.6557 - val_loss: 2.7012 - val_accuracy: 0.5909\n",
      "Epoch 93/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 2.7056 - accuracy: 0.6230 - val_loss: 2.7010 - val_accuracy: 0.5909\n",
      "Epoch 94/100\n",
      "122/122 [==============================] - 16s 135ms/step - loss: 2.6996 - accuracy: 0.6311 - val_loss: 2.7008 - val_accuracy: 0.5909\n",
      "Epoch 95/100\n",
      "122/122 [==============================] - 16s 132ms/step - loss: 2.7087 - accuracy: 0.5820 - val_loss: 2.7006 - val_accuracy: 0.5909\n",
      "Epoch 96/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 2.7067 - accuracy: 0.5738 - val_loss: 2.7004 - val_accuracy: 0.5909\n",
      "Epoch 97/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 2.7085 - accuracy: 0.5984 - val_loss: 2.7002 - val_accuracy: 0.5909\n",
      "Epoch 98/100\n",
      "122/122 [==============================] - 16s 131ms/step - loss: 2.6869 - accuracy: 0.6475 - val_loss: 2.7000 - val_accuracy: 0.5909\n",
      "Epoch 99/100\n",
      "122/122 [==============================] - 17s 136ms/step - loss: 2.7190 - accuracy: 0.5574 - val_loss: 2.6998 - val_accuracy: 0.5909\n",
      "Epoch 100/100\n",
      "122/122 [==============================] - 16s 133ms/step - loss: 2.7077 - accuracy: 0.5738 - val_loss: 2.6997 - val_accuracy: 0.5909\n",
      "(170, 1363, 12)\n",
      "(170, 1)\n",
      "Training/Valid data shape: (144, 1363, 12)\n",
      "Test data shape: (26, 1363, 12)\n",
      "Training/Valid target shape: (144, 1)\n",
      "Test target shape: (26, 1)\n",
      "(122, 2)\n",
      "Train on 122 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "122/122 [==============================] - 21s 173ms/step - loss: 2.6594 - accuracy: 0.4426 - val_loss: 2.6138 - val_accuracy: 0.5909\n",
      "Epoch 2/100\n",
      "122/122 [==============================] - 19s 156ms/step - loss: 2.6120 - accuracy: 0.5738 - val_loss: 2.6065 - val_accuracy: 0.5909\n",
      "Epoch 3/100\n",
      "122/122 [==============================] - 19s 158ms/step - loss: 2.6027 - accuracy: 0.5574 - val_loss: 2.6021 - val_accuracy: 0.5455\n",
      "Epoch 4/100\n",
      "122/122 [==============================] - 19s 156ms/step - loss: 2.5968 - accuracy: 0.5164 - val_loss: 2.5992 - val_accuracy: 0.5909\n",
      "Epoch 5/100\n",
      "122/122 [==============================] - 19s 159ms/step - loss: 2.5862 - accuracy: 0.5820 - val_loss: 2.5973 - val_accuracy: 0.5909\n",
      "Epoch 6/100\n",
      "122/122 [==============================] - 19s 155ms/step - loss: 2.5788 - accuracy: 0.5902 - val_loss: 2.5955 - val_accuracy: 0.5909\n",
      "Epoch 7/100\n",
      "122/122 [==============================] - 19s 159ms/step - loss: 2.5740 - accuracy: 0.5902 - val_loss: 2.5937 - val_accuracy: 0.5909\n",
      "Epoch 8/100\n",
      "122/122 [==============================] - 20s 160ms/step - loss: 2.5778 - accuracy: 0.5574 - val_loss: 2.5920 - val_accuracy: 0.5909\n",
      "Epoch 9/100\n",
      "122/122 [==============================] - 19s 154ms/step - loss: 2.5761 - accuracy: 0.5738 - val_loss: 2.5906 - val_accuracy: 0.5909\n",
      "Epoch 10/100\n",
      "122/122 [==============================] - 20s 161ms/step - loss: 2.5688 - accuracy: 0.5820 - val_loss: 2.5892 - val_accuracy: 0.5909\n",
      "Epoch 11/100\n",
      "122/122 [==============================] - 19s 155ms/step - loss: 2.5650 - accuracy: 0.5984 - val_loss: 2.5879 - val_accuracy: 0.5909\n",
      "Epoch 12/100\n",
      "122/122 [==============================] - 19s 159ms/step - loss: 2.5578 - accuracy: 0.6230 - val_loss: 2.5867 - val_accuracy: 0.6364\n",
      "Epoch 13/100\n",
      "122/122 [==============================] - 19s 157ms/step - loss: 2.5642 - accuracy: 0.6148 - val_loss: 2.5857 - val_accuracy: 0.6364\n",
      "Epoch 14/100\n",
      "122/122 [==============================] - 19s 158ms/step - loss: 2.5626 - accuracy: 0.6393 - val_loss: 2.5849 - val_accuracy: 0.6364\n",
      "Epoch 15/100\n",
      "122/122 [==============================] - 19s 158ms/step - loss: 2.5541 - accuracy: 0.6393 - val_loss: 2.5841 - val_accuracy: 0.6364\n",
      "Epoch 16/100\n",
      "122/122 [==============================] - 19s 156ms/step - loss: 2.5586 - accuracy: 0.5656 - val_loss: 2.5833 - val_accuracy: 0.6364\n",
      "Epoch 17/100\n",
      "122/122 [==============================] - 20s 161ms/step - loss: 2.5634 - accuracy: 0.5902 - val_loss: 2.5825 - val_accuracy: 0.6364\n",
      "Epoch 18/100\n",
      "122/122 [==============================] - 19s 155ms/step - loss: 2.5639 - accuracy: 0.6066 - val_loss: 2.5818 - val_accuracy: 0.6364\n",
      "Epoch 19/100\n",
      "122/122 [==============================] - 19s 158ms/step - loss: 2.5651 - accuracy: 0.5738 - val_loss: 2.5811 - val_accuracy: 0.6364\n",
      "Epoch 20/100\n",
      "122/122 [==============================] - 21s 168ms/step - loss: 2.5544 - accuracy: 0.5984 - val_loss: 2.5807 - val_accuracy: 0.6364\n",
      "Epoch 21/100\n",
      "122/122 [==============================] - 19s 157ms/step - loss: 2.5543 - accuracy: 0.6066 - val_loss: 2.5802 - val_accuracy: 0.6364\n",
      "Epoch 22/100\n",
      "122/122 [==============================] - 20s 160ms/step - loss: 2.5588 - accuracy: 0.5984 - val_loss: 2.5798 - val_accuracy: 0.6364\n",
      "Epoch 23/100\n",
      "122/122 [==============================] - 19s 154ms/step - loss: 2.5495 - accuracy: 0.6311 - val_loss: 2.5792 - val_accuracy: 0.6364\n",
      "Epoch 24/100\n",
      "122/122 [==============================] - 20s 161ms/step - loss: 2.5515 - accuracy: 0.5820 - val_loss: 2.5786 - val_accuracy: 0.6364\n",
      "Epoch 25/100\n",
      "122/122 [==============================] - 19s 155ms/step - loss: 2.5495 - accuracy: 0.5984 - val_loss: 2.5780 - val_accuracy: 0.6364\n",
      "Epoch 26/100\n",
      "122/122 [==============================] - 19s 155ms/step - loss: 2.5504 - accuracy: 0.6148 - val_loss: 2.5775 - val_accuracy: 0.6364\n",
      "Epoch 27/100\n",
      "122/122 [==============================] - 19s 158ms/step - loss: 2.5535 - accuracy: 0.5820 - val_loss: 2.5771 - val_accuracy: 0.6364\n",
      "Epoch 28/100\n",
      "122/122 [==============================] - 19s 156ms/step - loss: 2.5504 - accuracy: 0.5656 - val_loss: 2.5765 - val_accuracy: 0.6364\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 20s 161ms/step - loss: 2.5468 - accuracy: 0.5902 - val_loss: 2.5760 - val_accuracy: 0.6364\n",
      "Epoch 30/100\n",
      "122/122 [==============================] - 19s 159ms/step - loss: 2.5681 - accuracy: 0.5492 - val_loss: 2.5755 - val_accuracy: 0.6364\n",
      "Epoch 31/100\n",
      "122/122 [==============================] - 19s 158ms/step - loss: 2.5515 - accuracy: 0.5820 - val_loss: 2.5750 - val_accuracy: 0.6364\n",
      "Epoch 32/100\n",
      "122/122 [==============================] - 19s 158ms/step - loss: 2.5394 - accuracy: 0.5984 - val_loss: 2.5745 - val_accuracy: 0.6364\n",
      "Epoch 33/100\n",
      "122/122 [==============================] - 19s 154ms/step - loss: 2.5399 - accuracy: 0.5902 - val_loss: 2.5741 - val_accuracy: 0.6364\n",
      "Epoch 34/100\n",
      "122/122 [==============================] - 19s 157ms/step - loss: 2.5585 - accuracy: 0.5738 - val_loss: 2.5737 - val_accuracy: 0.6364\n",
      "Epoch 35/100\n",
      "122/122 [==============================] - 19s 156ms/step - loss: 2.5503 - accuracy: 0.5984 - val_loss: 2.5732 - val_accuracy: 0.6364\n",
      "Epoch 36/100\n",
      "122/122 [==============================] - 20s 160ms/step - loss: 2.5541 - accuracy: 0.5738 - val_loss: 2.5727 - val_accuracy: 0.6364\n",
      "Epoch 37/100\n",
      "122/122 [==============================] - 19s 155ms/step - loss: 2.5467 - accuracy: 0.5820 - val_loss: 2.5724 - val_accuracy: 0.6364\n",
      "Epoch 38/100\n",
      "122/122 [==============================] - 19s 158ms/step - loss: 2.5527 - accuracy: 0.5984 - val_loss: 2.5721 - val_accuracy: 0.6364\n",
      "Epoch 39/100\n",
      "122/122 [==============================] - 19s 158ms/step - loss: 2.5422 - accuracy: 0.6311 - val_loss: 2.5719 - val_accuracy: 0.6364\n",
      "Epoch 40/100\n",
      "122/122 [==============================] - 19s 157ms/step - loss: 2.5423 - accuracy: 0.5902 - val_loss: 2.5716 - val_accuracy: 0.6364\n",
      "Epoch 41/100\n",
      "122/122 [==============================] - 20s 161ms/step - loss: 2.5508 - accuracy: 0.5656 - val_loss: 2.5713 - val_accuracy: 0.6364\n",
      "Epoch 42/100\n",
      "122/122 [==============================] - 19s 155ms/step - loss: 2.5489 - accuracy: 0.5902 - val_loss: 2.5711 - val_accuracy: 0.6364\n",
      "Epoch 43/100\n",
      "122/122 [==============================] - 19s 159ms/step - loss: 2.5556 - accuracy: 0.5656 - val_loss: 2.5709 - val_accuracy: 0.6364\n",
      "Epoch 44/100\n",
      "122/122 [==============================] - 19s 156ms/step - loss: 2.5461 - accuracy: 0.5820 - val_loss: 2.5707 - val_accuracy: 0.6364\n",
      "Epoch 45/100\n",
      "122/122 [==============================] - 19s 155ms/step - loss: 2.5391 - accuracy: 0.5984 - val_loss: 2.5705 - val_accuracy: 0.6364\n",
      "Epoch 46/100\n",
      "122/122 [==============================] - 20s 162ms/step - loss: 2.5373 - accuracy: 0.5984 - val_loss: 2.5703 - val_accuracy: 0.6364\n",
      "Epoch 47/100\n",
      "122/122 [==============================] - 19s 155ms/step - loss: 2.5434 - accuracy: 0.5492 - val_loss: 2.5701 - val_accuracy: 0.6364\n",
      "Epoch 48/100\n",
      "122/122 [==============================] - 19s 158ms/step - loss: 2.5321 - accuracy: 0.6148 - val_loss: 2.5698 - val_accuracy: 0.6364\n",
      "Epoch 49/100\n",
      "122/122 [==============================] - 19s 157ms/step - loss: 2.5414 - accuracy: 0.5574 - val_loss: 2.5696 - val_accuracy: 0.6364\n",
      "Epoch 50/100\n",
      "122/122 [==============================] - 19s 156ms/step - loss: 2.5385 - accuracy: 0.5656 - val_loss: 2.5694 - val_accuracy: 0.6364\n",
      "Epoch 51/100\n",
      "122/122 [==============================] - 19s 159ms/step - loss: 2.5367 - accuracy: 0.6311 - val_loss: 2.5691 - val_accuracy: 0.6364\n",
      "Epoch 52/100\n",
      "122/122 [==============================] - 19s 158ms/step - loss: 2.5395 - accuracy: 0.6148 - val_loss: 2.5688 - val_accuracy: 0.6364\n",
      "Epoch 53/100\n",
      "122/122 [==============================] - 20s 161ms/step - loss: 2.5484 - accuracy: 0.5902 - val_loss: 2.5685 - val_accuracy: 0.6364\n",
      "Epoch 54/100\n",
      "122/122 [==============================] - 19s 157ms/step - loss: 2.5330 - accuracy: 0.6230 - val_loss: 2.5682 - val_accuracy: 0.6364\n",
      "Epoch 55/100\n",
      "122/122 [==============================] - 19s 159ms/step - loss: 2.5381 - accuracy: 0.6230 - val_loss: 2.5680 - val_accuracy: 0.6364\n",
      "Epoch 56/100\n",
      "122/122 [==============================] - 19s 158ms/step - loss: 2.5234 - accuracy: 0.6311 - val_loss: 2.5677 - val_accuracy: 0.6364\n",
      "Epoch 57/100\n",
      "122/122 [==============================] - 19s 157ms/step - loss: 2.5395 - accuracy: 0.6066 - val_loss: 2.5675 - val_accuracy: 0.6364\n",
      "Epoch 58/100\n",
      "122/122 [==============================] - 19s 160ms/step - loss: 2.5486 - accuracy: 0.5656 - val_loss: 2.5672 - val_accuracy: 0.6364\n",
      "Epoch 59/100\n",
      "122/122 [==============================] - 19s 157ms/step - loss: 2.5465 - accuracy: 0.5738 - val_loss: 2.5670 - val_accuracy: 0.6364\n",
      "Epoch 60/100\n",
      "122/122 [==============================] - 20s 162ms/step - loss: 2.5397 - accuracy: 0.5820 - val_loss: 2.5668 - val_accuracy: 0.6364\n",
      "Epoch 61/100\n",
      "122/122 [==============================] - 19s 157ms/step - loss: 2.5367 - accuracy: 0.5902 - val_loss: 2.5666 - val_accuracy: 0.6364\n",
      "Epoch 62/100\n",
      "122/122 [==============================] - 19s 156ms/step - loss: 2.5467 - accuracy: 0.5492 - val_loss: 2.5663 - val_accuracy: 0.6364\n",
      "Epoch 63/100\n",
      "122/122 [==============================] - 20s 161ms/step - loss: 2.5394 - accuracy: 0.5984 - val_loss: 2.5661 - val_accuracy: 0.6364\n",
      "Epoch 64/100\n",
      "122/122 [==============================] - 19s 156ms/step - loss: 2.5387 - accuracy: 0.5656 - val_loss: 2.5658 - val_accuracy: 0.6364\n",
      "Epoch 65/100\n",
      "122/122 [==============================] - 19s 158ms/step - loss: 2.5451 - accuracy: 0.5902 - val_loss: 2.5656 - val_accuracy: 0.6364\n",
      "Epoch 66/100\n",
      "122/122 [==============================] - 20s 160ms/step - loss: 2.5306 - accuracy: 0.6230 - val_loss: 2.5653 - val_accuracy: 0.6364\n",
      "Epoch 67/100\n",
      "122/122 [==============================] - 19s 158ms/step - loss: 2.5410 - accuracy: 0.6148 - val_loss: 2.5651 - val_accuracy: 0.6364\n",
      "Epoch 68/100\n",
      "122/122 [==============================] - 19s 160ms/step - loss: 2.5227 - accuracy: 0.6475 - val_loss: 2.5649 - val_accuracy: 0.6364\n",
      "Epoch 69/100\n",
      "122/122 [==============================] - 19s 158ms/step - loss: 2.5357 - accuracy: 0.6393 - val_loss: 2.5646 - val_accuracy: 0.6364\n",
      "Epoch 70/100\n",
      "122/122 [==============================] - 20s 160ms/step - loss: 2.5418 - accuracy: 0.5656 - val_loss: 2.5644 - val_accuracy: 0.6364\n",
      "Epoch 71/100\n",
      "122/122 [==============================] - 19s 157ms/step - loss: 2.5355 - accuracy: 0.5984 - val_loss: 2.5642 - val_accuracy: 0.6364\n",
      "Epoch 72/100\n",
      "122/122 [==============================] - 20s 160ms/step - loss: 2.5339 - accuracy: 0.6066 - val_loss: 2.5641 - val_accuracy: 0.6364\n",
      "Epoch 73/100\n",
      "122/122 [==============================] - 19s 158ms/step - loss: 2.5343 - accuracy: 0.6230 - val_loss: 2.5639 - val_accuracy: 0.6364\n",
      "Epoch 74/100\n",
      "122/122 [==============================] - 19s 158ms/step - loss: 2.5338 - accuracy: 0.6066 - val_loss: 2.5637 - val_accuracy: 0.6364\n",
      "Epoch 75/100\n",
      "122/122 [==============================] - 20s 160ms/step - loss: 2.5264 - accuracy: 0.6066 - val_loss: 2.5635 - val_accuracy: 0.6364\n",
      "Epoch 76/100\n",
      "122/122 [==============================] - 19s 157ms/step - loss: 2.5455 - accuracy: 0.5902 - val_loss: 2.5633 - val_accuracy: 0.6364\n",
      "Epoch 77/100\n",
      "122/122 [==============================] - 20s 160ms/step - loss: 2.5353 - accuracy: 0.5656 - val_loss: 2.5632 - val_accuracy: 0.6364\n",
      "Epoch 78/100\n",
      "122/122 [==============================] - 19s 156ms/step - loss: 2.5446 - accuracy: 0.5820 - val_loss: 2.5630 - val_accuracy: 0.6364\n",
      "Epoch 79/100\n",
      "122/122 [==============================] - 19s 158ms/step - loss: 2.5377 - accuracy: 0.5902 - val_loss: 2.5629 - val_accuracy: 0.6364\n",
      "Epoch 80/100\n",
      "122/122 [==============================] - 20s 161ms/step - loss: 2.5376 - accuracy: 0.5820 - val_loss: 2.5628 - val_accuracy: 0.6364\n",
      "Epoch 81/100\n",
      "122/122 [==============================] - 19s 156ms/step - loss: 2.5257 - accuracy: 0.6393 - val_loss: 2.5626 - val_accuracy: 0.6364\n",
      "Epoch 82/100\n",
      "122/122 [==============================] - 19s 158ms/step - loss: 2.5298 - accuracy: 0.6066 - val_loss: 2.5625 - val_accuracy: 0.6364\n",
      "Epoch 83/100\n",
      "122/122 [==============================] - 20s 160ms/step - loss: 2.5343 - accuracy: 0.5656 - val_loss: 2.5623 - val_accuracy: 0.6364\n",
      "Epoch 84/100\n",
      "122/122 [==============================] - 19s 158ms/step - loss: 2.5315 - accuracy: 0.5820 - val_loss: 2.5621 - val_accuracy: 0.6364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "122/122 [==============================] - 19s 160ms/step - loss: 2.5381 - accuracy: 0.6066 - val_loss: 2.5619 - val_accuracy: 0.6364\n",
      "Epoch 86/100\n",
      "122/122 [==============================] - 20s 161ms/step - loss: 2.5269 - accuracy: 0.6066 - val_loss: 2.5617 - val_accuracy: 0.6364\n",
      "Epoch 87/100\n",
      "122/122 [==============================] - 19s 156ms/step - loss: 2.5354 - accuracy: 0.5902 - val_loss: 2.5615 - val_accuracy: 0.6364\n",
      "Epoch 88/100\n",
      "122/122 [==============================] - 19s 155ms/step - loss: 2.5232 - accuracy: 0.6311 - val_loss: 2.5613 - val_accuracy: 0.6364\n",
      "Epoch 89/100\n",
      "122/122 [==============================] - 19s 157ms/step - loss: 2.5373 - accuracy: 0.5738 - val_loss: 2.5611 - val_accuracy: 0.6364\n",
      "Epoch 90/100\n",
      "122/122 [==============================] - 19s 155ms/step - loss: 2.5293 - accuracy: 0.6148 - val_loss: 2.5609 - val_accuracy: 0.6364\n",
      "Epoch 91/100\n",
      "122/122 [==============================] - 19s 155ms/step - loss: 2.5285 - accuracy: 0.5820 - val_loss: 2.5607 - val_accuracy: 0.6364\n",
      "Epoch 92/100\n",
      "122/122 [==============================] - 19s 157ms/step - loss: 2.5401 - accuracy: 0.5328 - val_loss: 2.5605 - val_accuracy: 0.6364\n",
      "Epoch 93/100\n",
      "122/122 [==============================] - 19s 152ms/step - loss: 2.5224 - accuracy: 0.6230 - val_loss: 2.5603 - val_accuracy: 0.6364\n",
      "Epoch 94/100\n",
      "122/122 [==============================] - 20s 161ms/step - loss: 2.5334 - accuracy: 0.6066 - val_loss: 2.5602 - val_accuracy: 0.6364\n",
      "Epoch 95/100\n",
      "122/122 [==============================] - 19s 152ms/step - loss: 2.5235 - accuracy: 0.6066 - val_loss: 2.5600 - val_accuracy: 0.6364\n",
      "Epoch 96/100\n",
      "122/122 [==============================] - 19s 154ms/step - loss: 2.5303 - accuracy: 0.5656 - val_loss: 2.5599 - val_accuracy: 0.6364\n",
      "Epoch 97/100\n",
      "122/122 [==============================] - 19s 156ms/step - loss: 2.5393 - accuracy: 0.5574 - val_loss: 2.5597 - val_accuracy: 0.6364\n",
      "Epoch 98/100\n",
      "122/122 [==============================] - 19s 154ms/step - loss: 2.5219 - accuracy: 0.6639 - val_loss: 2.5596 - val_accuracy: 0.6364\n",
      "Epoch 99/100\n",
      "122/122 [==============================] - 20s 162ms/step - loss: 2.5236 - accuracy: 0.5984 - val_loss: 2.5594 - val_accuracy: 0.6364\n",
      "Epoch 100/100\n",
      "122/122 [==============================] - 19s 156ms/step - loss: 2.5225 - accuracy: 0.6066 - val_loss: 2.5593 - val_accuracy: 0.6364\n",
      "(170, 1363, 12)\n",
      "(170, 1)\n",
      "Training/Valid data shape: (144, 1363, 12)\n",
      "Test data shape: (26, 1363, 12)\n",
      "Training/Valid target shape: (144, 1)\n",
      "Test target shape: (26, 1)\n",
      "(122, 2)\n",
      "Train on 122 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "122/122 [==============================] - 23s 190ms/step - loss: 2.2724 - accuracy: 0.5000 - val_loss: 2.2348 - val_accuracy: 0.7273\n",
      "Epoch 2/100\n",
      "122/122 [==============================] - 21s 172ms/step - loss: 2.2442 - accuracy: 0.5902 - val_loss: 2.2245 - val_accuracy: 0.7273\n",
      "Epoch 3/100\n",
      "122/122 [==============================] - 21s 176ms/step - loss: 2.2334 - accuracy: 0.5902 - val_loss: 2.2181 - val_accuracy: 0.6364\n",
      "Epoch 4/100\n",
      "122/122 [==============================] - 21s 173ms/step - loss: 2.2271 - accuracy: 0.6066 - val_loss: 2.2136 - val_accuracy: 0.6818\n",
      "Epoch 5/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.2148 - accuracy: 0.6475 - val_loss: 2.2098 - val_accuracy: 0.6818\n",
      "Epoch 6/100\n",
      "122/122 [==============================] - 21s 171ms/step - loss: 2.2109 - accuracy: 0.6803 - val_loss: 2.2067 - val_accuracy: 0.6818\n",
      "Epoch 7/100\n",
      "122/122 [==============================] - 22s 177ms/step - loss: 2.2111 - accuracy: 0.6148 - val_loss: 2.2041 - val_accuracy: 0.6364\n",
      "Epoch 8/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.2152 - accuracy: 0.5820 - val_loss: 2.2020 - val_accuracy: 0.6364\n",
      "Epoch 9/100\n",
      "122/122 [==============================] - 21s 169ms/step - loss: 2.2130 - accuracy: 0.5902 - val_loss: 2.2000 - val_accuracy: 0.6364\n",
      "Epoch 10/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.2077 - accuracy: 0.5820 - val_loss: 2.1982 - val_accuracy: 0.6364\n",
      "Epoch 11/100\n",
      "122/122 [==============================] - 21s 170ms/step - loss: 2.1991 - accuracy: 0.6393 - val_loss: 2.1966 - val_accuracy: 0.6364\n",
      "Epoch 12/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.2059 - accuracy: 0.6148 - val_loss: 2.1952 - val_accuracy: 0.5909\n",
      "Epoch 13/100\n",
      "122/122 [==============================] - 21s 173ms/step - loss: 2.2094 - accuracy: 0.5984 - val_loss: 2.1938 - val_accuracy: 0.5909\n",
      "Epoch 14/100\n",
      "122/122 [==============================] - 21s 176ms/step - loss: 2.2037 - accuracy: 0.6066 - val_loss: 2.1926 - val_accuracy: 0.5909\n",
      "Epoch 15/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.2000 - accuracy: 0.6475 - val_loss: 2.1914 - val_accuracy: 0.5909\n",
      "Epoch 16/100\n",
      "122/122 [==============================] - 21s 170ms/step - loss: 2.1972 - accuracy: 0.6311 - val_loss: 2.1903 - val_accuracy: 0.5909\n",
      "Epoch 17/100\n",
      "122/122 [==============================] - 21s 175ms/step - loss: 2.1954 - accuracy: 0.6311 - val_loss: 2.1893 - val_accuracy: 0.5909\n",
      "Epoch 18/100\n",
      "122/122 [==============================] - 21s 170ms/step - loss: 2.1958 - accuracy: 0.6066 - val_loss: 2.1884 - val_accuracy: 0.5909\n",
      "Epoch 19/100\n",
      "122/122 [==============================] - 21s 172ms/step - loss: 2.2002 - accuracy: 0.6148 - val_loss: 2.1875 - val_accuracy: 0.5909\n",
      "Epoch 20/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.1948 - accuracy: 0.6393 - val_loss: 2.1867 - val_accuracy: 0.5909\n",
      "Epoch 21/100\n",
      "122/122 [==============================] - 21s 171ms/step - loss: 2.1941 - accuracy: 0.6148 - val_loss: 2.1859 - val_accuracy: 0.5909\n",
      "Epoch 22/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.1973 - accuracy: 0.6230 - val_loss: 2.1851 - val_accuracy: 0.5909\n",
      "Epoch 23/100\n",
      "122/122 [==============================] - 21s 172ms/step - loss: 2.1887 - accuracy: 0.6967 - val_loss: 2.1844 - val_accuracy: 0.6364\n",
      "Epoch 24/100\n",
      "122/122 [==============================] - 22s 177ms/step - loss: 2.1890 - accuracy: 0.6557 - val_loss: 2.1837 - val_accuracy: 0.6364\n",
      "Epoch 25/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.1928 - accuracy: 0.6393 - val_loss: 2.1830 - val_accuracy: 0.6364\n",
      "Epoch 26/100\n",
      "122/122 [==============================] - 21s 173ms/step - loss: 2.1917 - accuracy: 0.5984 - val_loss: 2.1823 - val_accuracy: 0.6364\n",
      "Epoch 27/100\n",
      "122/122 [==============================] - 21s 175ms/step - loss: 2.1904 - accuracy: 0.5820 - val_loss: 2.1817 - val_accuracy: 0.6364\n",
      "Epoch 28/100\n",
      "122/122 [==============================] - 21s 171ms/step - loss: 2.1858 - accuracy: 0.6148 - val_loss: 2.1811 - val_accuracy: 0.6364\n",
      "Epoch 29/100\n",
      "122/122 [==============================] - 21s 176ms/step - loss: 2.1924 - accuracy: 0.5820 - val_loss: 2.1805 - val_accuracy: 0.6364\n",
      "Epoch 30/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.1786 - accuracy: 0.7131 - val_loss: 2.1799 - val_accuracy: 0.6364\n",
      "Epoch 31/100\n",
      "122/122 [==============================] - 21s 175ms/step - loss: 2.1884 - accuracy: 0.6066 - val_loss: 2.1794 - val_accuracy: 0.6364\n",
      "Epoch 32/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.1900 - accuracy: 0.6639 - val_loss: 2.1789 - val_accuracy: 0.6364\n",
      "Epoch 33/100\n",
      "122/122 [==============================] - 21s 173ms/step - loss: 2.1844 - accuracy: 0.6557 - val_loss: 2.1784 - val_accuracy: 0.6364\n",
      "Epoch 34/100\n",
      "122/122 [==============================] - 21s 175ms/step - loss: 2.1791 - accuracy: 0.6393 - val_loss: 2.1779 - val_accuracy: 0.6364\n",
      "Epoch 35/100\n",
      "122/122 [==============================] - 21s 171ms/step - loss: 2.1854 - accuracy: 0.5902 - val_loss: 2.1774 - val_accuracy: 0.6364\n",
      "Epoch 36/100\n",
      "122/122 [==============================] - 21s 172ms/step - loss: 2.1833 - accuracy: 0.5902 - val_loss: 2.1769 - val_accuracy: 0.6364\n",
      "Epoch 37/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.1821 - accuracy: 0.6721 - val_loss: 2.1765 - val_accuracy: 0.6364\n",
      "Epoch 38/100\n",
      "122/122 [==============================] - 21s 176ms/step - loss: 2.1781 - accuracy: 0.6557 - val_loss: 2.1760 - val_accuracy: 0.6364\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 21s 173ms/step - loss: 2.1800 - accuracy: 0.5902 - val_loss: 2.1755 - val_accuracy: 0.6364\n",
      "Epoch 40/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.1769 - accuracy: 0.6393 - val_loss: 2.1751 - val_accuracy: 0.5909\n",
      "Epoch 41/100\n",
      "122/122 [==============================] - 22s 177ms/step - loss: 2.1803 - accuracy: 0.6475 - val_loss: 2.1746 - val_accuracy: 0.5909\n",
      "Epoch 42/100\n",
      "122/122 [==============================] - 21s 170ms/step - loss: 2.1740 - accuracy: 0.6557 - val_loss: 2.1742 - val_accuracy: 0.5909\n",
      "Epoch 43/100\n",
      "122/122 [==============================] - 21s 172ms/step - loss: 2.1774 - accuracy: 0.6393 - val_loss: 2.1738 - val_accuracy: 0.5909\n",
      "Epoch 44/100\n",
      "122/122 [==============================] - 22s 179ms/step - loss: 2.1794 - accuracy: 0.6557 - val_loss: 2.1734 - val_accuracy: 0.5909\n",
      "Epoch 45/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.1851 - accuracy: 0.6066 - val_loss: 2.1730 - val_accuracy: 0.5909\n",
      "Epoch 46/100\n",
      "122/122 [==============================] - 21s 175ms/step - loss: 2.1741 - accuracy: 0.6557 - val_loss: 2.1726 - val_accuracy: 0.5909\n",
      "Epoch 47/100\n",
      "122/122 [==============================] - 21s 173ms/step - loss: 2.1839 - accuracy: 0.6393 - val_loss: 2.1722 - val_accuracy: 0.5909\n",
      "Epoch 48/100\n",
      "122/122 [==============================] - 21s 175ms/step - loss: 2.1824 - accuracy: 0.6311 - val_loss: 2.1718 - val_accuracy: 0.5909\n",
      "Epoch 49/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.1746 - accuracy: 0.6148 - val_loss: 2.1715 - val_accuracy: 0.5909\n",
      "Epoch 50/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.1831 - accuracy: 0.5902 - val_loss: 2.1711 - val_accuracy: 0.5909\n",
      "Epoch 51/100\n",
      "122/122 [==============================] - 21s 175ms/step - loss: 2.1730 - accuracy: 0.6803 - val_loss: 2.1708 - val_accuracy: 0.5909\n",
      "Epoch 52/100\n",
      "122/122 [==============================] - 21s 170ms/step - loss: 2.1775 - accuracy: 0.6066 - val_loss: 2.1704 - val_accuracy: 0.5909\n",
      "Epoch 53/100\n",
      "122/122 [==============================] - 22s 179ms/step - loss: 2.1668 - accuracy: 0.6885 - val_loss: 2.1701 - val_accuracy: 0.5909\n",
      "Epoch 54/100\n",
      "122/122 [==============================] - 21s 176ms/step - loss: 2.1705 - accuracy: 0.6803 - val_loss: 2.1698 - val_accuracy: 0.5909\n",
      "Epoch 55/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.1732 - accuracy: 0.6475 - val_loss: 2.1695 - val_accuracy: 0.5909\n",
      "Epoch 56/100\n",
      "122/122 [==============================] - 21s 172ms/step - loss: 2.1783 - accuracy: 0.6393 - val_loss: 2.1692 - val_accuracy: 0.5909\n",
      "Epoch 57/100\n",
      "122/122 [==============================] - 21s 173ms/step - loss: 2.1775 - accuracy: 0.6230 - val_loss: 2.1689 - val_accuracy: 0.5909\n",
      "Epoch 58/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.1798 - accuracy: 0.6311 - val_loss: 2.1686 - val_accuracy: 0.5909\n",
      "Epoch 59/100\n",
      "122/122 [==============================] - 21s 169ms/step - loss: 2.1708 - accuracy: 0.6311 - val_loss: 2.1683 - val_accuracy: 0.5909\n",
      "Epoch 60/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.1719 - accuracy: 0.6393 - val_loss: 2.1680 - val_accuracy: 0.5909\n",
      "Epoch 61/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.1797 - accuracy: 0.5574 - val_loss: 2.1678 - val_accuracy: 0.5909\n",
      "Epoch 62/100\n",
      "122/122 [==============================] - 21s 170ms/step - loss: 2.1713 - accuracy: 0.6066 - val_loss: 2.1675 - val_accuracy: 0.5909\n",
      "Epoch 63/100\n",
      "122/122 [==============================] - 21s 172ms/step - loss: 2.1724 - accuracy: 0.6311 - val_loss: 2.1672 - val_accuracy: 0.5909\n",
      "Epoch 64/100\n",
      "122/122 [==============================] - 21s 171ms/step - loss: 2.1705 - accuracy: 0.6475 - val_loss: 2.1670 - val_accuracy: 0.5909\n",
      "Epoch 65/100\n",
      "122/122 [==============================] - 22s 176ms/step - loss: 2.1722 - accuracy: 0.6066 - val_loss: 2.1667 - val_accuracy: 0.5909\n",
      "Epoch 66/100\n",
      "122/122 [==============================] - 21s 170ms/step - loss: 2.1741 - accuracy: 0.6148 - val_loss: 2.1665 - val_accuracy: 0.5909\n",
      "Epoch 67/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.1674 - accuracy: 0.6803 - val_loss: 2.1662 - val_accuracy: 0.5909\n",
      "Epoch 68/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.1747 - accuracy: 0.5902 - val_loss: 2.1660 - val_accuracy: 0.5909\n",
      "Epoch 69/100\n",
      "122/122 [==============================] - 21s 171ms/step - loss: 2.1638 - accuracy: 0.6967 - val_loss: 2.1657 - val_accuracy: 0.5909\n",
      "Epoch 70/100\n",
      "122/122 [==============================] - 21s 172ms/step - loss: 2.1746 - accuracy: 0.6311 - val_loss: 2.1655 - val_accuracy: 0.5909\n",
      "Epoch 71/100\n",
      "122/122 [==============================] - 21s 172ms/step - loss: 2.1689 - accuracy: 0.6311 - val_loss: 2.1653 - val_accuracy: 0.5909\n",
      "Epoch 72/100\n",
      "122/122 [==============================] - 21s 175ms/step - loss: 2.1759 - accuracy: 0.6148 - val_loss: 2.1650 - val_accuracy: 0.5909\n",
      "Epoch 73/100\n",
      "122/122 [==============================] - 21s 175ms/step - loss: 2.1643 - accuracy: 0.7213 - val_loss: 2.1648 - val_accuracy: 0.5909\n",
      "Epoch 74/100\n",
      "122/122 [==============================] - 21s 173ms/step - loss: 2.1670 - accuracy: 0.6393 - val_loss: 2.1645 - val_accuracy: 0.5909\n",
      "Epoch 75/100\n",
      "122/122 [==============================] - 22s 176ms/step - loss: 2.1702 - accuracy: 0.6557 - val_loss: 2.1643 - val_accuracy: 0.5909\n",
      "Epoch 76/100\n",
      "122/122 [==============================] - 21s 171ms/step - loss: 2.1764 - accuracy: 0.6066 - val_loss: 2.1641 - val_accuracy: 0.5909\n",
      "Epoch 77/100\n",
      "122/122 [==============================] - 21s 175ms/step - loss: 2.1598 - accuracy: 0.6393 - val_loss: 2.1639 - val_accuracy: 0.5909\n",
      "Epoch 78/100\n",
      "122/122 [==============================] - 22s 178ms/step - loss: 2.1780 - accuracy: 0.6230 - val_loss: 2.1637 - val_accuracy: 0.5909\n",
      "Epoch 79/100\n",
      "122/122 [==============================] - 23s 186ms/step - loss: 2.1731 - accuracy: 0.6639 - val_loss: 2.1635 - val_accuracy: 0.5909\n",
      "Epoch 80/100\n",
      "122/122 [==============================] - 21s 173ms/step - loss: 2.1695 - accuracy: 0.6230 - val_loss: 2.1632 - val_accuracy: 0.5909\n",
      "Epoch 81/100\n",
      "122/122 [==============================] - 21s 172ms/step - loss: 2.1606 - accuracy: 0.6885 - val_loss: 2.1630 - val_accuracy: 0.5909\n",
      "Epoch 82/100\n",
      "122/122 [==============================] - 21s 176ms/step - loss: 2.1615 - accuracy: 0.6557 - val_loss: 2.1628 - val_accuracy: 0.5909\n",
      "Epoch 83/100\n",
      "122/122 [==============================] - 21s 170ms/step - loss: 2.1718 - accuracy: 0.6066 - val_loss: 2.1626 - val_accuracy: 0.5909\n",
      "Epoch 84/100\n",
      "122/122 [==============================] - 21s 172ms/step - loss: 2.1708 - accuracy: 0.6393 - val_loss: 2.1624 - val_accuracy: 0.5909\n",
      "Epoch 85/100\n",
      "122/122 [==============================] - 21s 176ms/step - loss: 2.1651 - accuracy: 0.6311 - val_loss: 2.1622 - val_accuracy: 0.5909\n",
      "Epoch 86/100\n",
      "122/122 [==============================] - 21s 172ms/step - loss: 2.1676 - accuracy: 0.6148 - val_loss: 2.1620 - val_accuracy: 0.5909\n",
      "Epoch 87/100\n",
      "122/122 [==============================] - 21s 173ms/step - loss: 2.1678 - accuracy: 0.6230 - val_loss: 2.1618 - val_accuracy: 0.5909\n",
      "Epoch 88/100\n",
      "122/122 [==============================] - 21s 173ms/step - loss: 2.1680 - accuracy: 0.6311 - val_loss: 2.1616 - val_accuracy: 0.5909\n",
      "Epoch 89/100\n",
      "122/122 [==============================] - 22s 176ms/step - loss: 2.1641 - accuracy: 0.6066 - val_loss: 2.1614 - val_accuracy: 0.5909\n",
      "Epoch 90/100\n",
      "122/122 [==============================] - 21s 170ms/step - loss: 2.1674 - accuracy: 0.6066 - val_loss: 2.1613 - val_accuracy: 0.5909\n",
      "Epoch 91/100\n",
      "122/122 [==============================] - 21s 175ms/step - loss: 2.1630 - accuracy: 0.6311 - val_loss: 2.1611 - val_accuracy: 0.5909\n",
      "Epoch 92/100\n",
      "122/122 [==============================] - 21s 175ms/step - loss: 2.1755 - accuracy: 0.5820 - val_loss: 2.1609 - val_accuracy: 0.5909\n",
      "Epoch 93/100\n",
      "122/122 [==============================] - 21s 171ms/step - loss: 2.1625 - accuracy: 0.6803 - val_loss: 2.1607 - val_accuracy: 0.5909\n",
      "Epoch 94/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.1683 - accuracy: 0.6393 - val_loss: 2.1605 - val_accuracy: 0.5909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "122/122 [==============================] - 21s 172ms/step - loss: 2.1655 - accuracy: 0.6721 - val_loss: 2.1604 - val_accuracy: 0.5909\n",
      "Epoch 96/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.1654 - accuracy: 0.6311 - val_loss: 2.1602 - val_accuracy: 0.5909\n",
      "Epoch 97/100\n",
      "122/122 [==============================] - 22s 178ms/step - loss: 2.1662 - accuracy: 0.6393 - val_loss: 2.1600 - val_accuracy: 0.5909\n",
      "Epoch 98/100\n",
      "122/122 [==============================] - 21s 171ms/step - loss: 2.1560 - accuracy: 0.6475 - val_loss: 2.1599 - val_accuracy: 0.5909\n",
      "Epoch 99/100\n",
      "122/122 [==============================] - 22s 177ms/step - loss: 2.1655 - accuracy: 0.6393 - val_loss: 2.1597 - val_accuracy: 0.5909\n",
      "Epoch 100/100\n",
      "122/122 [==============================] - 21s 174ms/step - loss: 2.1692 - accuracy: 0.6475 - val_loss: 2.1596 - val_accuracy: 0.5909\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import CuDNNLSTM\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "history_list = []\n",
    "for model_iter in range(5):\n",
    "    X=sio.loadmat('feat_vec_rnn.mat')\n",
    "    y=sio.loadmat('labels')\n",
    "\n",
    "    print(X_data.shape)\n",
    "    print(y_data.shape)\n",
    "\n",
    "    X_data=X['feat_vec_rnn']\n",
    "    X_data=np.transpose(X_data, (2, 0, 1))\n",
    "\n",
    "    y_data=y['labels']\n",
    "\n",
    "\n",
    "    X_train_val, X_test, y_train_val, y_test= train_test_split(X_data, y_data, test_size=0.15)\n",
    "\n",
    "    X_train, X_val, y_train, y_val= train_test_split(X_train_val, y_train_val, test_size=0.15)\n",
    "\n",
    "\n",
    "\n",
    "    print ('Training/Valid data shape: {}'.format(X_train_val.shape))\n",
    "    print ('Test data shape: {}'.format(X_test.shape))\n",
    "    print ('Training/Valid target shape: {}'.format(y_train_val.shape))\n",
    "    print ('Test target shape: {}'.format(y_test.shape))\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "    y_train = onehot_encoder.fit_transform(y_train)\n",
    "    y_val = onehot_encoder.fit_transform(y_val)\n",
    "    y_test = onehot_encoder.fit_transform(y_test)\n",
    "\n",
    "    print(y_train.shape)\n",
    "\n",
    "    n_samples = X_train.shape[0]  # number of data points\n",
    "    n_features = X_train.shape[1]  # dimension of feature vector for each sample\n",
    "    time_steps = X_train.shape[2] # how many samples across time were taken\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(50, dropout=0.2, recurrent_dropout=0.2, return_sequences=True, kernel_initializer='random_normal', input_shape=(n_features, time_steps)))\n",
    "\n",
    "    model.add(MaxPooling1D(pool_size=(2), strides=2, padding='valid', data_format=None))\n",
    "\n",
    "    model.add(LSTM(40, return_sequences=True))\n",
    "\n",
    "    model.add(LSTM(30, return_sequences=False))\n",
    "\n",
    "    model.add(Dense(2, activation='softmax', kernel_regularizer=regularizers.l1_l2(l1=0,l2=0.5)))\n",
    "\n",
    "    #sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    Adam=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, decay=0.99, amsgrad=False)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history=model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=100, epochs=100)\n",
    "    history_list.append(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60000001 0.60000001 0.58181819 0.60000001 0.60000001 0.60000001\n",
      " 0.59999999 0.59999999 0.59999999 0.59999999 0.59999999 0.59999999\n",
      " 0.59999999 0.59999999 0.59999999 0.59999999 0.59999999 0.59999999\n",
      " 0.59999999 0.59999999 0.59999999 0.59999999 0.60909091 0.60909091\n",
      " 0.60909091 0.60909091 0.60909091 0.60909091 0.60909091 0.60909091\n",
      " 0.60909091 0.60909091 0.60909091 0.60909091 0.60909091 0.60909091\n",
      " 0.60909091 0.60909091 0.60909091 0.59999999 0.59999999 0.59999999\n",
      " 0.59999999 0.59999999 0.59999999 0.59999999 0.59999999 0.59999999\n",
      " 0.59999999 0.59999999 0.59999999 0.59999999 0.59999999 0.59999999\n",
      " 0.59999999 0.59999999 0.59999999 0.59999999 0.59999999 0.59999999\n",
      " 0.59999999 0.59999999 0.59999999 0.59999999 0.59999999 0.59999999\n",
      " 0.59999999 0.59999999 0.59999999 0.59999999 0.59999999 0.59999999\n",
      " 0.59999999 0.59999999 0.59999999 0.59999999 0.59999999 0.59999999\n",
      " 0.59999999 0.59999999 0.59999999 0.59999999 0.59999999 0.59999999\n",
      " 0.59999999 0.59999999 0.59999999 0.59999999 0.59999999 0.59999999\n",
      " 0.59999999 0.59999999 0.59999999 0.59999999 0.59999999 0.59999999\n",
      " 0.59999999 0.59999999 0.59999999 0.59999999]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = []\n",
    "val_acc = []\n",
    "for history in history_list:\n",
    "    acc.append(history.history['accuracy'])\n",
    "    val_acc.append(history.history['val_accuracy'])\n",
    "acc = np.array(acc)\n",
    "val_acc = np.array(val_acc)\n",
    "avg_acc = np.mean(acc, axis=0)\n",
    "avg_val_acc = np.mean(val_acc, axis=0)\n",
    "print(avg_val_acc)\n",
    "\n",
    "plt.plot(avg_acc)\n",
    "plt.plot(avg_val_acc)\n",
    "plt.title('RNN Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import CuDNNLSTM\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "\n",
    "n_samples = X_train.shape[0]  # number of data points\n",
    "n_features = X_train.shape[1]  # dimension of feature vector for each sample\n",
    "time_steps = X_train.shape[2] # how many samples across time were taken\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(50, dropout=0.2, recurrent_dropout=0.2, return_sequences=True, kernel_initializer='random_normal', input_shape=(n_features, time_steps)))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=(2), strides=2, padding='valid', data_format=None))\n",
    "\n",
    "model.add(LSTM(40, return_sequences=True))\n",
    "\n",
    "model.add(LSTM(30, return_sequences=False))\n",
    "\n",
    "model.add(Dense(2, activation='softmax', kernel_regularizer=regularizers.l1_l2(l1=0,l2=0.5)))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "Adam=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, decay=0.99, amsgrad=False)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=100, epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Ajihnp6auW2"
   },
   "source": [
    "Get val and test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "LIU-beqBPHhb",
    "outputId": "aab5739b-1c58-4457-bd29-583a5dc983b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 53ms/step\n",
      "26/26 [==============================] - 1s 43ms/step\n",
      "Validation [loss, accuracy] is  [2.668516440825029, 0.6818181872367859]\n",
      "Test [loss, accuracy] is  [2.6850311022538405, 0.5769230723381042]\n"
     ]
    }
   ],
   "source": [
    "score_val = model.evaluate(X_val, y_val, batch_size=20)\n",
    "score_test = model.evaluate(X_test, y_test, batch_size=20)\n",
    "\n",
    "print('Validation [loss, accuracy] is ', score_val)\n",
    "print('Test [loss, accuracy] is ', score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN on MFCC raw data did pretty much nothing,v but CNN on statistics of raw data was able to classify (standard deviation and mean)\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('RNN Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ECE114_Speech_ML_project_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
