{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LoBdJNiyaMoC"
   },
   "source": [
    "Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "t6cfKHA7p3WP",
    "outputId": "90dcb3d6-6b1c-4834-85eb-5b9d08b5b61b"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9a9a89271754>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/gdrive/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vr1CQxtvaQTa"
   },
   "source": [
    "Change Directory to Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "NX_Gzz72p-bH",
    "outputId": "0da83b7a-5701-41a3-aa46-0c542200835b"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/content/gdrive/My Drive/ECE114F19_SpeechMLproj'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b7a43c5553e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#print(os.getcwd())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/gdrive/My Drive/ECE114F19_SpeechMLproj'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ls'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/content/gdrive/My Drive/ECE114F19_SpeechMLproj'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#print(os.getcwd())\n",
    "os.chdir('/content/gdrive/My Drive/ECE114F19_SpeechMLproj')\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gT9QjbtWaWa-"
   },
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "OD-odBBaw613",
    "outputId": "9d449e36-ab02-4c19-954d-d368849116a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (144, 12)\n",
      "Test data shape: (26, 12)\n",
      "Training/Valid target shape: (144, 1)\n",
      "Test target shape: (26, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X=sio.loadmat('feat_vec.mat')\n",
    "y=sio.loadmat('labels')\n",
    "\n",
    "X_data=X['feat_vec']\n",
    "y_data=y['labels']\n",
    "\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test= train_test_split(X_data, y_data, test_size=0.15)\n",
    "\n",
    "X_train, X_val, y_train, y_val= train_test_split(X_train_val, y_train_val, test_size=0.15)\n",
    "\n",
    "\n",
    "\n",
    "print ('Training/Valid data shape: {}'.format(X_train_val.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_val.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7UGP5EPvaYYJ"
   },
   "source": [
    "One-hot encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vQ6w6PHUzh_o",
    "outputId": "31198211-c366-4ab9-ab7e-d61cd0ad7b91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "\n",
    "\n",
    "y_train = onehot_encoder.fit_transform(y_train)\n",
    "y_val = onehot_encoder.fit_transform(y_val)\n",
    "y_test = onehot_encoder.fit_transform(y_test)\n",
    "\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qRV3K8M5acwm"
   },
   "source": [
    "Run Fully Connected (FeedForward) Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pKIRxQRg1PMn",
    "outputId": "836d17ad-22a3-444d-ae5c-ee1f0be230ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 122 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "122/122 [==============================] - 0s 2ms/step - loss: 0.7928 - accuracy: 0.4754 - val_loss: 0.6884 - val_accuracy: 0.5909\n",
      "Epoch 2/100\n",
      "122/122 [==============================] - 0s 73us/step - loss: 0.7790 - accuracy: 0.4754 - val_loss: 0.6830 - val_accuracy: 0.5909\n",
      "Epoch 3/100\n",
      "122/122 [==============================] - 0s 73us/step - loss: 0.7370 - accuracy: 0.4754 - val_loss: 0.6792 - val_accuracy: 0.5909\n",
      "Epoch 4/100\n",
      "122/122 [==============================] - 0s 73us/step - loss: 0.7676 - accuracy: 0.4590 - val_loss: 0.6773 - val_accuracy: 0.5909\n",
      "Epoch 5/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.7529 - accuracy: 0.4754 - val_loss: 0.6767 - val_accuracy: 0.5909\n",
      "Epoch 6/100\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.7176 - accuracy: 0.4672 - val_loss: 0.6772 - val_accuracy: 0.5909\n",
      "Epoch 7/100\n",
      "122/122 [==============================] - 0s 73us/step - loss: 0.7322 - accuracy: 0.4672 - val_loss: 0.6784 - val_accuracy: 0.5909\n",
      "Epoch 8/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7198 - accuracy: 0.4918 - val_loss: 0.6802 - val_accuracy: 0.5909\n",
      "Epoch 9/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.7207 - accuracy: 0.4590 - val_loss: 0.6826 - val_accuracy: 0.5909\n",
      "Epoch 10/100\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.7147 - accuracy: 0.4344 - val_loss: 0.6855 - val_accuracy: 0.5909\n",
      "Epoch 11/100\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.7056 - accuracy: 0.5082 - val_loss: 0.6883 - val_accuracy: 0.5909\n",
      "Epoch 12/100\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.7164 - accuracy: 0.4016 - val_loss: 0.6911 - val_accuracy: 0.5909\n",
      "Epoch 13/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7034 - accuracy: 0.4836 - val_loss: 0.6940 - val_accuracy: 0.4091\n",
      "Epoch 14/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.7020 - accuracy: 0.4344 - val_loss: 0.6968 - val_accuracy: 0.4091\n",
      "Epoch 15/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6936 - accuracy: 0.5656 - val_loss: 0.6990 - val_accuracy: 0.4091\n",
      "Epoch 16/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6939 - accuracy: 0.5492 - val_loss: 0.7006 - val_accuracy: 0.4091\n",
      "Epoch 17/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.7035 - accuracy: 0.5082 - val_loss: 0.7019 - val_accuracy: 0.4091\n",
      "Epoch 18/100\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6995 - accuracy: 0.5000 - val_loss: 0.7029 - val_accuracy: 0.4091\n",
      "Epoch 19/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6993 - accuracy: 0.4836 - val_loss: 0.7038 - val_accuracy: 0.4091\n",
      "Epoch 20/100\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6860 - accuracy: 0.5738 - val_loss: 0.7048 - val_accuracy: 0.4091\n",
      "Epoch 21/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6837 - accuracy: 0.5738 - val_loss: 0.7057 - val_accuracy: 0.4091\n",
      "Epoch 22/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.7076 - accuracy: 0.4918 - val_loss: 0.7065 - val_accuracy: 0.4091\n",
      "Epoch 23/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.7044 - accuracy: 0.5164 - val_loss: 0.7073 - val_accuracy: 0.4091\n",
      "Epoch 24/100\n",
      "122/122 [==============================] - 0s 81us/step - loss: 0.6968 - accuracy: 0.5246 - val_loss: 0.7078 - val_accuracy: 0.4091\n",
      "Epoch 25/100\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.7037 - accuracy: 0.5000 - val_loss: 0.7082 - val_accuracy: 0.4091\n",
      "Epoch 26/100\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6940 - accuracy: 0.4918 - val_loss: 0.7085 - val_accuracy: 0.4091\n",
      "Epoch 27/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6928 - accuracy: 0.5082 - val_loss: 0.7085 - val_accuracy: 0.4091\n",
      "Epoch 28/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6946 - accuracy: 0.5328 - val_loss: 0.7086 - val_accuracy: 0.4091\n",
      "Epoch 29/100\n",
      "122/122 [==============================] - 0s 73us/step - loss: 0.7046 - accuracy: 0.4426 - val_loss: 0.7089 - val_accuracy: 0.4091\n",
      "Epoch 30/100\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6976 - accuracy: 0.5410 - val_loss: 0.7095 - val_accuracy: 0.4091\n",
      "Epoch 31/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.7112 - accuracy: 0.4836 - val_loss: 0.7103 - val_accuracy: 0.4091\n",
      "Epoch 32/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6929 - accuracy: 0.5164 - val_loss: 0.7106 - val_accuracy: 0.4091\n",
      "Epoch 33/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.7174 - accuracy: 0.4426 - val_loss: 0.7105 - val_accuracy: 0.4091\n",
      "Epoch 34/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6936 - accuracy: 0.5246 - val_loss: 0.7099 - val_accuracy: 0.4091\n",
      "Epoch 35/100\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6759 - accuracy: 0.6066 - val_loss: 0.7092 - val_accuracy: 0.4091\n",
      "Epoch 36/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6953 - accuracy: 0.5164 - val_loss: 0.7085 - val_accuracy: 0.4091\n",
      "Epoch 37/100\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.7043 - accuracy: 0.5082 - val_loss: 0.7077 - val_accuracy: 0.4091\n",
      "Epoch 38/100\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.7114 - accuracy: 0.4508 - val_loss: 0.7068 - val_accuracy: 0.4091\n",
      "Epoch 39/100\n",
      "122/122 [==============================] - 0s 98us/step - loss: 0.6970 - accuracy: 0.5000 - val_loss: 0.7061 - val_accuracy: 0.4091\n",
      "Epoch 40/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6871 - accuracy: 0.5574 - val_loss: 0.7059 - val_accuracy: 0.4091\n",
      "Epoch 41/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6843 - accuracy: 0.5574 - val_loss: 0.7057 - val_accuracy: 0.4091\n",
      "Epoch 42/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.7116 - accuracy: 0.4672 - val_loss: 0.7056 - val_accuracy: 0.4091\n",
      "Epoch 43/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6979 - accuracy: 0.5246 - val_loss: 0.7055 - val_accuracy: 0.4091\n",
      "Epoch 44/100\n",
      "122/122 [==============================] - 0s 90us/step - loss: 0.6967 - accuracy: 0.4918 - val_loss: 0.7053 - val_accuracy: 0.4091\n",
      "Epoch 45/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6970 - accuracy: 0.5410 - val_loss: 0.7050 - val_accuracy: 0.4091\n",
      "Epoch 46/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6857 - accuracy: 0.5738 - val_loss: 0.7050 - val_accuracy: 0.4091\n",
      "Epoch 47/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6929 - accuracy: 0.5328 - val_loss: 0.7051 - val_accuracy: 0.4091\n",
      "Epoch 48/100\n",
      "122/122 [==============================] - 0s 73us/step - loss: 0.6965 - accuracy: 0.4836 - val_loss: 0.7054 - val_accuracy: 0.4091\n",
      "Epoch 49/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.7089 - accuracy: 0.4344 - val_loss: 0.7061 - val_accuracy: 0.4091\n",
      "Epoch 50/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6936 - accuracy: 0.4672 - val_loss: 0.7072 - val_accuracy: 0.4091\n",
      "Epoch 51/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7092 - accuracy: 0.4918 - val_loss: 0.7081 - val_accuracy: 0.4091\n",
      "Epoch 52/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7016 - accuracy: 0.4590 - val_loss: 0.7088 - val_accuracy: 0.4091\n",
      "Epoch 53/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.7078 - accuracy: 0.4918 - val_loss: 0.7091 - val_accuracy: 0.4091\n",
      "Epoch 54/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.7038 - accuracy: 0.5328 - val_loss: 0.7092 - val_accuracy: 0.4091\n",
      "Epoch 55/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6936 - accuracy: 0.5164 - val_loss: 0.7088 - val_accuracy: 0.4091\n",
      "Epoch 56/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6802 - accuracy: 0.5738 - val_loss: 0.7084 - val_accuracy: 0.4091\n",
      "Epoch 57/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6914 - accuracy: 0.5000 - val_loss: 0.7078 - val_accuracy: 0.4091\n",
      "Epoch 58/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6931 - accuracy: 0.5410 - val_loss: 0.7069 - val_accuracy: 0.4091\n",
      "Epoch 59/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6941 - accuracy: 0.5410 - val_loss: 0.7061 - val_accuracy: 0.4091\n",
      "Epoch 60/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6947 - accuracy: 0.5164 - val_loss: 0.7059 - val_accuracy: 0.4091\n",
      "Epoch 61/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6891 - accuracy: 0.5328 - val_loss: 0.7055 - val_accuracy: 0.4091\n",
      "Epoch 62/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6990 - accuracy: 0.5328 - val_loss: 0.7049 - val_accuracy: 0.4091\n",
      "Epoch 63/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7004 - accuracy: 0.4672 - val_loss: 0.7042 - val_accuracy: 0.4091\n",
      "Epoch 64/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6875 - accuracy: 0.5492 - val_loss: 0.7038 - val_accuracy: 0.4091\n",
      "Epoch 65/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6994 - accuracy: 0.4836 - val_loss: 0.7033 - val_accuracy: 0.4091\n",
      "Epoch 66/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7090 - accuracy: 0.4180 - val_loss: 0.7031 - val_accuracy: 0.4091\n",
      "Epoch 67/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6930 - accuracy: 0.4918 - val_loss: 0.7036 - val_accuracy: 0.4091\n",
      "Epoch 68/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6958 - accuracy: 0.5082 - val_loss: 0.7046 - val_accuracy: 0.4091\n",
      "Epoch 69/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7022 - accuracy: 0.5082 - val_loss: 0.7057 - val_accuracy: 0.4091\n",
      "Epoch 70/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6935 - accuracy: 0.5246 - val_loss: 0.7067 - val_accuracy: 0.4091\n",
      "Epoch 71/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6969 - accuracy: 0.4836 - val_loss: 0.7074 - val_accuracy: 0.4091\n",
      "Epoch 72/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6889 - accuracy: 0.5410 - val_loss: 0.7081 - val_accuracy: 0.4091\n",
      "Epoch 73/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6945 - accuracy: 0.5574 - val_loss: 0.7091 - val_accuracy: 0.4091\n",
      "Epoch 74/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7032 - accuracy: 0.4836 - val_loss: 0.7097 - val_accuracy: 0.4091\n",
      "Epoch 75/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6958 - accuracy: 0.5164 - val_loss: 0.7101 - val_accuracy: 0.4091\n",
      "Epoch 76/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7061 - accuracy: 0.4918 - val_loss: 0.7106 - val_accuracy: 0.4091\n",
      "Epoch 77/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7065 - accuracy: 0.4918 - val_loss: 0.7104 - val_accuracy: 0.4091\n",
      "Epoch 78/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.7036 - accuracy: 0.4590 - val_loss: 0.7098 - val_accuracy: 0.4091\n",
      "Epoch 79/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6967 - accuracy: 0.5082 - val_loss: 0.7093 - val_accuracy: 0.4091\n",
      "Epoch 80/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6984 - accuracy: 0.5328 - val_loss: 0.7090 - val_accuracy: 0.4091\n",
      "Epoch 81/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6980 - accuracy: 0.5328 - val_loss: 0.7083 - val_accuracy: 0.4091\n",
      "Epoch 82/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.7021 - accuracy: 0.4836 - val_loss: 0.7071 - val_accuracy: 0.4091\n",
      "Epoch 83/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6941 - accuracy: 0.5082 - val_loss: 0.7058 - val_accuracy: 0.4091\n",
      "Epoch 84/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7000 - accuracy: 0.5000 - val_loss: 0.7049 - val_accuracy: 0.4091\n",
      "Epoch 85/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6940 - accuracy: 0.5000 - val_loss: 0.7044 - val_accuracy: 0.4091\n",
      "Epoch 86/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6933 - accuracy: 0.5164 - val_loss: 0.7039 - val_accuracy: 0.4091\n",
      "Epoch 87/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7023 - accuracy: 0.4590 - val_loss: 0.7036 - val_accuracy: 0.4091\n",
      "Epoch 88/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6877 - accuracy: 0.5000 - val_loss: 0.7036 - val_accuracy: 0.4091\n",
      "Epoch 89/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6977 - accuracy: 0.5082 - val_loss: 0.7035 - val_accuracy: 0.4091\n",
      "Epoch 90/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6874 - accuracy: 0.5328 - val_loss: 0.7038 - val_accuracy: 0.4091\n",
      "Epoch 91/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6982 - accuracy: 0.5246 - val_loss: 0.7043 - val_accuracy: 0.4091\n",
      "Epoch 92/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.7005 - accuracy: 0.4262 - val_loss: 0.7050 - val_accuracy: 0.4091\n",
      "Epoch 93/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6867 - accuracy: 0.5656 - val_loss: 0.7061 - val_accuracy: 0.4091\n",
      "Epoch 94/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6948 - accuracy: 0.5000 - val_loss: 0.7069 - val_accuracy: 0.4091\n",
      "Epoch 95/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6958 - accuracy: 0.5164 - val_loss: 0.7073 - val_accuracy: 0.4091\n",
      "Epoch 96/100\n",
      "122/122 [==============================] - 0s 82us/step - loss: 0.6863 - accuracy: 0.5738 - val_loss: 0.7072 - val_accuracy: 0.4091\n",
      "Epoch 97/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6951 - accuracy: 0.5082 - val_loss: 0.7068 - val_accuracy: 0.4091\n",
      "Epoch 98/100\n",
      "122/122 [==============================] - 0s 74us/step - loss: 0.6951 - accuracy: 0.5246 - val_loss: 0.7066 - val_accuracy: 0.4091\n",
      "Epoch 99/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6950 - accuracy: 0.5082 - val_loss: 0.7065 - val_accuracy: 0.4091\n",
      "Epoch 100/100\n",
      "122/122 [==============================] - 0s 65us/step - loss: 0.6902 - accuracy: 0.5410 - val_loss: 0.7062 - val_accuracy: 0.4091\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(128, activation='sigmoid', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='sigmoid'))         \n",
    "\n",
    "Adam=optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=100, epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EebZ47qMakj3"
   },
   "source": [
    "Get validation and test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "yuWhLcrO5WFB",
    "outputId": "2c5a638d-d257-45de-8a83-97a219b52a09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 223us/step\n",
      "26/26 [==============================] - 0s 651us/step\n",
      "Validation [loss, accuracy] is  [0.6840943748300726, 0.5909091125835072]\n",
      "Test [loss, accuracy] is  [0.704076546889085, 0.4230769230769231]\n"
     ]
    }
   ],
   "source": [
    "score_val = model.evaluate(X_val, y_val, batch_size=20)\n",
    "score_test = model.evaluate(X_test, y_test, batch_size=20)\n",
    "\n",
    "print('Validation [loss, accuracy] is ', score_val)\n",
    "print('Test [loss, accuracy] is ', score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "89iHOYkaapTo"
   },
   "source": [
    "Get data formatted for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "colab_type": "code",
    "id": "7b397hiNG0pY",
    "outputId": "9d76a759-5637-4fea-dc0a-9da4c7fa323a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170, 12)\n",
      "(170, 1)\n",
      "Training/Valid data shape: (144, 1363, 12)\n",
      "Test data shape: (26, 1363, 12)\n",
      "Training/Valid target shape: (144, 1)\n",
      "Test target shape: (26, 1)\n",
      "(122, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X=sio.loadmat('feat_vec_rnn.mat')\n",
    "y=sio.loadmat('labels')\n",
    "\n",
    "print(X_data.shape)\n",
    "print(y_data.shape)\n",
    "\n",
    "X_data=X['feat_vec_rnn']\n",
    "X_data=np.transpose(X_data, (2, 0, 1))\n",
    "\n",
    "y_data=y['labels']\n",
    "\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test= train_test_split(X_data, y_data, test_size=0.15, random_state = 31)\n",
    "\n",
    "X_train, X_val, y_train, y_val= train_test_split(X_train_val, y_train_val, test_size=0.15, random_state = 21)\n",
    "\n",
    "\n",
    "\n",
    "print ('Training/Valid data shape: {}'.format(X_train_val.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_val.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "y_train = onehot_encoder.fit_transform(y_train)\n",
    "y_val = onehot_encoder.fit_transform(y_val)\n",
    "y_test = onehot_encoder.fit_transform(y_test)\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oXHr6znGasSG"
   },
   "source": [
    "Run LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "colab_type": "code",
    "id": "i3Nd9Djw7rZR",
    "outputId": "590b450e-cb6b-48d2-ca62-0e2dac752d69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170, 1363, 12)\n",
      "(170, 1)\n",
      "Training/Valid data shape: (144, 1363, 12)\n",
      "Test data shape: (26, 1363, 12)\n",
      "Training/Valid target shape: (144, 1)\n",
      "Test target shape: (26, 1)\n",
      "(122, 2)\n",
      "Train on 122 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "122/122 [==============================] - 8s 64ms/step - loss: 2.7812 - accuracy: 0.5410 - val_loss: 2.7330 - val_accuracy: 0.6364\n",
      "Epoch 2/100\n",
      "122/122 [==============================] - 7s 58ms/step - loss: 2.7397 - accuracy: 0.6230 - val_loss: 2.7204 - val_accuracy: 0.6364\n",
      "Epoch 3/100\n",
      "122/122 [==============================] - 6s 53ms/step - loss: 2.7354 - accuracy: 0.6066 - val_loss: 2.7128 - val_accuracy: 0.6818\n",
      "Epoch 4/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.7403 - accuracy: 0.5984 - val_loss: 2.7077 - val_accuracy: 0.6818\n",
      "Epoch 5/100\n",
      "122/122 [==============================] - 7s 53ms/step - loss: 2.7091 - accuracy: 0.6066 - val_loss: 2.7035 - val_accuracy: 0.6818\n",
      "Epoch 6/100\n",
      "122/122 [==============================] - 6s 53ms/step - loss: 2.7226 - accuracy: 0.6148 - val_loss: 2.6999 - val_accuracy: 0.6818\n",
      "Epoch 7/100\n",
      "122/122 [==============================] - 6s 53ms/step - loss: 2.7078 - accuracy: 0.6230 - val_loss: 2.6969 - val_accuracy: 0.6818\n",
      "Epoch 8/100\n",
      "122/122 [==============================] - 7s 54ms/step - loss: 2.7138 - accuracy: 0.5902 - val_loss: 2.6943 - val_accuracy: 0.6818\n",
      "Epoch 9/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.7069 - accuracy: 0.6393 - val_loss: 2.6919 - val_accuracy: 0.6818\n",
      "Epoch 10/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6975 - accuracy: 0.6311 - val_loss: 2.6898 - val_accuracy: 0.6818\n",
      "Epoch 11/100\n",
      "122/122 [==============================] - 7s 57ms/step - loss: 2.7047 - accuracy: 0.6148 - val_loss: 2.6879 - val_accuracy: 0.6818\n",
      "Epoch 12/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.7014 - accuracy: 0.5902 - val_loss: 2.6863 - val_accuracy: 0.6818\n",
      "Epoch 13/100\n",
      "122/122 [==============================] - 7s 58ms/step - loss: 2.7120 - accuracy: 0.5820 - val_loss: 2.6847 - val_accuracy: 0.6818\n",
      "Epoch 14/100\n",
      "122/122 [==============================] - 7s 54ms/step - loss: 2.6901 - accuracy: 0.6066 - val_loss: 2.6833 - val_accuracy: 0.6818\n",
      "Epoch 15/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6964 - accuracy: 0.6393 - val_loss: 2.6819 - val_accuracy: 0.6818\n",
      "Epoch 16/100\n",
      "122/122 [==============================] - 7s 57ms/step - loss: 2.6971 - accuracy: 0.6230 - val_loss: 2.6806 - val_accuracy: 0.6818\n",
      "Epoch 17/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6897 - accuracy: 0.6475 - val_loss: 2.6793 - val_accuracy: 0.6818\n",
      "Epoch 18/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6877 - accuracy: 0.6557 - val_loss: 2.6782 - val_accuracy: 0.6818\n",
      "Epoch 19/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6904 - accuracy: 0.6066 - val_loss: 2.6771 - val_accuracy: 0.6818\n",
      "Epoch 20/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6912 - accuracy: 0.6066 - val_loss: 2.6761 - val_accuracy: 0.6818\n",
      "Epoch 21/100\n",
      "122/122 [==============================] - 7s 57ms/step - loss: 2.6969 - accuracy: 0.5820 - val_loss: 2.6751 - val_accuracy: 0.6818\n",
      "Epoch 22/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.6899 - accuracy: 0.6230 - val_loss: 2.6741 - val_accuracy: 0.6818\n",
      "Epoch 23/100\n",
      "122/122 [==============================] - 7s 58ms/step - loss: 2.6890 - accuracy: 0.6066 - val_loss: 2.6732 - val_accuracy: 0.6818\n",
      "Epoch 24/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6913 - accuracy: 0.6393 - val_loss: 2.6723 - val_accuracy: 0.6818\n",
      "Epoch 25/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6804 - accuracy: 0.6148 - val_loss: 2.6714 - val_accuracy: 0.6818\n",
      "Epoch 26/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6897 - accuracy: 0.6311 - val_loss: 2.6706 - val_accuracy: 0.6818\n",
      "Epoch 27/100\n",
      "122/122 [==============================] - 7s 54ms/step - loss: 2.7019 - accuracy: 0.6148 - val_loss: 2.6699 - val_accuracy: 0.6818\n",
      "Epoch 28/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6826 - accuracy: 0.6311 - val_loss: 2.6692 - val_accuracy: 0.6818\n",
      "Epoch 29/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6907 - accuracy: 0.5984 - val_loss: 2.6685 - val_accuracy: 0.6818\n",
      "Epoch 30/100\n",
      "122/122 [==============================] - 7s 54ms/step - loss: 2.6923 - accuracy: 0.5656 - val_loss: 2.6678 - val_accuracy: 0.6818\n",
      "Epoch 31/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6883 - accuracy: 0.5902 - val_loss: 2.6672 - val_accuracy: 0.6818\n",
      "Epoch 32/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6842 - accuracy: 0.6557 - val_loss: 2.6666 - val_accuracy: 0.6818\n",
      "Epoch 33/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6970 - accuracy: 0.5984 - val_loss: 2.6661 - val_accuracy: 0.6818\n",
      "Epoch 34/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6903 - accuracy: 0.6148 - val_loss: 2.6656 - val_accuracy: 0.6818\n",
      "Epoch 35/100\n",
      "122/122 [==============================] - 7s 58ms/step - loss: 2.6700 - accuracy: 0.6721 - val_loss: 2.6650 - val_accuracy: 0.6818\n",
      "Epoch 36/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6849 - accuracy: 0.5902 - val_loss: 2.6645 - val_accuracy: 0.6818\n",
      "Epoch 37/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6693 - accuracy: 0.6721 - val_loss: 2.6640 - val_accuracy: 0.6818\n",
      "Epoch 38/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6841 - accuracy: 0.5902 - val_loss: 2.6634 - val_accuracy: 0.6818\n",
      "Epoch 39/100\n",
      "122/122 [==============================] - 7s 58ms/step - loss: 2.6770 - accuracy: 0.6311 - val_loss: 2.6629 - val_accuracy: 0.7273\n",
      "Epoch 40/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6726 - accuracy: 0.6311 - val_loss: 2.6624 - val_accuracy: 0.7273\n",
      "Epoch 41/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6855 - accuracy: 0.5902 - val_loss: 2.6619 - val_accuracy: 0.7273\n",
      "Epoch 42/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6747 - accuracy: 0.5984 - val_loss: 2.6614 - val_accuracy: 0.7273\n",
      "Epoch 43/100\n",
      "122/122 [==============================] - 7s 61ms/step - loss: 2.6720 - accuracy: 0.6230 - val_loss: 2.6610 - val_accuracy: 0.7273\n",
      "Epoch 44/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6888 - accuracy: 0.5656 - val_loss: 2.6605 - val_accuracy: 0.7273\n",
      "Epoch 45/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6865 - accuracy: 0.5738 - val_loss: 2.6601 - val_accuracy: 0.7273\n",
      "Epoch 46/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6832 - accuracy: 0.6230 - val_loss: 2.6597 - val_accuracy: 0.7273\n",
      "Epoch 47/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6853 - accuracy: 0.5820 - val_loss: 2.6593 - val_accuracy: 0.7273\n",
      "Epoch 48/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6839 - accuracy: 0.6230 - val_loss: 2.6589 - val_accuracy: 0.7273\n",
      "Epoch 49/100\n",
      "122/122 [==============================] - 7s 57ms/step - loss: 2.6777 - accuracy: 0.6639 - val_loss: 2.6585 - val_accuracy: 0.7273\n",
      "Epoch 50/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6811 - accuracy: 0.5984 - val_loss: 2.6582 - val_accuracy: 0.7273\n",
      "Epoch 51/100\n",
      "122/122 [==============================] - 7s 58ms/step - loss: 2.6926 - accuracy: 0.6066 - val_loss: 2.6578 - val_accuracy: 0.7273\n",
      "Epoch 52/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6852 - accuracy: 0.5738 - val_loss: 2.6575 - val_accuracy: 0.7273\n",
      "Epoch 53/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6784 - accuracy: 0.5820 - val_loss: 2.6571 - val_accuracy: 0.7273\n",
      "Epoch 54/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6772 - accuracy: 0.6557 - val_loss: 2.6568 - val_accuracy: 0.7273\n",
      "Epoch 55/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6715 - accuracy: 0.6557 - val_loss: 2.6565 - val_accuracy: 0.7273\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6715 - accuracy: 0.6393 - val_loss: 2.6562 - val_accuracy: 0.7273\n",
      "Epoch 57/100\n",
      "122/122 [==============================] - 7s 58ms/step - loss: 2.6688 - accuracy: 0.6311 - val_loss: 2.6558 - val_accuracy: 0.7273\n",
      "Epoch 58/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6862 - accuracy: 0.5902 - val_loss: 2.6555 - val_accuracy: 0.7273\n",
      "Epoch 59/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6931 - accuracy: 0.5738 - val_loss: 2.6552 - val_accuracy: 0.7273\n",
      "Epoch 60/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6715 - accuracy: 0.6066 - val_loss: 2.6548 - val_accuracy: 0.7273\n",
      "Epoch 61/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6644 - accuracy: 0.6475 - val_loss: 2.6545 - val_accuracy: 0.7273\n",
      "Epoch 62/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6660 - accuracy: 0.6311 - val_loss: 2.6543 - val_accuracy: 0.7273\n",
      "Epoch 63/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6703 - accuracy: 0.6393 - val_loss: 2.6539 - val_accuracy: 0.7273\n",
      "Epoch 64/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6670 - accuracy: 0.6721 - val_loss: 2.6536 - val_accuracy: 0.7273\n",
      "Epoch 65/100\n",
      "122/122 [==============================] - 7s 57ms/step - loss: 2.6751 - accuracy: 0.5984 - val_loss: 2.6533 - val_accuracy: 0.7273\n",
      "Epoch 66/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6789 - accuracy: 0.6230 - val_loss: 2.6530 - val_accuracy: 0.7273\n",
      "Epoch 67/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6752 - accuracy: 0.6393 - val_loss: 2.6528 - val_accuracy: 0.7273\n",
      "Epoch 68/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6802 - accuracy: 0.6393 - val_loss: 2.6525 - val_accuracy: 0.7273\n",
      "Epoch 69/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6723 - accuracy: 0.6557 - val_loss: 2.6522 - val_accuracy: 0.7273\n",
      "Epoch 70/100\n",
      "122/122 [==============================] - 7s 57ms/step - loss: 2.6719 - accuracy: 0.6475 - val_loss: 2.6520 - val_accuracy: 0.7273\n",
      "Epoch 71/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6782 - accuracy: 0.6475 - val_loss: 2.6517 - val_accuracy: 0.7273\n",
      "Epoch 72/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6807 - accuracy: 0.6230 - val_loss: 2.6514 - val_accuracy: 0.7273\n",
      "Epoch 73/100\n",
      "122/122 [==============================] - 7s 57ms/step - loss: 2.6744 - accuracy: 0.5902 - val_loss: 2.6512 - val_accuracy: 0.7273\n",
      "Epoch 74/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6763 - accuracy: 0.6311 - val_loss: 2.6509 - val_accuracy: 0.7273\n",
      "Epoch 75/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6772 - accuracy: 0.6311 - val_loss: 2.6507 - val_accuracy: 0.7273\n",
      "Epoch 76/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6634 - accuracy: 0.6066 - val_loss: 2.6504 - val_accuracy: 0.7273\n",
      "Epoch 77/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6573 - accuracy: 0.6230 - val_loss: 2.6502 - val_accuracy: 0.7273\n",
      "Epoch 78/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6718 - accuracy: 0.5984 - val_loss: 2.6500 - val_accuracy: 0.7273\n",
      "Epoch 79/100\n",
      "122/122 [==============================] - 7s 58ms/step - loss: 2.6621 - accuracy: 0.6475 - val_loss: 2.6497 - val_accuracy: 0.7273\n",
      "Epoch 80/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6801 - accuracy: 0.6066 - val_loss: 2.6495 - val_accuracy: 0.7273\n",
      "Epoch 81/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6800 - accuracy: 0.6393 - val_loss: 2.6493 - val_accuracy: 0.7273\n",
      "Epoch 82/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6628 - accuracy: 0.6148 - val_loss: 2.6490 - val_accuracy: 0.7273\n",
      "Epoch 83/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6731 - accuracy: 0.6066 - val_loss: 2.6488 - val_accuracy: 0.7273\n",
      "Epoch 84/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6563 - accuracy: 0.6475 - val_loss: 2.6486 - val_accuracy: 0.7273\n",
      "Epoch 85/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6691 - accuracy: 0.5820 - val_loss: 2.6483 - val_accuracy: 0.7273\n",
      "Epoch 86/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6788 - accuracy: 0.5902 - val_loss: 2.6481 - val_accuracy: 0.7273\n",
      "Epoch 87/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6691 - accuracy: 0.6311 - val_loss: 2.6479 - val_accuracy: 0.7273\n",
      "Epoch 88/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6644 - accuracy: 0.5820 - val_loss: 2.6477 - val_accuracy: 0.7273\n",
      "Epoch 89/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6645 - accuracy: 0.6393 - val_loss: 2.6474 - val_accuracy: 0.7273\n",
      "Epoch 90/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6745 - accuracy: 0.5902 - val_loss: 2.6472 - val_accuracy: 0.7273\n",
      "Epoch 91/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6554 - accuracy: 0.6393 - val_loss: 2.6470 - val_accuracy: 0.7273\n",
      "Epoch 92/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6650 - accuracy: 0.6475 - val_loss: 2.6468 - val_accuracy: 0.7273\n",
      "Epoch 93/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6734 - accuracy: 0.6148 - val_loss: 2.6466 - val_accuracy: 0.7273\n",
      "Epoch 94/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6699 - accuracy: 0.6066 - val_loss: 2.6464 - val_accuracy: 0.7273\n",
      "Epoch 95/100\n",
      "122/122 [==============================] - 7s 57ms/step - loss: 2.6787 - accuracy: 0.6230 - val_loss: 2.6462 - val_accuracy: 0.7273\n",
      "Epoch 96/100\n",
      "122/122 [==============================] - 7s 57ms/step - loss: 2.6656 - accuracy: 0.6311 - val_loss: 2.6460 - val_accuracy: 0.7273\n",
      "Epoch 97/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6658 - accuracy: 0.5984 - val_loss: 2.6458 - val_accuracy: 0.7273\n",
      "Epoch 98/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.6528 - accuracy: 0.6557 - val_loss: 2.6456 - val_accuracy: 0.7273\n",
      "Epoch 99/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6781 - accuracy: 0.6230 - val_loss: 2.6454 - val_accuracy: 0.7273\n",
      "Epoch 100/100\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 2.6692 - accuracy: 0.5902 - val_loss: 2.6453 - val_accuracy: 0.7273\n",
      "(170, 1363, 12)\n",
      "(170, 1)\n",
      "Training/Valid data shape: (144, 1363, 12)\n",
      "Test data shape: (26, 1363, 12)\n",
      "Training/Valid target shape: (144, 1)\n",
      "Test target shape: (26, 1)\n",
      "(122, 2)\n",
      "Train on 122 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "122/122 [==============================] - 9s 73ms/step - loss: 2.4889 - accuracy: 0.5246 - val_loss: 2.4599 - val_accuracy: 0.5455\n",
      "Epoch 2/100\n",
      "122/122 [==============================] - 7s 57ms/step - loss: 2.4481 - accuracy: 0.5738 - val_loss: 2.4480 - val_accuracy: 0.6364\n",
      "Epoch 3/100\n",
      "122/122 [==============================] - 7s 56ms/step - loss: 2.4402 - accuracy: 0.6066 - val_loss: 2.4405 - val_accuracy: 0.6364\n",
      "Epoch 4/100\n",
      "122/122 [==============================] - 7s 57ms/step - loss: 2.4471 - accuracy: 0.5820 - val_loss: 2.4349 - val_accuracy: 0.6818\n",
      "Epoch 5/100\n",
      "122/122 [==============================] - 7s 58ms/step - loss: 2.4394 - accuracy: 0.6148 - val_loss: 2.4308 - val_accuracy: 0.6818\n",
      "Epoch 6/100\n",
      "122/122 [==============================] - 7s 58ms/step - loss: 2.4393 - accuracy: 0.5656 - val_loss: 2.4275 - val_accuracy: 0.6818\n",
      "Epoch 7/100\n",
      "122/122 [==============================] - 7s 57ms/step - loss: 2.4327 - accuracy: 0.5902 - val_loss: 2.4248 - val_accuracy: 0.6818\n",
      "Epoch 8/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.4364 - accuracy: 0.5492 - val_loss: 2.4223 - val_accuracy: 0.6818\n",
      "Epoch 9/100\n",
      "122/122 [==============================] - 7s 57ms/step - loss: 2.4201 - accuracy: 0.6311 - val_loss: 2.4202 - val_accuracy: 0.6818\n",
      "Epoch 10/100\n",
      "122/122 [==============================] - 7s 58ms/step - loss: 2.4214 - accuracy: 0.6066 - val_loss: 2.4182 - val_accuracy: 0.6818\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 7s 58ms/step - loss: 2.4165 - accuracy: 0.6475 - val_loss: 2.4164 - val_accuracy: 0.6818\n",
      "Epoch 12/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.4169 - accuracy: 0.5984 - val_loss: 2.4148 - val_accuracy: 0.6818\n",
      "Epoch 13/100\n",
      "122/122 [==============================] - 8s 62ms/step - loss: 2.4242 - accuracy: 0.5902 - val_loss: 2.4133 - val_accuracy: 0.6818\n",
      "Epoch 14/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.4202 - accuracy: 0.6230 - val_loss: 2.4119 - val_accuracy: 0.6818\n",
      "Epoch 15/100\n",
      "122/122 [==============================] - 7s 58ms/step - loss: 2.4062 - accuracy: 0.6475 - val_loss: 2.4106 - val_accuracy: 0.6818\n",
      "Epoch 16/100\n",
      "122/122 [==============================] - 7s 58ms/step - loss: 2.4220 - accuracy: 0.5902 - val_loss: 2.4094 - val_accuracy: 0.6818\n",
      "Epoch 17/100\n",
      "122/122 [==============================] - 7s 61ms/step - loss: 2.3983 - accuracy: 0.6311 - val_loss: 2.4082 - val_accuracy: 0.6818\n",
      "Epoch 18/100\n",
      "122/122 [==============================] - 7s 58ms/step - loss: 2.4126 - accuracy: 0.6066 - val_loss: 2.4071 - val_accuracy: 0.6818\n",
      "Epoch 19/100\n",
      "122/122 [==============================] - 7s 57ms/step - loss: 2.4251 - accuracy: 0.5984 - val_loss: 2.4061 - val_accuracy: 0.6818\n",
      "Epoch 20/100\n",
      "122/122 [==============================] - 7s 58ms/step - loss: 2.4074 - accuracy: 0.6066 - val_loss: 2.4052 - val_accuracy: 0.6818\n",
      "Epoch 21/100\n",
      "122/122 [==============================] - 7s 58ms/step - loss: 2.4182 - accuracy: 0.5984 - val_loss: 2.4044 - val_accuracy: 0.6818\n",
      "Epoch 22/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.4130 - accuracy: 0.6230 - val_loss: 2.4036 - val_accuracy: 0.6818\n",
      "Epoch 23/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.4149 - accuracy: 0.5902 - val_loss: 2.4029 - val_accuracy: 0.6818\n",
      "Epoch 24/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.4131 - accuracy: 0.5820 - val_loss: 2.4022 - val_accuracy: 0.6818\n",
      "Epoch 25/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.4169 - accuracy: 0.6230 - val_loss: 2.4014 - val_accuracy: 0.6818\n",
      "Epoch 26/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.4052 - accuracy: 0.5902 - val_loss: 2.4008 - val_accuracy: 0.6818\n",
      "Epoch 27/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.3994 - accuracy: 0.6393 - val_loss: 2.4001 - val_accuracy: 0.6818\n",
      "Epoch 28/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.4044 - accuracy: 0.6475 - val_loss: 2.3995 - val_accuracy: 0.6818\n",
      "Epoch 29/100\n",
      "122/122 [==============================] - 7s 61ms/step - loss: 2.3946 - accuracy: 0.6393 - val_loss: 2.3988 - val_accuracy: 0.6818\n",
      "Epoch 30/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.4150 - accuracy: 0.6066 - val_loss: 2.3983 - val_accuracy: 0.6818\n",
      "Epoch 31/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.4105 - accuracy: 0.5820 - val_loss: 2.3977 - val_accuracy: 0.6818\n",
      "Epoch 32/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.4052 - accuracy: 0.6148 - val_loss: 2.3972 - val_accuracy: 0.6818\n",
      "Epoch 33/100\n",
      "122/122 [==============================] - 7s 61ms/step - loss: 2.4042 - accuracy: 0.5984 - val_loss: 2.3966 - val_accuracy: 0.6818\n",
      "Epoch 34/100\n",
      "122/122 [==============================] - 7s 61ms/step - loss: 2.4154 - accuracy: 0.5984 - val_loss: 2.3961 - val_accuracy: 0.6818\n",
      "Epoch 35/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.4091 - accuracy: 0.6066 - val_loss: 2.3956 - val_accuracy: 0.6818\n",
      "Epoch 36/100\n",
      "122/122 [==============================] - 8s 65ms/step - loss: 2.4155 - accuracy: 0.5984 - val_loss: 2.3951 - val_accuracy: 0.6818\n",
      "Epoch 37/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.4129 - accuracy: 0.5984 - val_loss: 2.3947 - val_accuracy: 0.6818\n",
      "Epoch 38/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.4045 - accuracy: 0.5902 - val_loss: 2.3942 - val_accuracy: 0.6818\n",
      "Epoch 39/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.3924 - accuracy: 0.6148 - val_loss: 2.3938 - val_accuracy: 0.6818\n",
      "Epoch 40/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.4151 - accuracy: 0.5902 - val_loss: 2.3933 - val_accuracy: 0.6818\n",
      "Epoch 41/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3996 - accuracy: 0.6230 - val_loss: 2.3929 - val_accuracy: 0.6818\n",
      "Epoch 42/100\n",
      "122/122 [==============================] - 7s 61ms/step - loss: 2.3962 - accuracy: 0.6557 - val_loss: 2.3925 - val_accuracy: 0.6818\n",
      "Epoch 43/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3855 - accuracy: 0.6148 - val_loss: 2.3920 - val_accuracy: 0.6818\n",
      "Epoch 44/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.4023 - accuracy: 0.6393 - val_loss: 2.3916 - val_accuracy: 0.6818\n",
      "Epoch 45/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3989 - accuracy: 0.6148 - val_loss: 2.3912 - val_accuracy: 0.6818\n",
      "Epoch 46/100\n",
      "122/122 [==============================] - 8s 62ms/step - loss: 2.3979 - accuracy: 0.5984 - val_loss: 2.3907 - val_accuracy: 0.7273\n",
      "Epoch 47/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.3991 - accuracy: 0.5738 - val_loss: 2.3903 - val_accuracy: 0.7273\n",
      "Epoch 48/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.4001 - accuracy: 0.6148 - val_loss: 2.3899 - val_accuracy: 0.7273\n",
      "Epoch 49/100\n",
      "122/122 [==============================] - 7s 58ms/step - loss: 2.3992 - accuracy: 0.6311 - val_loss: 2.3896 - val_accuracy: 0.7273\n",
      "Epoch 50/100\n",
      "122/122 [==============================] - 7s 61ms/step - loss: 2.4053 - accuracy: 0.5738 - val_loss: 2.3892 - val_accuracy: 0.7273\n",
      "Epoch 51/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.4047 - accuracy: 0.5984 - val_loss: 2.3888 - val_accuracy: 0.7273\n",
      "Epoch 52/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3990 - accuracy: 0.6148 - val_loss: 2.3885 - val_accuracy: 0.7273\n",
      "Epoch 53/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3983 - accuracy: 0.6230 - val_loss: 2.3881 - val_accuracy: 0.7273\n",
      "Epoch 54/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.3983 - accuracy: 0.5984 - val_loss: 2.3878 - val_accuracy: 0.7273\n",
      "Epoch 55/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.4004 - accuracy: 0.6066 - val_loss: 2.3875 - val_accuracy: 0.7273\n",
      "Epoch 56/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.3967 - accuracy: 0.6148 - val_loss: 2.3872 - val_accuracy: 0.7273\n",
      "Epoch 57/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3940 - accuracy: 0.6148 - val_loss: 2.3869 - val_accuracy: 0.7273\n",
      "Epoch 58/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.4040 - accuracy: 0.6230 - val_loss: 2.3866 - val_accuracy: 0.7273\n",
      "Epoch 59/100\n",
      "122/122 [==============================] - 7s 61ms/step - loss: 2.3839 - accuracy: 0.5984 - val_loss: 2.3863 - val_accuracy: 0.7273\n",
      "Epoch 60/100\n",
      "122/122 [==============================] - 7s 61ms/step - loss: 2.4000 - accuracy: 0.5984 - val_loss: 2.3860 - val_accuracy: 0.7273\n",
      "Epoch 61/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.4061 - accuracy: 0.5902 - val_loss: 2.3858 - val_accuracy: 0.7273\n",
      "Epoch 62/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3915 - accuracy: 0.5902 - val_loss: 2.3855 - val_accuracy: 0.7273\n",
      "Epoch 63/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3949 - accuracy: 0.5902 - val_loss: 2.3853 - val_accuracy: 0.7273\n",
      "Epoch 64/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.4054 - accuracy: 0.5656 - val_loss: 2.3850 - val_accuracy: 0.7273\n",
      "Epoch 65/100\n",
      "122/122 [==============================] - 7s 58ms/step - loss: 2.3981 - accuracy: 0.6230 - val_loss: 2.3847 - val_accuracy: 0.7273\n",
      "Epoch 66/100\n",
      "122/122 [==============================] - 7s 61ms/step - loss: 2.3880 - accuracy: 0.6721 - val_loss: 2.3845 - val_accuracy: 0.7273\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3983 - accuracy: 0.6148 - val_loss: 2.3842 - val_accuracy: 0.7273\n",
      "Epoch 68/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.4051 - accuracy: 0.5492 - val_loss: 2.3840 - val_accuracy: 0.7273\n",
      "Epoch 69/100\n",
      "122/122 [==============================] - 8s 62ms/step - loss: 2.3951 - accuracy: 0.6148 - val_loss: 2.3838 - val_accuracy: 0.7273\n",
      "Epoch 70/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3987 - accuracy: 0.5984 - val_loss: 2.3835 - val_accuracy: 0.7273\n",
      "Epoch 71/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.3957 - accuracy: 0.5820 - val_loss: 2.3833 - val_accuracy: 0.7273\n",
      "Epoch 72/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3854 - accuracy: 0.6311 - val_loss: 2.3830 - val_accuracy: 0.7273\n",
      "Epoch 73/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.3827 - accuracy: 0.6885 - val_loss: 2.3828 - val_accuracy: 0.7273\n",
      "Epoch 74/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3967 - accuracy: 0.5902 - val_loss: 2.3825 - val_accuracy: 0.7273\n",
      "Epoch 75/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.4034 - accuracy: 0.5902 - val_loss: 2.3823 - val_accuracy: 0.7273\n",
      "Epoch 76/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.4001 - accuracy: 0.5656 - val_loss: 2.3820 - val_accuracy: 0.7273\n",
      "Epoch 77/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.3884 - accuracy: 0.6148 - val_loss: 2.3818 - val_accuracy: 0.7273\n",
      "Epoch 78/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3937 - accuracy: 0.6475 - val_loss: 2.3816 - val_accuracy: 0.7273\n",
      "Epoch 79/100\n",
      "122/122 [==============================] - 7s 61ms/step - loss: 2.3866 - accuracy: 0.6311 - val_loss: 2.3814 - val_accuracy: 0.7273\n",
      "Epoch 80/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3875 - accuracy: 0.5902 - val_loss: 2.3811 - val_accuracy: 0.7273\n",
      "Epoch 81/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.3932 - accuracy: 0.5984 - val_loss: 2.3809 - val_accuracy: 0.7273\n",
      "Epoch 82/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3985 - accuracy: 0.5820 - val_loss: 2.3807 - val_accuracy: 0.7273\n",
      "Epoch 83/100\n",
      "122/122 [==============================] - 8s 63ms/step - loss: 2.3922 - accuracy: 0.6311 - val_loss: 2.3805 - val_accuracy: 0.7273\n",
      "Epoch 84/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3881 - accuracy: 0.6393 - val_loss: 2.3803 - val_accuracy: 0.7273\n",
      "Epoch 85/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.3877 - accuracy: 0.6230 - val_loss: 2.3801 - val_accuracy: 0.7273\n",
      "Epoch 86/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3744 - accuracy: 0.6475 - val_loss: 2.3798 - val_accuracy: 0.7273\n",
      "Epoch 87/100\n",
      "122/122 [==============================] - 8s 63ms/step - loss: 2.4009 - accuracy: 0.6066 - val_loss: 2.3796 - val_accuracy: 0.7273\n",
      "Epoch 88/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3960 - accuracy: 0.6066 - val_loss: 2.3794 - val_accuracy: 0.7273\n",
      "Epoch 89/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.3862 - accuracy: 0.6066 - val_loss: 2.3792 - val_accuracy: 0.7273\n",
      "Epoch 90/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3864 - accuracy: 0.6393 - val_loss: 2.3790 - val_accuracy: 0.7273\n",
      "Epoch 91/100\n",
      "122/122 [==============================] - 8s 62ms/step - loss: 2.3955 - accuracy: 0.5574 - val_loss: 2.3788 - val_accuracy: 0.7273\n",
      "Epoch 92/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.3900 - accuracy: 0.6066 - val_loss: 2.3786 - val_accuracy: 0.7273\n",
      "Epoch 93/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3875 - accuracy: 0.6311 - val_loss: 2.3784 - val_accuracy: 0.7273\n",
      "Epoch 94/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.3840 - accuracy: 0.6475 - val_loss: 2.3782 - val_accuracy: 0.7273\n",
      "Epoch 95/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3714 - accuracy: 0.6639 - val_loss: 2.3780 - val_accuracy: 0.7273\n",
      "Epoch 96/100\n",
      "122/122 [==============================] - 7s 61ms/step - loss: 2.3858 - accuracy: 0.6230 - val_loss: 2.3779 - val_accuracy: 0.7273\n",
      "Epoch 97/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3836 - accuracy: 0.6066 - val_loss: 2.3777 - val_accuracy: 0.7273\n",
      "Epoch 98/100\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 2.3932 - accuracy: 0.6311 - val_loss: 2.3775 - val_accuracy: 0.7273\n",
      "Epoch 99/100\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 2.3844 - accuracy: 0.6230 - val_loss: 2.3773 - val_accuracy: 0.7273\n",
      "Epoch 100/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.3899 - accuracy: 0.5902 - val_loss: 2.3771 - val_accuracy: 0.7273\n",
      "(170, 1363, 12)\n",
      "(170, 1)\n",
      "Training/Valid data shape: (144, 1363, 12)\n",
      "Test data shape: (26, 1363, 12)\n",
      "Training/Valid target shape: (144, 1)\n",
      "Test target shape: (26, 1)\n",
      "(122, 2)\n",
      "Train on 122 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "122/122 [==============================] - 10s 80ms/step - loss: 2.5595 - accuracy: 0.5492 - val_loss: 2.5166 - val_accuracy: 0.5909\n",
      "Epoch 2/100\n",
      "122/122 [==============================] - 8s 68ms/step - loss: 2.5137 - accuracy: 0.6230 - val_loss: 2.5010 - val_accuracy: 0.6364\n",
      "Epoch 3/100\n",
      "122/122 [==============================] - 8s 66ms/step - loss: 2.5078 - accuracy: 0.5492 - val_loss: 2.4921 - val_accuracy: 0.6364\n",
      "Epoch 4/100\n",
      "122/122 [==============================] - 8s 67ms/step - loss: 2.4989 - accuracy: 0.6148 - val_loss: 2.4856 - val_accuracy: 0.6364\n",
      "Epoch 5/100\n",
      "122/122 [==============================] - 8s 67ms/step - loss: 2.4975 - accuracy: 0.6066 - val_loss: 2.4810 - val_accuracy: 0.6364\n",
      "Epoch 6/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4859 - accuracy: 0.6557 - val_loss: 2.4771 - val_accuracy: 0.6364\n",
      "Epoch 7/100\n",
      "122/122 [==============================] - 8s 68ms/step - loss: 2.4960 - accuracy: 0.5820 - val_loss: 2.4739 - val_accuracy: 0.6364\n",
      "Epoch 8/100\n",
      "122/122 [==============================] - 8s 68ms/step - loss: 2.4882 - accuracy: 0.6148 - val_loss: 2.4712 - val_accuracy: 0.6364\n",
      "Epoch 9/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4775 - accuracy: 0.6311 - val_loss: 2.4688 - val_accuracy: 0.6364\n",
      "Epoch 10/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4704 - accuracy: 0.6148 - val_loss: 2.4666 - val_accuracy: 0.6364\n",
      "Epoch 11/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4879 - accuracy: 0.5984 - val_loss: 2.4647 - val_accuracy: 0.6364\n",
      "Epoch 12/100\n",
      "122/122 [==============================] - 8s 68ms/step - loss: 2.4737 - accuracy: 0.6066 - val_loss: 2.4631 - val_accuracy: 0.6364\n",
      "Epoch 13/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4797 - accuracy: 0.6475 - val_loss: 2.4616 - val_accuracy: 0.6364\n",
      "Epoch 14/100\n",
      "122/122 [==============================] - 9s 71ms/step - loss: 2.4820 - accuracy: 0.5820 - val_loss: 2.4604 - val_accuracy: 0.6364\n",
      "Epoch 15/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4775 - accuracy: 0.6557 - val_loss: 2.4593 - val_accuracy: 0.6364\n",
      "Epoch 16/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4690 - accuracy: 0.6066 - val_loss: 2.4581 - val_accuracy: 0.6364\n",
      "Epoch 17/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4757 - accuracy: 0.6230 - val_loss: 2.4571 - val_accuracy: 0.6364\n",
      "Epoch 18/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4646 - accuracy: 0.6311 - val_loss: 2.4561 - val_accuracy: 0.6364\n",
      "Epoch 19/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4707 - accuracy: 0.5820 - val_loss: 2.4551 - val_accuracy: 0.6364\n",
      "Epoch 20/100\n",
      "122/122 [==============================] - 8s 68ms/step - loss: 2.4747 - accuracy: 0.6393 - val_loss: 2.4542 - val_accuracy: 0.6364\n",
      "Epoch 21/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4690 - accuracy: 0.6230 - val_loss: 2.4534 - val_accuracy: 0.6364\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 8s 70ms/step - loss: 2.4796 - accuracy: 0.5902 - val_loss: 2.4526 - val_accuracy: 0.6364\n",
      "Epoch 23/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4721 - accuracy: 0.6230 - val_loss: 2.4519 - val_accuracy: 0.6364\n",
      "Epoch 24/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4710 - accuracy: 0.6148 - val_loss: 2.4511 - val_accuracy: 0.6364\n",
      "Epoch 25/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4613 - accuracy: 0.6066 - val_loss: 2.4503 - val_accuracy: 0.6364\n",
      "Epoch 26/100\n",
      "122/122 [==============================] - 8s 68ms/step - loss: 2.4520 - accuracy: 0.6803 - val_loss: 2.4496 - val_accuracy: 0.6364\n",
      "Epoch 27/100\n",
      "122/122 [==============================] - 8s 70ms/step - loss: 2.4664 - accuracy: 0.6311 - val_loss: 2.4488 - val_accuracy: 0.6364\n",
      "Epoch 28/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4724 - accuracy: 0.5984 - val_loss: 2.4480 - val_accuracy: 0.6364\n",
      "Epoch 29/100\n",
      "122/122 [==============================] - 8s 68ms/step - loss: 2.4514 - accuracy: 0.6311 - val_loss: 2.4473 - val_accuracy: 0.6364\n",
      "Epoch 30/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4702 - accuracy: 0.5902 - val_loss: 2.4467 - val_accuracy: 0.6364\n",
      "Epoch 31/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4671 - accuracy: 0.5984 - val_loss: 2.4460 - val_accuracy: 0.6364\n",
      "Epoch 32/100\n",
      "122/122 [==============================] - 8s 70ms/step - loss: 2.4560 - accuracy: 0.6066 - val_loss: 2.4454 - val_accuracy: 0.6818\n",
      "Epoch 33/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4539 - accuracy: 0.6557 - val_loss: 2.4448 - val_accuracy: 0.6818\n",
      "Epoch 34/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4573 - accuracy: 0.6066 - val_loss: 2.4442 - val_accuracy: 0.6818\n",
      "Epoch 35/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4616 - accuracy: 0.5902 - val_loss: 2.4437 - val_accuracy: 0.6818\n",
      "Epoch 36/100\n",
      "122/122 [==============================] - 8s 68ms/step - loss: 2.4635 - accuracy: 0.6066 - val_loss: 2.4432 - val_accuracy: 0.6818\n",
      "Epoch 37/100\n",
      "122/122 [==============================] - 8s 68ms/step - loss: 2.4613 - accuracy: 0.5984 - val_loss: 2.4427 - val_accuracy: 0.6818\n",
      "Epoch 38/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4527 - accuracy: 0.6557 - val_loss: 2.4422 - val_accuracy: 0.6818\n",
      "Epoch 39/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4640 - accuracy: 0.5656 - val_loss: 2.4417 - val_accuracy: 0.7273\n",
      "Epoch 40/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4603 - accuracy: 0.5820 - val_loss: 2.4413 - val_accuracy: 0.7273\n",
      "Epoch 41/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4440 - accuracy: 0.6557 - val_loss: 2.4408 - val_accuracy: 0.7273\n",
      "Epoch 42/100\n",
      "122/122 [==============================] - 8s 70ms/step - loss: 2.4661 - accuracy: 0.6393 - val_loss: 2.4404 - val_accuracy: 0.7273\n",
      "Epoch 43/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4620 - accuracy: 0.6066 - val_loss: 2.4399 - val_accuracy: 0.7273\n",
      "Epoch 44/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4776 - accuracy: 0.5574 - val_loss: 2.4395 - val_accuracy: 0.7273\n",
      "Epoch 45/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4625 - accuracy: 0.6066 - val_loss: 2.4392 - val_accuracy: 0.7273\n",
      "Epoch 46/100\n",
      "122/122 [==============================] - 8s 68ms/step - loss: 2.4607 - accuracy: 0.6393 - val_loss: 2.4388 - val_accuracy: 0.7273\n",
      "Epoch 47/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4630 - accuracy: 0.5410 - val_loss: 2.4384 - val_accuracy: 0.7273\n",
      "Epoch 48/100\n",
      "122/122 [==============================] - 8s 68ms/step - loss: 2.4456 - accuracy: 0.6639 - val_loss: 2.4381 - val_accuracy: 0.7273\n",
      "Epoch 49/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4459 - accuracy: 0.6475 - val_loss: 2.4377 - val_accuracy: 0.7273\n",
      "Epoch 50/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4605 - accuracy: 0.5984 - val_loss: 2.4373 - val_accuracy: 0.7273\n",
      "Epoch 51/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4435 - accuracy: 0.6885 - val_loss: 2.4370 - val_accuracy: 0.7273\n",
      "Epoch 52/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4461 - accuracy: 0.6230 - val_loss: 2.4366 - val_accuracy: 0.7273\n",
      "Epoch 53/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4774 - accuracy: 0.5410 - val_loss: 2.4362 - val_accuracy: 0.7273\n",
      "Epoch 54/100\n",
      "122/122 [==============================] - 8s 68ms/step - loss: 2.4629 - accuracy: 0.5574 - val_loss: 2.4359 - val_accuracy: 0.7273\n",
      "Epoch 55/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4606 - accuracy: 0.6066 - val_loss: 2.4355 - val_accuracy: 0.7273\n",
      "Epoch 56/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4332 - accuracy: 0.6557 - val_loss: 2.4351 - val_accuracy: 0.7273\n",
      "Epoch 57/100\n",
      "122/122 [==============================] - 8s 67ms/step - loss: 2.4626 - accuracy: 0.5902 - val_loss: 2.4347 - val_accuracy: 0.7273\n",
      "Epoch 58/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4489 - accuracy: 0.6148 - val_loss: 2.4343 - val_accuracy: 0.7273\n",
      "Epoch 59/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4510 - accuracy: 0.6311 - val_loss: 2.4340 - val_accuracy: 0.7273\n",
      "Epoch 60/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4466 - accuracy: 0.6803 - val_loss: 2.4336 - val_accuracy: 0.7273\n",
      "Epoch 61/100\n",
      "122/122 [==============================] - 8s 68ms/step - loss: 2.4495 - accuracy: 0.6066 - val_loss: 2.4333 - val_accuracy: 0.6818\n",
      "Epoch 62/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4511 - accuracy: 0.6393 - val_loss: 2.4330 - val_accuracy: 0.6818\n",
      "Epoch 63/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4563 - accuracy: 0.5820 - val_loss: 2.4327 - val_accuracy: 0.6818\n",
      "Epoch 64/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4422 - accuracy: 0.6230 - val_loss: 2.4324 - val_accuracy: 0.6818\n",
      "Epoch 65/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4515 - accuracy: 0.5902 - val_loss: 2.4321 - val_accuracy: 0.7273\n",
      "Epoch 66/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4403 - accuracy: 0.6639 - val_loss: 2.4318 - val_accuracy: 0.7273\n",
      "Epoch 67/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4472 - accuracy: 0.6475 - val_loss: 2.4315 - val_accuracy: 0.7273\n",
      "Epoch 68/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4413 - accuracy: 0.6475 - val_loss: 2.4313 - val_accuracy: 0.7273\n",
      "Epoch 69/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4461 - accuracy: 0.6148 - val_loss: 2.4310 - val_accuracy: 0.7273\n",
      "Epoch 70/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4547 - accuracy: 0.6230 - val_loss: 2.4307 - val_accuracy: 0.7273\n",
      "Epoch 71/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4588 - accuracy: 0.5820 - val_loss: 2.4304 - val_accuracy: 0.7273\n",
      "Epoch 72/100\n",
      "122/122 [==============================] - 8s 67ms/step - loss: 2.4446 - accuracy: 0.6557 - val_loss: 2.4301 - val_accuracy: 0.6818\n",
      "Epoch 73/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4435 - accuracy: 0.5984 - val_loss: 2.4298 - val_accuracy: 0.6818\n",
      "Epoch 74/100\n",
      "122/122 [==============================] - 8s 68ms/step - loss: 2.4410 - accuracy: 0.6148 - val_loss: 2.4296 - val_accuracy: 0.6818\n",
      "Epoch 75/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4446 - accuracy: 0.5902 - val_loss: 2.4293 - val_accuracy: 0.6818\n",
      "Epoch 76/100\n",
      "122/122 [==============================] - 8s 68ms/step - loss: 2.4604 - accuracy: 0.5656 - val_loss: 2.4291 - val_accuracy: 0.6818\n",
      "Epoch 77/100\n",
      "122/122 [==============================] - 9s 71ms/step - loss: 2.4455 - accuracy: 0.6311 - val_loss: 2.4288 - val_accuracy: 0.6818\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4390 - accuracy: 0.6230 - val_loss: 2.4286 - val_accuracy: 0.7273\n",
      "Epoch 79/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4529 - accuracy: 0.5902 - val_loss: 2.4283 - val_accuracy: 0.7273\n",
      "Epoch 80/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4582 - accuracy: 0.5820 - val_loss: 2.4281 - val_accuracy: 0.7273\n",
      "Epoch 81/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4551 - accuracy: 0.5902 - val_loss: 2.4279 - val_accuracy: 0.7273\n",
      "Epoch 82/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4502 - accuracy: 0.6230 - val_loss: 2.4277 - val_accuracy: 0.7273\n",
      "Epoch 83/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4493 - accuracy: 0.5984 - val_loss: 2.4275 - val_accuracy: 0.7273\n",
      "Epoch 84/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4403 - accuracy: 0.6393 - val_loss: 2.4273 - val_accuracy: 0.7273\n",
      "Epoch 85/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4382 - accuracy: 0.6311 - val_loss: 2.4270 - val_accuracy: 0.7273\n",
      "Epoch 86/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4323 - accuracy: 0.6393 - val_loss: 2.4268 - val_accuracy: 0.7273\n",
      "Epoch 87/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4382 - accuracy: 0.6230 - val_loss: 2.4266 - val_accuracy: 0.7273\n",
      "Epoch 88/100\n",
      "122/122 [==============================] - 8s 68ms/step - loss: 2.4362 - accuracy: 0.6393 - val_loss: 2.4264 - val_accuracy: 0.7273\n",
      "Epoch 89/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4508 - accuracy: 0.5902 - val_loss: 2.4262 - val_accuracy: 0.7273\n",
      "Epoch 90/100\n",
      "122/122 [==============================] - 8s 68ms/step - loss: 2.4412 - accuracy: 0.6557 - val_loss: 2.4259 - val_accuracy: 0.7273\n",
      "Epoch 91/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4419 - accuracy: 0.6393 - val_loss: 2.4257 - val_accuracy: 0.7273\n",
      "Epoch 92/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4355 - accuracy: 0.6639 - val_loss: 2.4255 - val_accuracy: 0.7273\n",
      "Epoch 93/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4447 - accuracy: 0.5984 - val_loss: 2.4253 - val_accuracy: 0.7273\n",
      "Epoch 94/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4331 - accuracy: 0.6557 - val_loss: 2.4251 - val_accuracy: 0.7273\n",
      "Epoch 95/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4368 - accuracy: 0.6393 - val_loss: 2.4249 - val_accuracy: 0.7273\n",
      "Epoch 96/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4466 - accuracy: 0.6475 - val_loss: 2.4247 - val_accuracy: 0.7273\n",
      "Epoch 97/100\n",
      "122/122 [==============================] - 9s 70ms/step - loss: 2.4484 - accuracy: 0.6393 - val_loss: 2.4246 - val_accuracy: 0.7273\n",
      "Epoch 98/100\n",
      "122/122 [==============================] - 8s 68ms/step - loss: 2.4391 - accuracy: 0.5820 - val_loss: 2.4244 - val_accuracy: 0.7273\n",
      "Epoch 99/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4213 - accuracy: 0.6557 - val_loss: 2.4242 - val_accuracy: 0.7273\n",
      "Epoch 100/100\n",
      "122/122 [==============================] - 8s 69ms/step - loss: 2.4271 - accuracy: 0.5902 - val_loss: 2.4240 - val_accuracy: 0.7273\n",
      "(170, 1363, 12)\n",
      "(170, 1)\n",
      "Training/Valid data shape: (144, 1363, 12)\n",
      "Test data shape: (26, 1363, 12)\n",
      "Training/Valid target shape: (144, 1)\n",
      "Test target shape: (26, 1)\n",
      "(122, 2)\n",
      "Train on 122 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "122/122 [==============================] - 11s 88ms/step - loss: 2.4963 - accuracy: 0.5820 - val_loss: 2.4503 - val_accuracy: 0.6818\n",
      "Epoch 2/100\n",
      "122/122 [==============================] - 9s 78ms/step - loss: 2.4627 - accuracy: 0.6885 - val_loss: 2.4358 - val_accuracy: 0.6818\n",
      "Epoch 3/100\n",
      "122/122 [==============================] - 9s 77ms/step - loss: 2.4506 - accuracy: 0.6393 - val_loss: 2.4278 - val_accuracy: 0.6818\n",
      "Epoch 4/100\n",
      "122/122 [==============================] - 10s 78ms/step - loss: 2.4458 - accuracy: 0.6475 - val_loss: 2.4219 - val_accuracy: 0.6818\n",
      "Epoch 5/100\n",
      "122/122 [==============================] - 10s 80ms/step - loss: 2.4458 - accuracy: 0.6148 - val_loss: 2.4173 - val_accuracy: 0.6818\n",
      "Epoch 6/100\n",
      "122/122 [==============================] - 10s 79ms/step - loss: 2.4393 - accuracy: 0.6311 - val_loss: 2.4139 - val_accuracy: 0.6818\n",
      "Epoch 7/100\n",
      "122/122 [==============================] - 10s 81ms/step - loss: 2.4278 - accuracy: 0.6803 - val_loss: 2.4111 - val_accuracy: 0.6818\n",
      "Epoch 8/100\n",
      "122/122 [==============================] - 10s 80ms/step - loss: 2.4239 - accuracy: 0.6311 - val_loss: 2.4086 - val_accuracy: 0.6818\n",
      "Epoch 9/100\n",
      "122/122 [==============================] - 10s 80ms/step - loss: 2.4280 - accuracy: 0.6557 - val_loss: 2.4062 - val_accuracy: 0.6818\n",
      "Epoch 10/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.4304 - accuracy: 0.5984 - val_loss: 2.4040 - val_accuracy: 0.6818\n",
      "Epoch 11/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.4212 - accuracy: 0.6475 - val_loss: 2.4021 - val_accuracy: 0.6818\n",
      "Epoch 12/100\n",
      "122/122 [==============================] - 10s 81ms/step - loss: 2.4176 - accuracy: 0.6557 - val_loss: 2.4003 - val_accuracy: 0.6818\n",
      "Epoch 13/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.4077 - accuracy: 0.7131 - val_loss: 2.3986 - val_accuracy: 0.6818\n",
      "Epoch 14/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.4107 - accuracy: 0.6803 - val_loss: 2.3971 - val_accuracy: 0.6818\n",
      "Epoch 15/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.4181 - accuracy: 0.6393 - val_loss: 2.3957 - val_accuracy: 0.6818\n",
      "Epoch 16/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.4011 - accuracy: 0.6885 - val_loss: 2.3944 - val_accuracy: 0.6818\n",
      "Epoch 17/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.4133 - accuracy: 0.6230 - val_loss: 2.3931 - val_accuracy: 0.6818\n",
      "Epoch 18/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.4077 - accuracy: 0.6475 - val_loss: 2.3919 - val_accuracy: 0.6818\n",
      "Epoch 19/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.4225 - accuracy: 0.5902 - val_loss: 2.3908 - val_accuracy: 0.6818\n",
      "Epoch 20/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.4151 - accuracy: 0.6557 - val_loss: 2.3897 - val_accuracy: 0.6818\n",
      "Epoch 21/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.4056 - accuracy: 0.6230 - val_loss: 2.3887 - val_accuracy: 0.6818\n",
      "Epoch 22/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3991 - accuracy: 0.6557 - val_loss: 2.3877 - val_accuracy: 0.6818\n",
      "Epoch 23/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.4139 - accuracy: 0.6230 - val_loss: 2.3868 - val_accuracy: 0.6818\n",
      "Epoch 24/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.4085 - accuracy: 0.6557 - val_loss: 2.3859 - val_accuracy: 0.6818\n",
      "Epoch 25/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.4166 - accuracy: 0.6393 - val_loss: 2.3852 - val_accuracy: 0.6818\n",
      "Epoch 26/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.4078 - accuracy: 0.6475 - val_loss: 2.3844 - val_accuracy: 0.6818\n",
      "Epoch 27/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.4095 - accuracy: 0.6393 - val_loss: 2.3836 - val_accuracy: 0.6818\n",
      "Epoch 28/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.4050 - accuracy: 0.6393 - val_loss: 2.3828 - val_accuracy: 0.6818\n",
      "Epoch 29/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.3999 - accuracy: 0.6639 - val_loss: 2.3821 - val_accuracy: 0.6818\n",
      "Epoch 30/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.4046 - accuracy: 0.6475 - val_loss: 2.3814 - val_accuracy: 0.6818\n",
      "Epoch 31/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3974 - accuracy: 0.6803 - val_loss: 2.3807 - val_accuracy: 0.6818\n",
      "Epoch 32/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3980 - accuracy: 0.6721 - val_loss: 2.3801 - val_accuracy: 0.6818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3996 - accuracy: 0.6557 - val_loss: 2.3795 - val_accuracy: 0.6818\n",
      "Epoch 34/100\n",
      "122/122 [==============================] - 10s 84ms/step - loss: 2.4007 - accuracy: 0.6230 - val_loss: 2.3789 - val_accuracy: 0.6818\n",
      "Epoch 35/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.4017 - accuracy: 0.6721 - val_loss: 2.3783 - val_accuracy: 0.6818\n",
      "Epoch 36/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.4077 - accuracy: 0.6148 - val_loss: 2.3777 - val_accuracy: 0.6818\n",
      "Epoch 37/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.3977 - accuracy: 0.6311 - val_loss: 2.3771 - val_accuracy: 0.6818\n",
      "Epoch 38/100\n",
      "122/122 [==============================] - 10s 84ms/step - loss: 2.4011 - accuracy: 0.6230 - val_loss: 2.3766 - val_accuracy: 0.6818\n",
      "Epoch 39/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.4067 - accuracy: 0.6393 - val_loss: 2.3761 - val_accuracy: 0.6818\n",
      "Epoch 40/100\n",
      "122/122 [==============================] - 10s 84ms/step - loss: 2.3872 - accuracy: 0.7131 - val_loss: 2.3756 - val_accuracy: 0.6818\n",
      "Epoch 41/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.3955 - accuracy: 0.6311 - val_loss: 2.3751 - val_accuracy: 0.6818\n",
      "Epoch 42/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.4029 - accuracy: 0.6475 - val_loss: 2.3746 - val_accuracy: 0.6818\n",
      "Epoch 43/100\n",
      "122/122 [==============================] - 10s 84ms/step - loss: 2.3860 - accuracy: 0.6885 - val_loss: 2.3741 - val_accuracy: 0.6818\n",
      "Epoch 44/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3905 - accuracy: 0.6475 - val_loss: 2.3737 - val_accuracy: 0.6818\n",
      "Epoch 45/100\n",
      "122/122 [==============================] - 10s 84ms/step - loss: 2.3813 - accuracy: 0.7049 - val_loss: 2.3733 - val_accuracy: 0.6818\n",
      "Epoch 46/100\n",
      "122/122 [==============================] - 10s 84ms/step - loss: 2.3947 - accuracy: 0.6557 - val_loss: 2.3728 - val_accuracy: 0.6818\n",
      "Epoch 47/100\n",
      "122/122 [==============================] - 10s 84ms/step - loss: 2.3944 - accuracy: 0.6393 - val_loss: 2.3724 - val_accuracy: 0.6818\n",
      "Epoch 48/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3858 - accuracy: 0.6639 - val_loss: 2.3720 - val_accuracy: 0.6818\n",
      "Epoch 49/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.4030 - accuracy: 0.6148 - val_loss: 2.3716 - val_accuracy: 0.6818\n",
      "Epoch 50/100\n",
      "122/122 [==============================] - 10s 81ms/step - loss: 2.3936 - accuracy: 0.6393 - val_loss: 2.3712 - val_accuracy: 0.6818\n",
      "Epoch 51/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3982 - accuracy: 0.6311 - val_loss: 2.3708 - val_accuracy: 0.6818\n",
      "Epoch 52/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3854 - accuracy: 0.6311 - val_loss: 2.3704 - val_accuracy: 0.6818\n",
      "Epoch 53/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.3821 - accuracy: 0.6721 - val_loss: 2.3700 - val_accuracy: 0.6818\n",
      "Epoch 54/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.3989 - accuracy: 0.6393 - val_loss: 2.3696 - val_accuracy: 0.6818\n",
      "Epoch 55/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3895 - accuracy: 0.6803 - val_loss: 2.3692 - val_accuracy: 0.6818\n",
      "Epoch 56/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.3951 - accuracy: 0.6230 - val_loss: 2.3688 - val_accuracy: 0.6818\n",
      "Epoch 57/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.3854 - accuracy: 0.6393 - val_loss: 2.3684 - val_accuracy: 0.7273\n",
      "Epoch 58/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3917 - accuracy: 0.6393 - val_loss: 2.3680 - val_accuracy: 0.7273\n",
      "Epoch 59/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.3992 - accuracy: 0.6148 - val_loss: 2.3677 - val_accuracy: 0.7273\n",
      "Epoch 60/100\n",
      "122/122 [==============================] - 10s 84ms/step - loss: 2.3860 - accuracy: 0.6557 - val_loss: 2.3673 - val_accuracy: 0.7273\n",
      "Epoch 61/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3980 - accuracy: 0.5984 - val_loss: 2.3670 - val_accuracy: 0.7273\n",
      "Epoch 62/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.3996 - accuracy: 0.6148 - val_loss: 2.3667 - val_accuracy: 0.7273\n",
      "Epoch 63/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.3865 - accuracy: 0.6311 - val_loss: 2.3664 - val_accuracy: 0.7273\n",
      "Epoch 64/100\n",
      "122/122 [==============================] - 10s 81ms/step - loss: 2.3903 - accuracy: 0.5984 - val_loss: 2.3661 - val_accuracy: 0.7273\n",
      "Epoch 65/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3841 - accuracy: 0.6557 - val_loss: 2.3658 - val_accuracy: 0.7273\n",
      "Epoch 66/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.3866 - accuracy: 0.6639 - val_loss: 2.3655 - val_accuracy: 0.7273\n",
      "Epoch 67/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3854 - accuracy: 0.6721 - val_loss: 2.3652 - val_accuracy: 0.7273\n",
      "Epoch 68/100\n",
      "122/122 [==============================] - 10s 81ms/step - loss: 2.3824 - accuracy: 0.6230 - val_loss: 2.3649 - val_accuracy: 0.7273\n",
      "Epoch 69/100\n",
      "122/122 [==============================] - 10s 81ms/step - loss: 2.3883 - accuracy: 0.6066 - val_loss: 2.3646 - val_accuracy: 0.7273\n",
      "Epoch 70/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.3929 - accuracy: 0.6230 - val_loss: 2.3643 - val_accuracy: 0.7273\n",
      "Epoch 71/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.3840 - accuracy: 0.6721 - val_loss: 2.3640 - val_accuracy: 0.7273\n",
      "Epoch 72/100\n",
      "122/122 [==============================] - 10s 84ms/step - loss: 2.3965 - accuracy: 0.6066 - val_loss: 2.3638 - val_accuracy: 0.7273\n",
      "Epoch 73/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3913 - accuracy: 0.6311 - val_loss: 2.3635 - val_accuracy: 0.7273\n",
      "Epoch 74/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3828 - accuracy: 0.6639 - val_loss: 2.3633 - val_accuracy: 0.7273\n",
      "Epoch 75/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3782 - accuracy: 0.6475 - val_loss: 2.3630 - val_accuracy: 0.7273\n",
      "Epoch 76/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3753 - accuracy: 0.6639 - val_loss: 2.3627 - val_accuracy: 0.7273\n",
      "Epoch 77/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.3815 - accuracy: 0.6557 - val_loss: 2.3625 - val_accuracy: 0.7273\n",
      "Epoch 78/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.3759 - accuracy: 0.6803 - val_loss: 2.3622 - val_accuracy: 0.7273\n",
      "Epoch 79/100\n",
      "122/122 [==============================] - 10s 82ms/step - loss: 2.3816 - accuracy: 0.6721 - val_loss: 2.3619 - val_accuracy: 0.7273\n",
      "Epoch 80/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3840 - accuracy: 0.6393 - val_loss: 2.3617 - val_accuracy: 0.7273\n",
      "Epoch 81/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3848 - accuracy: 0.6639 - val_loss: 2.3614 - val_accuracy: 0.7273\n",
      "Epoch 82/100\n",
      "122/122 [==============================] - 10s 84ms/step - loss: 2.3881 - accuracy: 0.6066 - val_loss: 2.3611 - val_accuracy: 0.7273\n",
      "Epoch 83/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3699 - accuracy: 0.6721 - val_loss: 2.3609 - val_accuracy: 0.7273\n",
      "Epoch 84/100\n",
      "122/122 [==============================] - 10s 85ms/step - loss: 2.3795 - accuracy: 0.6475 - val_loss: 2.3606 - val_accuracy: 0.7273\n",
      "Epoch 85/100\n",
      "122/122 [==============================] - 10s 85ms/step - loss: 2.3759 - accuracy: 0.7049 - val_loss: 2.3604 - val_accuracy: 0.7273\n",
      "Epoch 86/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3872 - accuracy: 0.6639 - val_loss: 2.3602 - val_accuracy: 0.7273\n",
      "Epoch 87/100\n",
      "122/122 [==============================] - 10s 85ms/step - loss: 2.3704 - accuracy: 0.6557 - val_loss: 2.3599 - val_accuracy: 0.7273\n",
      "Epoch 88/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3838 - accuracy: 0.6393 - val_loss: 2.3597 - val_accuracy: 0.7273\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 10s 84ms/step - loss: 2.3818 - accuracy: 0.6311 - val_loss: 2.3595 - val_accuracy: 0.7273\n",
      "Epoch 90/100\n",
      "122/122 [==============================] - 10s 85ms/step - loss: 2.3870 - accuracy: 0.6557 - val_loss: 2.3593 - val_accuracy: 0.7273\n",
      "Epoch 91/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3776 - accuracy: 0.6393 - val_loss: 2.3591 - val_accuracy: 0.7273\n",
      "Epoch 92/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3917 - accuracy: 0.6311 - val_loss: 2.3589 - val_accuracy: 0.7273\n",
      "Epoch 93/100\n",
      "122/122 [==============================] - 10s 86ms/step - loss: 2.3878 - accuracy: 0.6393 - val_loss: 2.3587 - val_accuracy: 0.7273\n",
      "Epoch 94/100\n",
      "122/122 [==============================] - 10s 84ms/step - loss: 2.3852 - accuracy: 0.6148 - val_loss: 2.3585 - val_accuracy: 0.7273\n",
      "Epoch 95/100\n",
      "122/122 [==============================] - 10s 84ms/step - loss: 2.3790 - accuracy: 0.6393 - val_loss: 2.3583 - val_accuracy: 0.7273\n",
      "Epoch 96/100\n",
      "122/122 [==============================] - 10s 85ms/step - loss: 2.3720 - accuracy: 0.6803 - val_loss: 2.3581 - val_accuracy: 0.7273\n",
      "Epoch 97/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3825 - accuracy: 0.6885 - val_loss: 2.3579 - val_accuracy: 0.7273\n",
      "Epoch 98/100\n",
      "122/122 [==============================] - 10s 83ms/step - loss: 2.3797 - accuracy: 0.6639 - val_loss: 2.3577 - val_accuracy: 0.7273\n",
      "Epoch 99/100\n",
      "122/122 [==============================] - 10s 84ms/step - loss: 2.3767 - accuracy: 0.6639 - val_loss: 2.3575 - val_accuracy: 0.7273\n",
      "Epoch 100/100\n",
      "122/122 [==============================] - 10s 84ms/step - loss: 2.3702 - accuracy: 0.6803 - val_loss: 2.3573 - val_accuracy: 0.7273\n",
      "(170, 1363, 12)\n",
      "(170, 1)\n",
      "Training/Valid data shape: (144, 1363, 12)\n",
      "Test data shape: (26, 1363, 12)\n",
      "Training/Valid target shape: (144, 1)\n",
      "Test target shape: (26, 1)\n",
      "(122, 2)\n",
      "Train on 122 samples, validate on 22 samples\n",
      "Epoch 1/100\n",
      "122/122 [==============================] - 13s 107ms/step - loss: 2.7439 - accuracy: 0.4426 - val_loss: 2.7077 - val_accuracy: 0.4091\n",
      "Epoch 2/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.6894 - accuracy: 0.4508 - val_loss: 2.6827 - val_accuracy: 0.4545\n",
      "Epoch 3/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.6686 - accuracy: 0.5082 - val_loss: 2.6689 - val_accuracy: 0.4545\n",
      "Epoch 4/100\n",
      "122/122 [==============================] - 12s 97ms/step - loss: 2.6612 - accuracy: 0.5410 - val_loss: 2.6595 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.6537 - accuracy: 0.5984 - val_loss: 2.6523 - val_accuracy: 0.5455\n",
      "Epoch 6/100\n",
      "122/122 [==============================] - 12s 97ms/step - loss: 2.6516 - accuracy: 0.5902 - val_loss: 2.6466 - val_accuracy: 0.5909\n",
      "Epoch 7/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.6410 - accuracy: 0.5820 - val_loss: 2.6421 - val_accuracy: 0.6364\n",
      "Epoch 8/100\n",
      "122/122 [==============================] - 12s 97ms/step - loss: 2.6406 - accuracy: 0.5984 - val_loss: 2.6382 - val_accuracy: 0.6364\n",
      "Epoch 9/100\n",
      "122/122 [==============================] - 12s 97ms/step - loss: 2.6327 - accuracy: 0.6393 - val_loss: 2.6348 - val_accuracy: 0.7273\n",
      "Epoch 10/100\n",
      "122/122 [==============================] - 12s 97ms/step - loss: 2.6343 - accuracy: 0.6230 - val_loss: 2.6319 - val_accuracy: 0.6818\n",
      "Epoch 11/100\n",
      "122/122 [==============================] - 12s 97ms/step - loss: 2.6321 - accuracy: 0.6311 - val_loss: 2.6292 - val_accuracy: 0.6818\n",
      "Epoch 12/100\n",
      "122/122 [==============================] - 12s 94ms/step - loss: 2.6259 - accuracy: 0.6557 - val_loss: 2.6268 - val_accuracy: 0.6818\n",
      "Epoch 13/100\n",
      "122/122 [==============================] - 12s 97ms/step - loss: 2.6289 - accuracy: 0.6066 - val_loss: 2.6247 - val_accuracy: 0.6818\n",
      "Epoch 14/100\n",
      "122/122 [==============================] - 12s 97ms/step - loss: 2.6267 - accuracy: 0.5984 - val_loss: 2.6227 - val_accuracy: 0.6818\n",
      "Epoch 15/100\n",
      "122/122 [==============================] - 12s 97ms/step - loss: 2.6249 - accuracy: 0.6721 - val_loss: 2.6209 - val_accuracy: 0.6818\n",
      "Epoch 16/100\n",
      "122/122 [==============================] - 12s 97ms/step - loss: 2.6259 - accuracy: 0.6393 - val_loss: 2.6193 - val_accuracy: 0.6364\n",
      "Epoch 17/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.6156 - accuracy: 0.6885 - val_loss: 2.6178 - val_accuracy: 0.6364\n",
      "Epoch 18/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.6198 - accuracy: 0.6066 - val_loss: 2.6164 - val_accuracy: 0.6364\n",
      "Epoch 19/100\n",
      "122/122 [==============================] - 12s 97ms/step - loss: 2.6258 - accuracy: 0.5410 - val_loss: 2.6152 - val_accuracy: 0.6818\n",
      "Epoch 20/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.6201 - accuracy: 0.6066 - val_loss: 2.6141 - val_accuracy: 0.6818\n",
      "Epoch 21/100\n",
      "122/122 [==============================] - 12s 97ms/step - loss: 2.6189 - accuracy: 0.5984 - val_loss: 2.6130 - val_accuracy: 0.7273\n",
      "Epoch 22/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.6078 - accuracy: 0.6721 - val_loss: 2.6120 - val_accuracy: 0.7273\n",
      "Epoch 23/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.6234 - accuracy: 0.5820 - val_loss: 2.6111 - val_accuracy: 0.7273\n",
      "Epoch 24/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.6168 - accuracy: 0.5820 - val_loss: 2.6101 - val_accuracy: 0.7273\n",
      "Epoch 25/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.6131 - accuracy: 0.6148 - val_loss: 2.6092 - val_accuracy: 0.7273\n",
      "Epoch 26/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.6112 - accuracy: 0.6557 - val_loss: 2.6084 - val_accuracy: 0.7273\n",
      "Epoch 27/100\n",
      "122/122 [==============================] - 12s 97ms/step - loss: 2.6094 - accuracy: 0.5984 - val_loss: 2.6075 - val_accuracy: 0.7273\n",
      "Epoch 28/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.6076 - accuracy: 0.6230 - val_loss: 2.6067 - val_accuracy: 0.7273\n",
      "Epoch 29/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.6124 - accuracy: 0.5492 - val_loss: 2.6059 - val_accuracy: 0.7273\n",
      "Epoch 30/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.6087 - accuracy: 0.6475 - val_loss: 2.6051 - val_accuracy: 0.7273\n",
      "Epoch 31/100\n",
      "122/122 [==============================] - 12s 97ms/step - loss: 2.6092 - accuracy: 0.5984 - val_loss: 2.6043 - val_accuracy: 0.7273\n",
      "Epoch 32/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.6013 - accuracy: 0.6393 - val_loss: 2.6035 - val_accuracy: 0.7727\n",
      "Epoch 33/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.6000 - accuracy: 0.6557 - val_loss: 2.6027 - val_accuracy: 0.7727\n",
      "Epoch 34/100\n",
      "122/122 [==============================] - 12s 97ms/step - loss: 2.6013 - accuracy: 0.6230 - val_loss: 2.6020 - val_accuracy: 0.7727\n",
      "Epoch 35/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.6041 - accuracy: 0.6148 - val_loss: 2.6013 - val_accuracy: 0.7727\n",
      "Epoch 36/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.5960 - accuracy: 0.6885 - val_loss: 2.6007 - val_accuracy: 0.7727\n",
      "Epoch 37/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.6060 - accuracy: 0.6311 - val_loss: 2.6000 - val_accuracy: 0.7727\n",
      "Epoch 38/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.6025 - accuracy: 0.6475 - val_loss: 2.5994 - val_accuracy: 0.7727\n",
      "Epoch 39/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.5988 - accuracy: 0.6230 - val_loss: 2.5988 - val_accuracy: 0.7727\n",
      "Epoch 40/100\n",
      "122/122 [==============================] - 11s 94ms/step - loss: 2.6084 - accuracy: 0.5984 - val_loss: 2.5982 - val_accuracy: 0.7727\n",
      "Epoch 41/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.6032 - accuracy: 0.6148 - val_loss: 2.5975 - val_accuracy: 0.7727\n",
      "Epoch 42/100\n",
      "122/122 [==============================] - 12s 97ms/step - loss: 2.6026 - accuracy: 0.5820 - val_loss: 2.5969 - val_accuracy: 0.7727\n",
      "Epoch 43/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.5959 - accuracy: 0.6639 - val_loss: 2.5963 - val_accuracy: 0.7727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.6010 - accuracy: 0.5984 - val_loss: 2.5958 - val_accuracy: 0.7727\n",
      "Epoch 45/100\n",
      "122/122 [==============================] - 11s 94ms/step - loss: 2.5998 - accuracy: 0.6230 - val_loss: 2.5952 - val_accuracy: 0.7727\n",
      "Epoch 46/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.5954 - accuracy: 0.5902 - val_loss: 2.5946 - val_accuracy: 0.7727\n",
      "Epoch 47/100\n",
      "122/122 [==============================] - 11s 92ms/step - loss: 2.5982 - accuracy: 0.6066 - val_loss: 2.5940 - val_accuracy: 0.7727\n",
      "Epoch 48/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.5953 - accuracy: 0.6393 - val_loss: 2.5935 - val_accuracy: 0.7727\n",
      "Epoch 49/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.5986 - accuracy: 0.6721 - val_loss: 2.5930 - val_accuracy: 0.7727\n",
      "Epoch 50/100\n",
      "122/122 [==============================] - 12s 98ms/step - loss: 2.5977 - accuracy: 0.6066 - val_loss: 2.5925 - val_accuracy: 0.7727\n",
      "Epoch 51/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.6094 - accuracy: 0.5902 - val_loss: 2.5921 - val_accuracy: 0.7727\n",
      "Epoch 52/100\n",
      "122/122 [==============================] - 12s 98ms/step - loss: 2.5877 - accuracy: 0.6639 - val_loss: 2.5917 - val_accuracy: 0.7727\n",
      "Epoch 53/100\n",
      "122/122 [==============================] - 11s 91ms/step - loss: 2.6022 - accuracy: 0.6066 - val_loss: 2.5914 - val_accuracy: 0.7727\n",
      "Epoch 54/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.5897 - accuracy: 0.6393 - val_loss: 2.5910 - val_accuracy: 0.7727\n",
      "Epoch 55/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.5943 - accuracy: 0.6639 - val_loss: 2.5906 - val_accuracy: 0.7727\n",
      "Epoch 56/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.5952 - accuracy: 0.6066 - val_loss: 2.5902 - val_accuracy: 0.7727\n",
      "Epoch 57/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.5951 - accuracy: 0.6639 - val_loss: 2.5898 - val_accuracy: 0.7727\n",
      "Epoch 58/100\n",
      "122/122 [==============================] - 11s 94ms/step - loss: 2.5966 - accuracy: 0.6311 - val_loss: 2.5894 - val_accuracy: 0.7727\n",
      "Epoch 59/100\n",
      "122/122 [==============================] - 11s 94ms/step - loss: 2.5997 - accuracy: 0.6230 - val_loss: 2.5890 - val_accuracy: 0.7727\n",
      "Epoch 60/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.5986 - accuracy: 0.5738 - val_loss: 2.5886 - val_accuracy: 0.7727\n",
      "Epoch 61/100\n",
      "122/122 [==============================] - 12s 94ms/step - loss: 2.5921 - accuracy: 0.6311 - val_loss: 2.5882 - val_accuracy: 0.7727\n",
      "Epoch 62/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.5971 - accuracy: 0.6066 - val_loss: 2.5878 - val_accuracy: 0.7727\n",
      "Epoch 63/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.5959 - accuracy: 0.5738 - val_loss: 2.5874 - val_accuracy: 0.7727\n",
      "Epoch 64/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.5968 - accuracy: 0.5656 - val_loss: 2.5871 - val_accuracy: 0.7727\n",
      "Epoch 65/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.5872 - accuracy: 0.6803 - val_loss: 2.5867 - val_accuracy: 0.7727\n",
      "Epoch 66/100\n",
      "122/122 [==============================] - 11s 94ms/step - loss: 2.5948 - accuracy: 0.5738 - val_loss: 2.5864 - val_accuracy: 0.7727\n",
      "Epoch 67/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.5905 - accuracy: 0.6393 - val_loss: 2.5860 - val_accuracy: 0.7727\n",
      "Epoch 68/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.5947 - accuracy: 0.6475 - val_loss: 2.5856 - val_accuracy: 0.7727\n",
      "Epoch 69/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.5892 - accuracy: 0.6148 - val_loss: 2.5853 - val_accuracy: 0.7727\n",
      "Epoch 70/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.5866 - accuracy: 0.6557 - val_loss: 2.5849 - val_accuracy: 0.7727\n",
      "Epoch 71/100\n",
      "122/122 [==============================] - 11s 93ms/step - loss: 2.5874 - accuracy: 0.5902 - val_loss: 2.5846 - val_accuracy: 0.7727\n",
      "Epoch 72/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.5984 - accuracy: 0.6230 - val_loss: 2.5843 - val_accuracy: 0.7727\n",
      "Epoch 73/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.5823 - accuracy: 0.6475 - val_loss: 2.5839 - val_accuracy: 0.7727\n",
      "Epoch 74/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.5858 - accuracy: 0.6066 - val_loss: 2.5836 - val_accuracy: 0.7727\n",
      "Epoch 75/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.5798 - accuracy: 0.6557 - val_loss: 2.5832 - val_accuracy: 0.7727\n",
      "Epoch 76/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.5960 - accuracy: 0.5574 - val_loss: 2.5829 - val_accuracy: 0.7727\n",
      "Epoch 77/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.5946 - accuracy: 0.6066 - val_loss: 2.5826 - val_accuracy: 0.7727\n",
      "Epoch 78/100\n",
      "122/122 [==============================] - 11s 94ms/step - loss: 2.5854 - accuracy: 0.6230 - val_loss: 2.5823 - val_accuracy: 0.7727\n",
      "Epoch 79/100\n",
      "122/122 [==============================] - 11s 93ms/step - loss: 2.5805 - accuracy: 0.6803 - val_loss: 2.5820 - val_accuracy: 0.7727\n",
      "Epoch 80/100\n",
      "122/122 [==============================] - 11s 94ms/step - loss: 2.5947 - accuracy: 0.6148 - val_loss: 2.5817 - val_accuracy: 0.7727\n",
      "Epoch 81/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.5822 - accuracy: 0.6639 - val_loss: 2.5815 - val_accuracy: 0.7727\n",
      "Epoch 82/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.5955 - accuracy: 0.6066 - val_loss: 2.5812 - val_accuracy: 0.7727\n",
      "Epoch 83/100\n",
      "122/122 [==============================] - 12s 94ms/step - loss: 2.5873 - accuracy: 0.6148 - val_loss: 2.5809 - val_accuracy: 0.7727\n",
      "Epoch 84/100\n",
      "122/122 [==============================] - 11s 94ms/step - loss: 2.5933 - accuracy: 0.6066 - val_loss: 2.5807 - val_accuracy: 0.7727\n",
      "Epoch 85/100\n",
      "122/122 [==============================] - 12s 97ms/step - loss: 2.5897 - accuracy: 0.6148 - val_loss: 2.5805 - val_accuracy: 0.7727\n",
      "Epoch 86/100\n",
      "122/122 [==============================] - 12s 94ms/step - loss: 2.5798 - accuracy: 0.6393 - val_loss: 2.5802 - val_accuracy: 0.7727\n",
      "Epoch 87/100\n",
      "122/122 [==============================] - 11s 93ms/step - loss: 2.5826 - accuracy: 0.6475 - val_loss: 2.5800 - val_accuracy: 0.7727\n",
      "Epoch 88/100\n",
      "122/122 [==============================] - 11s 94ms/step - loss: 2.5883 - accuracy: 0.6393 - val_loss: 2.5797 - val_accuracy: 0.7727\n",
      "Epoch 89/100\n",
      "122/122 [==============================] - 11s 94ms/step - loss: 2.5797 - accuracy: 0.6475 - val_loss: 2.5795 - val_accuracy: 0.7727\n",
      "Epoch 90/100\n",
      "122/122 [==============================] - 12s 96ms/step - loss: 2.5882 - accuracy: 0.5902 - val_loss: 2.5792 - val_accuracy: 0.7727\n",
      "Epoch 91/100\n",
      "122/122 [==============================] - 12s 94ms/step - loss: 2.5874 - accuracy: 0.6066 - val_loss: 2.5790 - val_accuracy: 0.7727\n",
      "Epoch 92/100\n",
      "122/122 [==============================] - 11s 94ms/step - loss: 2.5867 - accuracy: 0.6230 - val_loss: 2.5787 - val_accuracy: 0.7727\n",
      "Epoch 93/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.5855 - accuracy: 0.6148 - val_loss: 2.5785 - val_accuracy: 0.7727\n",
      "Epoch 94/100\n",
      "122/122 [==============================] - 12s 94ms/step - loss: 2.5765 - accuracy: 0.6721 - val_loss: 2.5782 - val_accuracy: 0.7727\n",
      "Epoch 95/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.5858 - accuracy: 0.5820 - val_loss: 2.5780 - val_accuracy: 0.7727\n",
      "Epoch 96/100\n",
      "122/122 [==============================] - 11s 94ms/step - loss: 2.5788 - accuracy: 0.6311 - val_loss: 2.5778 - val_accuracy: 0.7727\n",
      "Epoch 97/100\n",
      "122/122 [==============================] - 11s 93ms/step - loss: 2.5879 - accuracy: 0.6230 - val_loss: 2.5776 - val_accuracy: 0.7727\n",
      "Epoch 98/100\n",
      "122/122 [==============================] - 12s 95ms/step - loss: 2.5867 - accuracy: 0.6311 - val_loss: 2.5774 - val_accuracy: 0.7727\n",
      "Epoch 99/100\n",
      "122/122 [==============================] - 11s 94ms/step - loss: 2.5866 - accuracy: 0.5738 - val_loss: 2.5771 - val_accuracy: 0.7727\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/122 [=======================>......] - ETA: 1s - loss: 2.5926 - accuracy: 0.6000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "122/122 [==============================] - 12s 94ms/step - loss: 2.5924 - accuracy: 0.5902 - val_loss: 2.5769 - val_accuracy: 0.7727\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import CuDNNLSTM\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "history_list = []\n",
    "for model_iter in range(5):\n",
    "    X=sio.loadmat('feat_vec_rnn.mat')\n",
    "    y=sio.loadmat('labels')\n",
    "\n",
    "    print(X_data.shape)\n",
    "    print(y_data.shape)\n",
    "\n",
    "    X_data=X['feat_vec_rnn']\n",
    "    X_data=np.transpose(X_data, (2, 0, 1))\n",
    "\n",
    "    y_data=y['labels']\n",
    "\n",
    "\n",
    "    X_train_val, X_test, y_train_val, y_test= train_test_split(X_data, y_data, test_size=0.15)\n",
    "\n",
    "    X_train, X_val, y_train, y_val= train_test_split(X_train_val, y_train_val, test_size=0.15)\n",
    "\n",
    "\n",
    "\n",
    "    print ('Training/Valid data shape: {}'.format(X_train_val.shape))\n",
    "    print ('Test data shape: {}'.format(X_test.shape))\n",
    "    print ('Training/Valid target shape: {}'.format(y_train_val.shape))\n",
    "    print ('Test target shape: {}'.format(y_test.shape))\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "    y_train = onehot_encoder.fit_transform(y_train)\n",
    "    y_val = onehot_encoder.fit_transform(y_val)\n",
    "    y_test = onehot_encoder.fit_transform(y_test)\n",
    "\n",
    "    print(y_train.shape)\n",
    "\n",
    "    n_samples = X_train.shape[0]  # number of data points\n",
    "    n_features = X_train.shape[1]  # dimension of feature vector for each sample\n",
    "    time_steps = X_train.shape[2] # how many samples across time were taken\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(50, dropout=0.2, recurrent_dropout=0.2, return_sequences=True, kernel_initializer='random_normal', input_shape=(n_features, time_steps)))\n",
    "\n",
    "    model.add(MaxPooling1D(pool_size=(2), strides=2, padding='valid', data_format=None))\n",
    "\n",
    "    model.add(LSTM(40, return_sequences=True))\n",
    "\n",
    "    model.add(LSTM(30, return_sequences=False))\n",
    "\n",
    "    model.add(Dense(2, activation='softmax', kernel_regularizer=regularizers.l1_l2(l1=0,l2=0.5)))\n",
    "\n",
    "    #sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    Adam=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, decay=0.99, amsgrad=False)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=Adam,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history=model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=100, epochs=100)\n",
    "    history_list.append(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57272727 0.60909091 0.61818182 0.63636364 0.64545455 0.65454545\n",
      " 0.66363636 0.66363636 0.68181819 0.67272727 0.67272727 0.67272727\n",
      " 0.67272727 0.67272727 0.67272727 0.66363636 0.66363636 0.66363636\n",
      " 0.67272727 0.67272727 0.68181819 0.68181819 0.68181819 0.68181819\n",
      " 0.68181819 0.68181819 0.68181819 0.68181819 0.68181819 0.68181819\n",
      " 0.68181819 0.7        0.7        0.7        0.7        0.7\n",
      " 0.7        0.7        0.71818182 0.71818182 0.71818182 0.71818182\n",
      " 0.71818182 0.71818182 0.71818182 0.72727274 0.72727274 0.72727274\n",
      " 0.72727274 0.72727274 0.72727274 0.72727274 0.72727274 0.72727274\n",
      " 0.72727274 0.72727274 0.73636365 0.73636365 0.73636365 0.73636365\n",
      " 0.72727274 0.72727274 0.72727274 0.72727274 0.73636365 0.73636365\n",
      " 0.73636365 0.73636365 0.73636365 0.73636365 0.73636365 0.72727274\n",
      " 0.72727274 0.72727274 0.72727274 0.72727274 0.72727274 0.73636365\n",
      " 0.73636365 0.73636365 0.73636365 0.73636365 0.73636365 0.73636365\n",
      " 0.73636365 0.73636365 0.73636365 0.73636365 0.73636365 0.73636365\n",
      " 0.73636365 0.73636365 0.73636365 0.73636365 0.73636365 0.73636365\n",
      " 0.73636365 0.73636365 0.73636365 0.73636365]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXd4m9XZuO8jWZY85D3jkdjZw9kQRiCkEMIsUEahAwotlO8rLS0tLV9/tAW66Pq6oKW0TduvZTRAoZRRZgk7gew4O05iO957alnn98f7vrJky5ZkW5btnPu6dNl656N1nvPMI6SUKBQKhUIxHKZYC6BQKBSKiY9SFgqFQqEIiVIWCoVCoQiJUhYKhUKhCIlSFgqFQqEIiVIWCoVCoQiJUhYKxSgQQpwjhKgO89h7hBB/i7ZMCkU0UMpCMe4IIY4JIXqFEF1CiDohxJ+FEMl++/8shJBCiFP9ts0SQki/528IIRxCiCK/becJIY4Nc18phKgXQsT5bYsTQjT4XzuWCCFKhBBeIcRvYi2LQuGPUhaKWHGplDIZWAosA/5nwP4W4HshrtENfCvC+7YBF/o9vwhojfAa0eR6NHmuFUJYx/PG/kpUoRiIUhaKmCKlrANeQlMa/vwFWCyEWDPM6b8CrhNCzIrgln9FG5ANrgf+z/8AIcQ0IcSzQogWIcRhIcTNfvsSdMunVQixFzglyLlPCSEahRBHhRBfikA2Q567ATdw6YBrLxRCvKLLVS+E+Ka+3SyE+KYQ4ogQolMIsVUIUSSEmKFbU/6W1BtCiM/p/39GCPGOEOLnQogW4B4hxEwhxOtCiGYhRJMQ4hEhRJrf+UVCiH/or69ZCPGAEMKqy1Tmd1yObj1mR/j6FRMUpSwUMUUIUYg20z88YFcP8APg+8OcfgL4PXBPBLd8BjhbCJGmD4JnAf8ccMxjQDUwDbgK+IEQ4lx933eAmfpjPXCD32sxAf8CdgIFwLnAl4UQ68MRTAhxFlAIPA5sxE+pCSHswKvAv3W5ZgGv6bvvAK5Ds5JSgJvQ3r9wWAVUADlo77UAfqjfYz5QhP7+CiHMwHPAcWCG/hofl1I6dZk/5Xfd64BXpZSNYcqhmOAoZaGIFc8IITqBKqABbRAeyO+AYiHEhUH2GfwQuFQIsTDM+zrQBvSPA9cCz+rbAG3mDKwGviGldEgpdwB/AD6tH3IN8H0pZYuUsgrNujE4BciWUt4npXRJKSvQlNm1Ycp2A/CilLIVeBS4UAiRo++7BKiTUv5Ml6tTSrlZ3/c54G4p5QGpsVNK2RzmPWuklL+WUnqklL1SysNSyleklE59oP9fwLDuTkVTIndKKbt1Od7W9/0F+ISuMNHfr7+GKYNiEqCUhSJWXC6ltAPnAPOArIEH6DPW7+oPEewi+oD2AHBfBPf+P7RZ+yAXFNpg2CKl7PTbdhxtFm3srxqwz2A6ME0I0WY8gG8CuaEEEkIkAFcDjwBIKd8DKoFP6IcUAUeGOH24faHwfy2G++hxIcQJIUQH8Df6P5si4LiU0jPwIrri6gbWCCHmoVk+z45QJsUERCkLRUyRUm4C/gz8dIhD/gSkAlcMc5mfAGuBFWHe9i0gH20Qf3vAvhogQ3f7GBSjubwAatEGTf99BlXAUSllmt/DLqW8KAyZrkBzIf1GzxCrQ1NQhiuqCs31FYyh9nXrfxP9tuUNOGZgFtgP9W2LpZQpaK4lQ1FXoVl6QwXC/6If/2ngSSmlY4jjFJMQpSwUE4FfAOuEEAOD3Oiz2HuAbwx1spSyDfgZ8PVwbia1vvyXAh+VA3r0666ld4EfCiFsQojFwGfRZ/xosYT/EUKk6/GWL/qdvgXoEEJ8Qw+Em4UQi4QQAUHwIbgB2ACUoQX7lwJnAkv1wPFzQJ4Q4st6QNkuhFiln/sH4LtCiNlCY7EQIlO3uk4An9JluYmhFY6BHegC2oQQBcCdA15fLXC/ECJJf3/O9Nv/VzSl9ykGW2yKSY5SFoqYow9q/8fQabCPoQ1Sw/FLoC+Ce5ZLKcuH2H0dWgC3Bnga+I6U8hV9371orqejwMv4+eWllH1oSmipvr8JbSBPHU4WfVA+F/iFlLLO77EVLaB9g+4WW6dfvw44hGZNgRZX2KjL0wH8EUjQ992MNuA3AwvRFOFw3AssB9qB54F/BHl9s9BcZNVosR9jfzWwDc0yeSvEfRSTDKEWP1IoFGOFEGIDWtD87ljLohhbVBGOQqEYE4QQM4CPoRVZKqYYyg2lUChGjRDiu8Ae4CdSyqOxlkcx9ig3lEKhUChCoiwLhUKhUIRkysQssrKy5IwZM2IthkKhUEwqtm7d2iSlDNnDa8ooixkzZvDhhx/GWgyFQqGYVAghjoc+SrmhFAqFQhEGSlkoFAqFIiRKWSgUCoUiJFMmZhEMt9tNdXU1DsfJ08/MZrNRWFiIxWKJtSgKhWIKMaWVRXV1NXa7nRkzZiBE0A7XUwopJc3NzVRXV1NSUhJrcRQKxRRiSruhHA4HmZmZJ4WiABBCkJmZeVJZUgqFYnyY0soCOGkUhcHJ9noVCsX4MKXdUArFlKT8Gagfqru6H8WnwaxzQx83EEcHbPkdeFyRnxuMBR+FvLKxuRZAbyts+QP0jZF8U4GUabDyxqjeQimLKNLc3My552o/1rq6OsxmM9nZWqHkli1biI+PD3mNG2+8kbvuuou5c+dGVVbFJKG7GZ76LHg9DLHSrI6EhAz46gGIC/09C+DDDfD690JcP1wkHHsLbvr3GFxLZ/Pv4I0fMjbyTREKVyplMZnJzMxkx44dANxzzz0kJyfzta99LeAYKSVSSkym4B7BP/3pT1GXUzGJKP+HpihufQfyFg193MGX4NFr4MhrMPfCyO6xayMUngqfeyX0saF486fw+neh9TikTx/99aTU5JtxFnzmudFfTxE2Uz5mMRE5fPgwixYt4tZbb2X58uXU1tZyyy23sHLlShYuXMh9993nO3b16tXs2LEDj8dDWload911F0uWLOH000+noaEhhq9CERN2PwE5C4ZXFAAzPwKJmdrAGgn15dBQDouvGbmM/pRdrf3d/cTYXO/ENmg5MnbyKcLmpLEs7v1XOXtrOsb0mgumpfCdSxeO6Ny9e/fypz/9iYceegiA+++/n4yMDDweD2vXruWqq65iwYIFAee0t7ezZs0a7r//fu644w42bNjAXXfdNerXoZgktByFqs1w7ndCH2u2wMIrYPvftBiELSW8e+zaCMKsnTsWpE+H4tM1ZXHWV2G0CRi7N4I5HuZ/dGzkU4SNsixixMyZMznllFN8zx977DGWL1/O8uXL2bdvH3v37h10TkJCAhdeqLkUVqxYwbFjx8ZLXMVEYPeT2l9jth6KxR8HjwP2h+mu8Xq1e8w6D5KyRiZjMMquhsb9ULd7dNfp88Cep2DOBZCQNjayKcLmpLEsRmoBRIukpCTf/4cOHeKXv/wlW7ZsIS0tjU996lNBayX8A+JmsxmPxzMusiomAFJqs+rpZ0JaUXjnFJ4C6TM0a2HpJ0IfX/kudFTDuntHJeogFl4BL35dkz9/8civc/QN6G5ULqgYoSyLCUBHRwd2u52UlBRqa2t56aWXYi2SYqJRuxOaDoZvVYDm8im7Go5ugs660Mfv2giWpMgD4qFIzIDZ52tWi7dv5NfZtRFsqdq1FOOOUhYTgOXLl7NgwQIWLVrEzTffzJlnnhlrkRQTjV26r37h5ZGdV3YNSK/mvhkOjxP2PgPzL4X4pOGPHQllV0NnLRx7e2Tnu7ph33Ow4HKIs46tbIqwmDJrcK9cuVIOXPxo3759zJ8/P0YSxY6T9XVHnVfviTy7aKzobtRm1Nc+Evm5v1sDjQe0Gf5Q9LmhuwE+9ZQWsxhr3L3wk9matWO1R35+n0t7Dz7zPMxYPfbyncQIIbZKKVeGOu6kiVkoFKPC2QnvPwTZc0OnrUYDYYJTPz+yc9f/AHY+Gvq4pGwoXTuye4TCkgCX/FyLO4wUez4UnzFmIikiQykLhSIc9j0Hnl648MdQvCrW0kTGjDO1R6xZfLX2UExKVMxCoQiHXX+HtOlQdGqsJVEoYoJSFgpFKDrrtYyixdeMvqhMoZikKGWhUIRiz1NaRlGZyu9XnLwoZaFQhGL3RshfAtlzYi2JQhEzlLKIIs3NzSxdupSlS5eSl5dHQUGB77nLFX4v/g0bNlBXF0ZRlWLsaToENduVVaE46VHZUFEknBbl4bBhwwaWL19OXl7eWIs4NZESqraAu3v01yp/GhCw6MrRX0uhmMQoZREj/vKXv/Dggw/icrk444wzeOCBB/B6vdx4443s2LEDKSW33HILubm57Nixg49//OMkJCSEvWjSSc3xd+DPF4/d9WaeCyn5Y3c9hWIScvIoixfvGn3Xy4HklcGF90d82p49e3j66ad59913iYuL45ZbbuHxxx9n5syZNDU1sXu3JmdbWxtpaWn8+te/5oEHHmDp0qVjK/9UpWa79vdT/xib1hXZ80Z/DYViknPyKIsJxKuvvsoHH3zAypVahX1vby9FRUWsX7+eAwcOcPvtt3PRRRdx/vmqYdqIqC/Xqn1Hsv60QqEIysmjLEZgAUQLKSU33XQT3/3udwft27VrFy+++CK/+tWveOqpp3j44YdjIOEkp74ccidWS3qFYrKjsqFiwHnnncfGjRtpamoCtKypyspKGhsbkVJy9dVXc++997Jt2zYA7HY7nZ2dsRR58tDn0RbayVkQ+liFQhE2J49lMYEoKyvjO9/5Dueddx5erxeLxcJDDz2E2Wzms5/9LFJKhBD86Ec/AuDGG2/kc5/7nApwh0PzYa1DaW4Mmv0pFFMY1aJ8CnKyvm5Aq7Z+8ia49Z3YdIdVKCYZ4bYoV24oxdSivhxMcZClqq0VirFEKQvF1KK+XFMUccpVp1CMJVNeWUwVN1u4nGyvdxD15Sq4rVBEgSmtLGw2G83NzSfNACqlpLm5GZvNFmtRYoOjHdqrVNqsQhEFpnQ2VGFhIdXV1TQ2NsZalHHDZrNRWFgYazFiQ/1e7a/KhFIoxpwprSwsFgslJSWxFkMxXtTv0f7mKjeUQjHWTGk3lOIko2Ev2FIhpSDWkigUUw6lLBRTh/pyyFmolj5VKKJAVJWFEOICIcQBIcRhIcRdQfb/XAixQ38cFEK0+e27QQhxSH/cEE05FVMAKbWYhQpuKxRRIWoxCyGEGXgQWAdUAx8IIZ6VUu41jpFSfsXv+C8Cy/T/M4DvACsBCWzVz22NlryKGCEleJyjv057Fbg6lbJQKKJENAPcpwKHpZQVAEKIx4HLgL1DHH8dmoIAWA+8IqVs0c99BbgAeCyK8ipiwZM36qvRjREqE0qhiArRVBYFQJXf82pgVbADhRDTgRLg9WHOHRS1FELcAtwCUFxcPHqJFeOLlHDkP1B0GsxZP/rrJaRBwYrRX0ehUAwimsoiWJRxqOq4a4EnpZR9kZwrpXwYeBi0RoIjEVIRQzpqwNEGZVfBqTfHWhqFQjEM0QxwVwNFfs8LgZohjr2WQBdTJOcqJisNRhGdijMoFBOdaCqLD4DZQogSIUQ8mkJ4duBBQoi5QDrwnt/ml4DzhRDpQoh04Hx9m2IqYRTRqV5OCsWEJ2puKCmlRwhxG9ogbwY2SCnLhRD3AR9KKQ3FcR3wuPRr4CSlbBFCfBdN4QDcZwS7FVOI+nJIKdRiDQqFYkIT1XYfUsoXgBcGbPv2gOf3DHHuBmBD1IRTxB5VF6FQTBpUBbciNnhc0HRAKQuFYpKglIUiNjQdBK9HKQuFYpKglIUiNqhMKIViUqGUhSI21O8Bczxkzoq1JAqFIgyUslDEhvq9kDUXzJZYS6JQKMJAKQtFbKgvVy4ohWISoZSFYvzpaYHOGqUsFIpJhFIWivHHF9xWldsKxWRBKQvF+FNfrv1V7cQVikmDUhaK8ae+HBIzITk31pIoFIowiWq7D4XO8Xdh+9/gow+AaYLo5z1Pwbu/js29m49A/hK1VrZCMYlQymI82PV32PEILLkOSs6KtTTaokNv3A/OTsgrG//7J2XDcrWsukIxmVDKYjwwfPS7/j4xlEXtTq3dxiU/h5U3xVoahUIxCZggPpEpjNerFaAB7H0W3I7YygOw+wkwWWDB5bGWRKFQTBKUsog2bcfB3a0NzM52OPRybOXx9sHuJ2H2+ZCYEVtZFArFpEEpi2hjuKBO+29IytFcUbHk6JvQVQeLr46tHAqFYlKhlEW0adgLCMhbBGVXaZZFb2vs5Nn9BMTbYc4FsZNBoVBMOpSyiDb1eyCjBOKToOxq6HNpsYtY4O7V7r3gMrAkxEYGhUIxKVHZUNHGv2HetGWQOVtLoy08ZWTXM5m1tt4mc3jHO7ugrVL7/9hb4OpULiiFQhExSllEE1cPtFTAoqu050LAko/D69+D354+8uuuuw/OvD28Yx+7VlMSBvZpMGMCpO8qFIpJhVIW0aRxP0hvYHfV02+D7PnakqIj4e3/he2PwBlfCl0B3XpMUxTLPg2zztO25SwI3ypRKBQKHaUsokmwpUMtCTD/kpFfs6cZnr8D6nZpLTOGY/cT2t81X4e04pHfU6FQnPSoAHc0qS8HSyKkl4zdNRdeoRXU7do4/HFSwq4noPh0pSgUCsWoUcoimtTvgZz5Y9s8MDEDZq/TGgF6+4Y+rm4XNB2AxdeM3b0VCsVJi1IW0ULK6C0dWnY1dNYGBq4HsmujaumhUCjGDKUsokVXgxZfyImCsph7oVZYt+uJ4Pt9LT3WqZYeCoViTFDKIlrU79H+RsOysCTAgo/Cvme1QruBHHtLa+lRpuopFArF2KCyocaS6g9hzz+0/6OpLEBTBDsegWf+S6ud8KfyPc3ymHthdO6tUChOOpSyGEte+BrU7YY4vZXGjLOi5wYqORsKVsChV4PvP/VzqqWHQqEYM5SyGCuaDkHNdjj/+3DGbdG/n8kMN78e/fsoFAoFKmYxduzaCAhYdGWsJVEoFIoxRymLsUBK2L0RStdASn6spVEoFIoxRymLsaD6A60PU5kqgFMoFFMTpSzGgl0bIc4G8y+NtSQKhUIRFZSyGC19bij/h5amakuJtTQKhUIRFZSyGC1HXtcqtZULSqFQTGGUshgtuzZCQnr/ehEKhUIxBVHKYjQ4O2H/81qzvrj4WEujUCgUUSOkshBC3CaESB/JxYUQFwghDgghDgsh7hrimGuEEHuFEOVCiEf9tvcJIXboj2dHcv+os/958PTC4o/HWhKFQqGIKuFUcOcBHwghtgEbgJeklDLUSUIIM/AgsA6o1q/xrJRyr98xs4H/Ac6UUrYKIXL8LtErpVwawWsZf3ZthNRiKFo1brfcXNHMwoJUkq2q+F6hUIwfIS0LKeXdwGzgj8BngENCiB8IIWaGOPVU4LCUskJK6QIeBy4bcMzNwINSylb9Xg0Ryh87uhqg4j+w+OqxXdxoGDodbq77/fv85d1j43I/hUKhMAhrlNMtiTr94QHSgSeFED8e5rQCoMrvebW+zZ85wBwhxDtCiPeFEBf47bMJIT7UtwddwUcIcYt+zIeNjY3hvJSxY89TIL3jmgVV3+HAK+FQfee43VOhUCggDDeUEOJLwA1AE/AH4E4ppVsIYQIOAV8f6tQg2wa6r+LQrJZzgELgLSHEIillG1AspawRQpQCrwshdkspjwRcTMqHgYcBVq5cGdI1Nqbs2gh5ZZAzb9xu2dDhBKCiqXvc7qlQKBQQnmWRBXxMSrleSvmElNINIKX0ApcMc141UOT3vBCoCXLMP6WUbinlUeAAmvJASlmj/60A3gCWhSHr+NB8BGq2jXttRX2nA4CKxm7CCBspFArFmBGOsngBaDGeCCHsQohVAFLKfcOc9wEwWwhRIoSIB64FBmY1PQOs1a+bheaWqhBCpAshrH7bzwT2MlEwOsyWXTWutzUsiy6nh8ZO57jeWxEe7xxu4rvPTZyvqkIxVoSjLH4LdPk979a3DYuU0gPcBrwE7AM2SinLhRD3CSE+qh/2EtAshNgL/AfNxdUMzAc+FELs1Lff759FFVOMDrMlZ0HKtNDHjyENfgriSKNyRU00Wrpd3P74dv749lGcnr5Yi3PS0NylJk7jQTj5l8I/VVZK6RVChJW3KaV8Ac0y8d/2bb//JXCH/vA/5l2gLJx7jDsntkJLBay+I/SxY0x9h4PEeDM9rj4qmro4fWbmuMugGJp7/1VOU5cLgLYeN7kp5hhLNPV561Aj12/YwitfOZtZOfZYizOlCceyqBBCfEkIYdEftwMV0RZswrJrI5itsOCjoY8dYxo6nSycloLNYqJigGXx9w8q+fBYyxBnKqLNK3vr+eeOGsoKUgFo7XGN6npSSh78z2GqWnrGQrwxoa3Hxf0v7qdpAs3kn952AinhaNPEeZ9Gg5SS3206wuGGiZfxGI6yuBU4AziBFpBeBdwSTaEmLH1uLWV27gVgSx332zd2OslNsVGSlUxFY79nsNfVx93P7OGXrx0aN1lUgL2f9h43/+/p3czPT+HrF8wFNJfUaKhu7eUnLx3gb5uPj4WIo6a9x82n/7iFhzYd4ZW99bEWBwCnp49X9mmyTBVXVFVLLz98cT8PbZp48/FwivIapJTXSilzpJS5UspPTKriubGk4g3oaYpZe4/6Dgc5dhul2UkB6bPbKltx90m2Hm/F3eeNuhxHm7qZ/+1/s+dEe9TvNRn4/VsVNHe7+MlVi8m2WwHNDTUaDItie2XbqOUbLe29bq7fsJkDdZ3EmUTARCWWvHu4mU6HB4DmUSrnicL7Fc0AbDrYOOEmZOH0hrIJIb4ghPiNEGKD8RgP4SYcuzaCLQ1mrYvotLp2B8/vqh3VrbucHnpcfeSmWJmZlURVS48viLpZ/4L1uPrYPQ4D+PbKVhxuL+8eaYr6vcaLf++pG7HLp7q1h8L0BBYVpJKRqDWUHK1lUdWqybKrum1cJgBD0evq4/oNW9hb28FvPrmcmdnJg1ygseL53bXYbXEkWMwTyjUWDl6v5G/vH6fL6QnY/v5R7bfc2Olkb21HLEQbknDcUH9F6w+1HtiEVi8x8Rxq0cbZBfufg4WRd5h9dEslX3h0Gx2Okc82Gzq0GoucFCul2cl4JVQ2awPK+0dbKM5IBGBzRfTjFsZgsfvExPoyj5Qup4f/fmQrG945OqLzOxwe7DYt5yNNVxZto4xZVOqKy+H2cqAudj+3f+2sYWdVGz//+FLOW5A7yKqNFS6Pl5fL61i3IJecFCvNXZPLsthe1cbdz+zhr+8Fuhk3V7SwcrrWt3XTwXHuShGCcJTFLCnlt4BuKeVfgIuZqJlK0eTAC+DuGZELyvCnjiZYWa/XWBhuKNDSZx3uPnZUtbF+YS6zc5J9Zmw0OaoPFuVjYMX8v6d389WNO2Nqcu+qasMr8WUyRUpHr5sUmwWA+DgTSfFmWrpH54aqbOklKV7Lptpe2Tqqa42GF/bUUpiewMVl+QCUZidR2dKDyxM7awfgvYpmOhweLlqUT2ZSPM3dk8uyMALYL+7p9zhUtfRwoq2XS5dMY35+CpsOTD5lYXzr24QQi4BUYEbUJJqo7NoIqUVQdFrEpxr+69Eoiwa9ejs3xUpJlqYsKpq62FHVhsvjZVVJJqtKM/jwWAueKLstjug+64qmbjpHYS0BvHmokae2VfPszoHF/ePH9iotLjDSIGmHo19ZAKQnxY+JZbG0OI1su5VtMYpbtPe4eedwExeV5SOE1r2nNCuZPq/0WT6x4oVdtSRb41g9O4vM5JFbFluPt3CirXfQ9gN1nVG16A7Wa7+hXdXtvnFh81HNK7CqNINz5maz9XjrqH9fY0k4yuJhfT2Lu9EqsPcCP4qqVBMNrxcq34M5F4yow6zhv65qGfylDBejYjvbbsNus5Bjt1LR2M37Fc0IAaeUZLCqJJNuVx/lNdFzD3m9kmPN3czKSQYY1b28Xkldu6YE73m2PGZV6duOazP3kQ44Hb0eUhL6S4/SE+NpGaWyqG7poTgjkWVFaTGzLF7ZV4+7T3KRblUAPqs2lkFud5+Xl/bWcd78HGwWM1nJ8SOyCh3uPj79xy3c+KctAUWUDZ0Orvnde1z24Nu8dyQ6lvqhhi5fMoRhXWyuaCY90cKcHDtr5mTj8UreORx9T0G4DDvy6c0CO6SUrVLKN6WUpXpW1O/GSb6JQdtxcHVpjQNHgJFzP5rZWEOnE2uciRTdN16anURFYxebK1pYkJ9CaoKFVaUZAFF1RdW09+Jwe7lsiVa9PpqMqKYuJ+4+yQ2nT6fb2cc9z5aPlZhhI6XstyxG6MroDGJZtI4iG6rL6aG520VRRiLLp6dzrLln1AHzkfDi7lqmpdpYUtifJl6arU0SYhm3eO9IM209bi7UlVhmkpWWbideb2SuzA+OtdDj6uNgfRcPvn4Y0L4P33pmD73uPqalJXDTnz/wJZCMhGNN3Vz38Pu0Dvj8Dtd3snpWFmUFqTy/uw7QgtunlmRgMglWTE8n2Ro3oeIWwyoLvVngbeMky8SlQe80krtwRKePhbKo73CQk2LtdwdkJ3OooYttla2sKtEquXPsNkqzknzmbLh0Oz2+OEQojOD2yhkZ5KfaRqUsDPN/zdxsbj9vNs/vruXF3aPLGouUyhZtIM62W2npdtEX4YDj6fPS7erD7q8sEi2DBodIMNwShmUBsKNqfK2LDoebtw41caGfCwogNcFCVnJ8TC2LjR9WkZpgYc2cbAAyk+PxSmjrjUxBbzrQSHyciYvL8vnNG0cor2nn+d21vFRezx3r5vD3W05nWpqNG//8AR+MsOD1tf0NvFfRzDt+mYOdDjc17Q5m5SRzYVkeO6va+PBYC1Utvb7fssVs4sxZmbzpl0J7sL4zJpMGg3B8Kq8IIb4mhCgSQmQYj6hLNpGoLwcEZEfejlxK6Ztljipm0eEk127zPS/NSqLT4cHp8fosCoBVpZl8cLQlokHv4TcruPTXb4d1jjFIzMxOYuG01FGl6ta0aS6o/NQEPn92KfPy7Pxan+GNF0Ydw3nzc7QBJ0L3kZHnP9ANNZoK7ko/ZVFWmIrZJNh2fHzjFq/tq8fV5w1wQRmUZsUufbal28XL5fVcsawAm0VLAMhM1tyQxN9DAAAgAElEQVQ5kcacNh1sZFVJBt+/YhFpifF8deNOvvPPcpYUpvK51SVk2608dvNp5NitfP3JXSOSd7+e/upfL2P0dZudk8xFi7T3995/aRNS/9/ymjk5nGjr5Z87arjpzx9w/s/f5PoNm2OWSh2OsrgJ+ALwJrBVf3wYTaEmHPV7IH0GWJMjPrXX3YfL4yXebKK6tTdiU9mgoVOzLAxm6u4AIWBVSf8X7LTSDDqdHvZFkKNd0dRNl9PjC6KHOjbZGke23UpZQSoVTd10D8gVD5ca3bKYlpZAnNnEmjnZHG7sGhSgf+dwE/e/uH9E9wjFtspWEuPNnFaqzegiLe4y0qED3FCJ8XQ6PCP+URuTiqL0RBLj45iXZ2f7OFsWL+yuIy/F5rNs/Blt+qyUkj+8VcFf34+8Ov0f26px9Xm57tRi37asJC1d2T9u4fT0cecTO33p5QM50dbLoYYu1szJJi0xnu9dvoj9dZ10ONz8+KolxJm1oTEnxcaNZ5ZwtKmbYyN4zfv1IPk2v7iTsXjZ7Fw7M7KSWJCfwu4T7aQmWJifl+I7bs1czXL68t93sPV4K1etKGTPiQ4efjM21d3hVHCXBHmUjodwE4b6vSN2QRlm4/x8O64+r29Nikhp6HCS429Z6IHGubl2X24/4DNjI4lb1OqDtjHTH46Kxm5Ks5MQQrCoIAUpGXHxUE17L8nWOF8cZlZOMi6Pd5C77tEtlTy06UjQrJXRsr2yjSWFab73NtLiro5ew7LoVxYZSdr/I63irmrpwW6NIy1Ru87y4nR2VrVH7CIbKZ0ON5sONnLBojxMpsFrmJVmJ9HS7RrSCmvtdg2ZWiul5Ef/PsD3nt/H/S/sw+EOvzuvlJLHtlSyvDiNuXn9TQN9loVfzGl/bSdPbK3m5b11Qa9lpKWeow/IFyzK46vr5vDjqxYHXNv/mEjjB54+LwfrOzEJKD/R4QuiH27oIj7O5KuNuqgsD4BTZmQEvN8FaQn81zkz+eq6Obz9jbX89OolXFyWzy9fPRST1TLDqeC+PthjPISbELh6oOUI5C4a0enGgLG4UJuhDTXTGY5eVx+dTk+AZVGYnojdGsfqWVkBx+al2ijKSIioTUSNT1mEHowrGrso1VN3jaZ5u6tH5oqqaetlWprN5xOfk6v9SA81BPrDDVN+rPPOe1197KvtYPn0NLKSNYUbaUZUv2XR74YylPdIXVGVLT0UZST63pdlxWl0OT0cbhifOMG7R5pxebxcsCgv6P7SLM2qDdYmv9vp4SM/e4NfBelTJqXkJy8d4KFNRzhlRjrdrj7ejGAA/uBYK0cau7nWz6oALWYBgZ+dMeEYyvW76WADBWkJPgsd4IvnzuaKZYWDjp2emcSMzETeOBBZl6NjzT04PV4+Mi8XV5+XvXrm4MH6TmZmJ2PWFYOWmgyrZw3uIv2NC+bxxXNn+2Ji9162kGRbHHc+uWvcJg8G4bihTvF7nAXcA4x/y9VY0bhfW2s7d8GITjcsi8V6Ron/rLmh08H9L+4fNLvqdnr44Qv7fD5Ywz3kb1mYTYJnv7iar6ybM+ie+SkJYc+QPX1e6vTq8FDKosfloabd4cuIyUmxkWO3sqdGUxa9rj7+95WDVLeGpxBr2hxMS0vwPZ+pp+P6D4oOd58v+B7pjzUUe2ra8Xgly4rSR+z3NvLg/QPcGbpbZKRB7ko9bdZgWbFW0Xv3M7u5/fHtfPnx7aPK0AmF4W5ZMC0l6H7Dqg2WFPHcrhpae9xBW8H85o0j/OaNI1x3ahGPfO400hItvLgn+Mw/GI9vqcRujeOSxYFxlPTEeIQI/OyMdilVrYO/0y6Pl3cON7NmbnZA8H44zpmbw3sVzRFZQvvrNOXwyVWacjPqZQ41dDE7p19JlWYn8+LtZ/GJVdNDXjMr2co9H13Ijqo2/jTCjgMjJRw31Bf9HjejLW8aWb+LyYwvE2pkloUxu1xUkIpJBH55/7HtBA9tOsLfBvhu//zuMX73ZgWPbakE/Ku3rQHHlWQlkWQdvLRIWqKF9jAzQ+o7nRgTlFDKwhgcjMHCeF17TrTjcPfxuf/7gF+9dog/vBXel7imrZf81H5lkWyNoyAtIcDEPlTfhVdqr92Y8fozmgJEo75iaXEaaQkWTGIEMYvewQFuw300EsvC65VUtfZSnNmvLGZkJvKReTk0djrZWdXGK3vr+d7zwy1SOToqW3pIS7QExGH8KcpIHLKh4GNbqgDYU9MRULvg9Ur++PZR1s7N5vuXlxEfZ+L8Bbm8urc+rIWi2nvcPL+7lsuWTSMxPvA7bzYJMhLjafL77AyLIlgG4rbKVrqcHl82VTismZONw+0dNitq4Ex/f20nZpPgjFmZFKQlsL2ylR6Xh+rW3gBlATAvL4X4uPBquC5dnM/SojSeG2W/uUiJvMIMetDXyT4pqC8HS6IW4B4Bxuwyx24lPzUhwCw2ZocPbarwzVi6nR7+8JYWwHpBz7/ur97utyyGIy3REra/3F9B1LQPH7MwMmAMNwRoyuJwQxc3/fkD3j3SzLRUW1iuBYe7j+ZuFwVpga9pVk5ygBvKmJ3dtLqELqeHrcf7A4VPbq3mlO+/ysER+m+3V7YxPTORrGQrJpMgI8kacXGXzw2VEMSyGEHMorHLicvjpSi9X4kKIdjwmVN44861vHHnWu5cP5fdJ9qj1vW3qrWXovTEIfdbzCaKMxMHZUTtq+1gR1Ubp87IwOXpd7uANptu6XZxYVm+zy9/YVk+nU4Pbx8K3ZDypfI6nB4v155SHHR/ZnJ8gGXh74YamFSy6WAjcSbBGREsHnZaaSbxcSbeCOIK9Xol33x6N6f/8LWAiuv9dR3MzE7CGmdmaXEa2yvbONKgZ0LlRp4sYyCEYHGh9rsbzzY54cQs/iWEeFZ/PAccAP4ZfdEmCPV7tJRZ08hWPTMGjNQEC0UZCb4vsafPywfHWlmQn0JTl5NHN2tWxF/fP05rj5tLFuezt7aDY03dvrW3B1oWQ5GWGE9bb3iDnqEsCtMTwrYsjHYjoMUtvFLr1fOTq5Zw89mlVDR1h4zN+GdC+TM7J5nDDV2+Wdr+uk5sFhPXnVpMnEn4goxOTx8/e/kArT1u7nxyV8QWRluPi62VrQHZPlkDBhzQXF/DVfF29LoRApLjA1NnYWSdZ43vR1HG0IP1FcsKscaZePyDyoivHw5VA9xgwSjNSqaiKdCyeHxLJfFmE/ddriWD+MfNNuvdVE8v7R+gz5yZRYotzjcpGlam1h5MAubnB3eNZSZZB8UshACnx0vjoM+0kZUz0gNch6FIiDezqiRjUJDb65X8v2f28OjmSho6nby+v99Vuq+2k3l6dtOyojROtPX66i1Gu6rf7Fw7XU4PtSEmeGNJOJbFT4Gf6Y8fAmdLKe+KqlQTBSk1y2KEmVCguSJSEyzEmbXsB2Mw2FvbQZfTw63nzGRVSQYPbTpCa7eL379Zwdlzsvmfi+YDWiO3+k4H8WaTz70RitQECw63Nyz/qpEBtXJ6ekhlUdHYRUFaAgnx/YpzxfR0pmcm8qMrF3PVikKfab/p4PDxBeNLPkhZ5Cbj9Hh9cY/9dR3MzbWTmmBh5Yx034/1ya3V1LY7uO7UYnZWtfHHt8NzfbX3uPnflw+w+kf/oanLyQWL+v3fmcnxg9xQ9zxbzvUbNvPqEAv+dDg82K1xAVksNouZBIt5RP2hDCU73GCdmmjh4rJ8/rm9hh7XyNKWh6LPK6lu7RlWWYFWZ3Osucen1B3uPp7efoILFuUxLy+Faak2X2U8aN1Up6XaKPSzmOLjTKxbkMcre+tCNiZs6HCSlWz1BYUH4v/Zefq81LQ5WKjHXPyt+U6Hm321HZwxMyvodYZjzZxsDjd0+b6bUkq+/eweHttSyX+dM5O8FJtvKYIOh5sTbb3My9eUghF32vhhFRazYEbm8O9vKAw31sBkkGgSjrKoBDZLKTdJKd8BmoUQM6Iq1UShqwF6mkccrwDNskjXB/nijEQaO530uvp8rcRPK8ng9nNn09Dp5FN/3Exzt4vbz51FQVoCS4rSeHF3HY0dTrLt1rCDcYZSGRi3+NVrh/jy49sDttW09ZKaYGF2rp3WHvewg09FU3dAvAI0l8umO9dyzcoiQLM6ijMSQ6YZGmmw01IHKgs9I6peM7H9Z2dr5uSwr7aD6tYefvOfIywrTuMHVyzi/AW5/OyVg74Gh/5UtfSw7L6XmfXNF5j1zRdY+t2X+dXrhzl7Thb/vv3sgIwfbXbaPwt193mpau3FK+G/HtnK6/sHK4wOhzvoDDU90RLghtp6vJUz73+d/335AO3DuKeMGXFBesKQxwBce2oxnU7PkH7r+1/czxce3TbsNYJR1+HA3SdDWxbZSbg8Xk7oMbgXdtfS4fBw7ana92BZcbovJiSlZPPRZlaVZg76Dl9UlkeHw8M7R5r48FgLn/7jZm7YsGXQ/Rq7nL5eSsHISrb6kjpq2x30eSVn6pmC/nELozngwiGC98NxztwcQHNj7ahq4/oNW/jb+5V8fk0pX18/lwsW5fHGwUa6nB7ffYy6iUUFKcSbteWQS7OSfXUcI8WnLMYxhTYciZ8A/NV+n75t6tOg9yoaYSYUaDGLdN2HbczWqlt7eL+imZKsJHJSbJw+M5NTZqRTXtPB6llZrJiuFdldXJbH7hPtbKtsDUibDUVagrGmQuCg9H5FMy/uqQsIxGnpqwkU6DP8oWotpJT6Fz0p6H4DIQRr5mTz7pHmYQOXNW29CAG5qYGva5bfjKmxy0lLt4v5+uzMsFru+PtOTrT1cvu5sxFC8L3LF5FgMfP1IOmEj2yupMPh4eazS/n8mlK+uHYWL95+Fr/55IpB+fSa37vfGjjR2kufV/LNi+YzLy+FW/+6bVA8RmsiGERZJMUHZEO9daiRE229/Or1w6z+8es88PqhoP7mqpYe8lJsWOOGd3ueMiOdmdlJPL4luCvqXztreH5XbcTptr6CwIzhlVWJHrf649sV/Pmdo/z+raPMyEz0uZmWFWtul4YOB0cau2jqcnFa6eDGD6tnZ2G3xnHH33dw1UPv8dahJt461DjIrdjYObyyyEyK1zsa9PmUw+mlmQgRqCz26YP4vCHcWcMxMzuJgrQE7n9xP5c/+A57TrTz7UsWcNcF8xBCcFFZPi6Pl9f3N/jSvQ3Lwhpn9mWXzRpFvMIgM9lKRlL8uKVTQ3jKIk5K6fvW6/+fHNlQ9bqyyBmdG8rwYRvK4mhTN1uOtfgqr4UQ3LFuLtY4E19Z1587cKHuIjnW3BN2vAL6LYuBbpCWbhdOj5djzf2ByZp2B9NSbeSnaoHm2vbgrqjGTiddTo8vbXY41szJpsfVx4fHhq46rmnrJTvZOmhQTLFZyEuxcaihk/21gT/s+fl2cuxWthxrYUlhqk955KTY+NYlC9h6vJXn/XpLufu8PLm1mrVzc/jGBfO4c/087jh/7pB+76xkK51Oj899Z7xPiwtT+dtnV1GQnsAvXj0YcI7WnnxwRtrAlh+HGrqYnpnIi7efxakzMvjpywd5L0j6a1UYLiDQvjPXnlLMtsq2Qa20GzocPsvt7xHGNfxbjQzH3Dw7ydY4/vLece7511721XbwmTNm+NWGaG6X7VVtvK9b0UbBqD/WODNXLC9ACME3L5rH3RfPD7q2SGOnk+zkYZSFvq+l2+VTeLNykslLsQUoi/21HdhtcUxLDS9ZxB8hBB9dOg2zSXDn+rm89Y2PcNPqEt9rXjE9nWy7lRd317KvrpPUBO27bLCsWIuPDcyEGikDk0GiTTjKolEI4aurEEJcBkyd9TSHo74c7PmQFH7WxEBau/uVhfEDfGVvPZ0Oj6/FBMDpMzMpv3e9z6oATbkYhW/+NRahSE0wUjcDLQvDp2sMwtBvWUzzWRbBlYXRinygGyoYp8/MJN5sGtYVNbDGwp/Zuckcqu/yZULN0y0Aw2oB+JJuVRh8bFkBs3OS+fVrh3zZL6/tq6epy8knVhWFlBm02Sn0B6aNeoPpmYmkJlpYXpzua6lu0NHrHtqy8Hv/D9drufXz81P46dVLAG0tg4EMrLEYjitXFBJvNvH3D6oCthuxguKMRJ7cWh1WaqpBVYsWSB7qszFITbDw4d3nsf1b69j+rXXs/Pb5fObMEt/+hdNSsJgF2ypbeb+imdwUK9OH8NPf+9GFbL37PG45eyYzMrXvl1H7A1oQuSmEG8q/MK+ypYc4kyA/NYGi9MSAmMX+uk7m56WE7dIdyNfXz2X7t9bxhbWzSLYOTuG9cFEe/znQwLbjrczLswfcx1Cgs0cZ3DaYk5vMwfrOccuICkdZ3Ap8UwhRKYSoBL4BfD66Yk0Q6sshZ+QuKAiMWWQmxZMYb/bNflcNMMuD+TGNRm65kbihfDGL/tmZlNLnFjEG4S6nh/ZeN9PSEshLtSEEnAjihnJ6+vjBC/vIT7WxXP/CD0eSNY5TStKHLaKrae/1ub4GMkvPiNpb00F+qi2gncnn15Ry5/q5fGReTsA5JpPgi+fO5lBDl6/Q69EtVeSn2lgzJ/DYoegvzNOVRXMPSfFm34w2N8VKQ2dgK+xOhydoPYIWs+gPuFY0dfkyYNKT4ilISxiU+upw91Hf4QxbWWQkxXPW7CxeGxBL2VbZisUs+NYlC2jtcfNyefDgfDCqWnqYlpaAJQyfus1iJj0pnvSkeFIHJF/YLGYWTEtl+/E2Nh9t4bQg8QoDIYRvX54+46/3UxZtvW48XhkiZmH0h3JS2aKtiW42CYoyEn3ryEgpOVDX6XMNjQR/WYNx4aJ8HG6vppQGWLDnzc/htrWzfO1DRsvsHDudDg8N47QOTDhFeUeklKcBC4CFUsozpJTj2xo0FnQ3awV505aO+BIOdx+97j5fzEIIQVF6Ij2uPoozEgMK0obi4rJ84s0mny8/HPrXge6f2Xb0evDog9w+3bKo9aWv2rCYTeTabUEti1+/dphDDV388GNlQYsAg7FmTjYH67uCXk9KqRfkBbeWZufY6XX3selgo8+qMJiVY+cLa2cF/cFeXJbPzOwkfvXaIapaenjrUCNXrywaMoNmIMbstEnvMXS8uZvpmUm+e+XYrXi8MsC91OFwBxTkGaQnxtPe66bPKznW3IO7Twa4HxYVpAxSFkaAfqgZeDDWzM3meHNPQDX19so2Fk5L5dx5ORSkJUSUYlvZ0jNsjUUkLCtK48PjLTR2OoO6oIJhxOb8lUX/wl/DxSz6FX1VS78rrzgjkboOBw53H9WtvXQ5Pb6EiWhwakmGz0Id+N1NjI/ja+vnhv0bCkV/kHt8XFHh1Fn8QAiRJqXsklJ2CiHShRDfGw/hYkr5P8DrgYUfG/EljEEl3W9mbHyJ/TvFDkdxZiKbv3ku6xcG79MTjKR4M3EmEdDf32iyZjELn2VxYkCtQ36abVDMYs+Jdn676QhXrSj0ZYOEgzGbf23f4Flta48bh9s7pKtjjh4AbO1xRxSINJsEX/zIbA7Ud3Kbngn08VPCc0EBZCUFWhbHm3uYkdU/cObo/mdjJuf1SrqcniGzoaTUMtKM9Zb9C7HKClI51tzjK+oD2KKvQ7JiemjrzeAc/X3epFtxnj4vu6rbWFachskk+PgpRbxzuJnjzd2097r5xasH+d5ze4e8XmVLb9iWTSiWFaf5ugMMtKKHIivJSpxJBLj7fMpi2JiF7obqdmpFhYayyNS+Y9Wtvb4OsKOxLEJhNgnW6xl2IwmiR4IRKD/UMD4ZUeG4oS6UUvoSpqWUrcBF0RNpgrD7Cc0FlTfytFnD9210IYX+uIV/vCIU6UnxEflYhRCDqrgNWZYVp1Pd2kuHwz2o1mFaWkJANpTL4+VrT+wkMymeb10cmTtuTm4ySwpT+cWrhwYVpw1VkGfgb0UNnJ2F4tIl0yjNSmJndTtr5mQP6eoKRr/f24mnz0tVaw/TM/tjNLkDZr2dTg9SEjzA7Rf/MGZ+s3ICK99B60ZqsLmihcL0BAojmNkXZyZSkpXkiw/tr+vE4fb6/OPXrCzCJOArf9/BWT96nV+8eog/vH10UOwFtN5fTV3OgFYjo8FwWWbbrSGz6AxMJkGO3eprcQPQ2KX3Rhumg0GyNY74OJNvVUHjd2ZYSVUtPb4Mpbm50VMWAJ9dXcK1pxSxIMrKIjvZSlqiZdyC3OEoC7MQwqfShRAJQPgO9MlIy1Go2gxlV4/qMsZg7e9zn5OrdZs8LYJWAyMhLTE+IGZhBLfP1IuRDtZ1UtPWi0lArm7eF6QlcKKt1xcw+8e2avbXdfK9yxcN8kmHQgjBj65aTIfDzb3/Clwu1bBohhrI0xLjfS6HoTKXhsJsEnzx3FkAfOLU4K0hhiIx3ozNYqK520VNm1Zv4F88ZSQZGJZFR+/gVh8G6T5XoItDDV0UpicE9DQylIXhivJ69VqEMN01/qyZk+1rcmes121Upuel2jhvfi7bKttYVZrJT65aDPRXVPtTrddMhJONFQ6F6QlMS7WxelZWRJOdnBRbxG4oIQRZSfHsqOwP7vv/rWrtYX9dJ9MzE8fMDTQUM7OTuf/KxWH3ehopQghm5ySPW61FOO/a34DXhBB/0p/fCPwleiJNAHY/qf0dpbLotyz6lcWVKwpZOSMjohnvSEhLCG5ZnDkrk5+/quWbn2jrJS/F5gusT0u14fJ4ae52kZVs5bldtZRkJbFuQe6IZJiXl8Jta2fz81cPcsniab7r1PjFSoZidk4y7T3ugNYi4XL50gJm59gjLrwSQpCZpBV3GWmz/paFMVgZg1ewhY8MMvwsi4P1nYPSJbOSrdqytHrH3kMNXbT2uMN21/izZm42f373GFuOtrC9so1suzWgUvonVy/hri4npdnJ9Hkl9z23l/crWrhsaUHAdcKpHo8EIQQbbz09orYaAHkpNg77FVg2dDhJsJhJih++9iQz2epbW8WwKLLtVqxxJiqbe9hX1xGwuNBUYFaOnRd21yKlHHGGV7iEE+D+MfA9YD5akPvfQOheupMVKWH3Rph+JqSF9nf3eSX1HQ7fwz9N0ahz8G/TYYkwWD1ShnJDLSpIJcUWx/7aDi3I7Ke0jP9r2xy0dLt4r6KZi8ryRvUl/K9zZjIvz87/e3q3r3K5tt2BNc4UoEQHcuXyQj59+vSwsnIGoi3MlDoiubP0wrzjzYP7YNksZlJscf1uqCBLqhoYn3lTl4uKpm5fZbo/iwr6l6U1ZvqnjcCyOK1Ea3K36WAj26vaWFaUNmjdbKM+xmwSnDIjI6hl4etLFaJ6PBIK0xN9qdzhkpc6wLLoCq+DQWZyvK8o01B4QgiKMxI5UN/JsabuqMYrYsHsnGTae90RN8AcCeHaY3VoVdzXAEeBp6ImUayp3QFNB+G0/w55aFuPi+s3bAnIly8rSOVfX1wN9Nc5+Ae4x4vUhHhf1hNoQdukeDM2i5l5+Snsr+ukqcvpW5QJ+t1CJ9p6Ka/RVma7cNHgNZgjIT7OxE+vXsJlD77DFb99hy+fN8eXnjncj//KFYVcOao7j4zMZCsNnQ6ONfdgs5gGFUPmpth8jR19bqhhLItd1W24PN6gE4RF01J5dV89XU4P71doHXtDVU4HI0FfFvb5XbXUdTh8rVeGYlVJBq/vb6ChwxEQB6hs0VKFh1Pi40FOipVOh4cel4fE+LiQ1dsGRkZUii0uwG1anJHIW4ea8EqimgkVC2b7BbnDeY9Gw5DTNiHEHCHEt4UQ+4AHgCpASCnXSikfiKpUsWTXE2COh4WXD3tYe4+bT/9xC/trO7nrwnn84IoyLlmcz+4T7b56hpZuF3Zr3Ihmx6NFsyz6Zxst3U4y9ADu/Dw7+2s7qG1zBLiC/AvzXthTx/TMxBH10BnIooJU/nD9SuJMgi89tp0X99QN64KKJZlJ/ZbFDL+0WYOcFKuvZXyHYVkEURYJFjPxcSa26OsfBKvaLSvUlqUtP9HOlqMtQXsnhcuaOdm+QjajUngojOSKzUcD12YwGghG250RCqPq2QjCh6reNjBqLQYG6IsyEnHp7UPmTzHLwlhdcjzafgw3iu0HzgUulVKullL+Gq0v1NRFStjzFMw+HxKGTl9s73Vz/YbN7K/r4HefXsGta2byiVXFfFJf6WqHXkHb1tPfF2q8SUuw0O3q83XzbO52kaHPvOblp2j7+rwBsZP0RAs2i4m9tR28e7iJCxflj9nAsXZeDv++/Wwe+MQyFhem+lI+JxpZdq3V9dGm7qD1Djl2my9Tpz/APdhAF0JbkMdY82EoNxTAP3fW0NTlCjudOhhGoZfZJHyrMg7FwmkpJFvjBrmiIqkejybGui3G+xyqiaCBkc02sE7ECNgnxpvHrIZkopBjt2K3xY1LrcVwyuJKNPfTf4QQvxdCnAvEdsoRbRxt0FUH088Y9rCvPbGTvbUd/PaTK1jrV0m8pEhbDc/ISGnxq94eb3z9ofSMqOYuV9BiIf+ur0IIpqUl8K+dNXi80reQ/FhhMgkuWTyNZ29bzc1nl47ptceKzKR4XH1ejjZ1+1pP+JOTYqWx04mU0hfgHtj2wcD4DKal2oIek2PXlqV9ams1EFk69UBKs5IoTE9gXp590EpyA4kzm1gxPd3Xswm0Qsmqlt4xy4QaDf3KQosBtvW4w+qNZrihBio84/ncPHtAK/mpgJERNdIFwCJhSGUhpXxaSvlxYB7wBvAVIFcI8VshxPlRlywWdOm9jJKGnvV2OT38Z38DnzljBucNyBJKjI9jXl6KrzdPLC2LVD1OYgSVW7pdPl/0nFw7hsGQP8AdNC01AafHS2F6gq8v1clElu7u8EqYESQTK8duw9Xnpb3XTUevh2Rr3JDtpo33e9Ywef1lBak4Pd5heyeFgxCCX167lO9fURbW8aeVZnK4ocvX1rupy0Wvu29CWBZGy4+6DoevQDIiy2IIZTHV4hUGn1g1nSuWFYQ+cJSEkw3VLaV8REp5CVAI7ACm5jz4g9AAABH/SURBVOJH3Xovo+She7e8e7gJj1cGWBT+LCtOY0dlG16vpMWvieB4k5ZgWBZupNRkMSyLJGsc0/Uf0MAUXiOWcFHZ2LmgJhPGgAPB224YM9z6DiedDjf2IAV5BsZnP1yXUcMVtapk5PEKgxXTM1haNHy8wsBI0TWqxsPtNjseJFvjSIo3U9/hCKvGwmB2rh27NW5QzGZ6ZiK5KVZWz4p8waPJwFUrCrk2wpqikRBR5FVK2SKl/J2U8iPREiimdBuWxdDK4o2DjSTFm1k5Pbh/eVlxOp1OD4cbu2jrccdOWfjalLvpcnpw9XkDslzm5aWQGG8elNZoBLmNBoYnG4YrAwjqhsr1tfxw6O3Jh3YzpuuV++Eoi9G4oEZCWUEqifFmNlc009Tl5JH3jwOh17EYL3L19NlIlEVBWgK7713PwmmBFrHNYmbzN8/j4sUn53d6rIhuKeNkI4QbSkrJpgONnDEra8jqzOX6rGbz0Ra6nJ7YxSwS+iuIgxUH/vfamaxbkDtoNnvl8kISLGaWhAiSTlWMjJr4OFPAWgQGhmXR0OHUFz4Kw7IYZrGbs2Zn8aVzZ3PpkvEdyCx63OKZHTVs/FBrY/7JVcXMDGO9kvEgL8VGXbvDt352tNNCFaGJak6nEOICIcQBIcRhIURQ15UQ4hohxF4hRLkQ4lG/7TcIIQ7pjxuiKaeP7gYQJkgMbjUcaezmRFuvb02FYJRkJZGaYOE/+sLtMcuGSupfWtVo9ZHll364uDCNK1cUDjqvKCORz6+ZeVK6oKD/85qekRg0GOrrihqGZVGanUSyNS5oJpSBzWLmjnVzIq5yHgs+Mi+HDoeb9QtzeeWONXz/irIJ87nnpmhZZ4Zl4W/xKWJD1CwLIYQZeBBYB1QDHwghnpVS7vU7ZjbwP8CZUspWIUSOvj0D+A6wEpDAVv3coZdeGwu6GiAxC0zB2woYzdqGUxZCCJYVp/HOYW19qFi5oezWOMwmQVuPm5auwZaFIjgWs4m0REtAmw9/EuPjsFvjNMvC4fbluQfjsiUFnDs/d1iFEktuOH0GH1tWGHHfr/EgN8VGQ6fWFSE90RL1PkuK0ETzEzgVOCylrNCXYn0cuGzAMTcDDxpKQEpprJazHnhFj5G0Aq8AF0RRVo3uRkgeOhPqjQMNzMxOCpleuLw4Hade35CeFJsfohCC1AQLbb3B3VCKoblt7Sw+ddrQAcNsPX220+EZNsBtMokJqyhAk28iKgqAvBQr7j5tsSLlgpoYRFNZFKBVfRtU69v8mQPMEUK8I4R4XwhxQQTnjj1dDUMGt3tdfWw+2hLWmg7+2RixsixAy4hq7el3Q/ln+iiG5nNnlQ77OefYrdR1OLQlVSewMpjMGIkEe2s7IlpSWBE9oqksgjk/By4WGwfMBs4BrgP+IIRIC/NchBC3CCE+FEJ82Ng49HrPYdPdOKSyeP9oMy6Pd1gXlMGSojRfHUMslUVqooX2Hjct3U5sFlPIYi1FeOTYbRxr6sYrg1dvK0ZPrl5r0ePqU5bFBCGayqIa8O9oVgjUBDnmn1JKt5TyKHAATXmEcy5SyoellCullCuzs8dgXdth3FCbDjRis5g4NYyWDCk2C7P0rJK0GJr5abobqrnbpQKEY0huitVnrSnLIjr4Z6IpZTExiKay+ACYLYQoEULEA9cCzw445hlgLYAQIgvNLVUBvAScry/hmg6cr2+LHs4ucPcMaVm8daiR00ozsVmG76lvsHJGBqkJlrCPjwZpifFagNuvelsxevzdIsEWPlKMHq0luf5/GE0EFdEnaja0lNIjhLgNbZA3AxuklOVCiPuAD6WUz9KvFPaiNSm8U0rZDCCE+C6awgG4T0rZMvguY4ivenuwZdHa7eJIYzdXrQh/PeevnT+HT66KflXlcKQmGG4opSzGEiN9Fhg2wK0YORazybcQlbIsJgZR/aZLKV8AXhiw7dt+/0vgDv0x8NwNwIZoyhfAMAV5RhfZUK2f/clMtpIZ4xlRWqKFTqeHhg7nuCy4dLIQYFkoN1TUyE1RymIioZKXDYxWH0H6Qm2vbMUkCNn6eaJh9Ieq63D4+kIpRo+/ZaHcUNHDiFsoZTExUMrCQHdDvVsnfHUJBtur2vReSpPL5ZDml4mVoQLcY4Z/u+wU5YaKGkZGlIpZTAyUsjDQ3VA3PnGMn758wLfZ65XsqGyLyAU1UfDPxFKWxdiRbI0jMV5LXIhFm46ThWVFaZRmJ8U0o1DRj1IWBt0NeG3pOL1mXtpTh0dfhvFwYxedTg/Li4deOW+iEmhZKGUxVgghyLFbsVlMqg1FFLl6ZRGvf/WcCdOv6mRHfdMNuhroS9D63Td3u3xrJxur3k1Ky8LPn56hqrfHlBy7TQW3FScVSlkYdDfiSuhfHOWF3bUAbK9sIzXBQkmQVdMmOsoNFT3m5duDrqSnUExVlLIw6G7EGa9VZ6cnWvj3nnr6vJJtla0sK06blKaw3WbxFTYpN9TYcvfFC/i/m06NtRgKxbihlIVBVyM98dpqZZcvK6Cpy8l/9jdwqKFrUsYrAMx619N4s4lkq8raGUvi40wxrc5XKMYbpSwA3A5wttNt0SyLSxZPw2Yx8eOX9iPl5IxXGKQlWshMjp+UlpFCoZg4KGUBvoK8DrOmFHLsVs6Zk8PB+i6E0LrITlbSEizKBaVQKEaN8k2AryCv3aS5m5KscVy0OJ9/l9cxKzt5Ume9XLGsgL5Bzd0VCoUiMpSyAF9BXgtaO48kq5mPzMvBZjGxcsbkjFcYfObMkliLoFAopgBKWYDPDdVMKhazA2ucGWscPHnrGeSnqlW6FAqFQikL8LmhGrypJFk9vs2LCiZX40CFQqGIFirAzf9v7+5jJa/qO46/P1x2ebhoQVkJZXlSN/WhIuiGUG0agzZBIWCCBnyISjQkRgMabQX/sGnTJjUxikRiRMViYnwIVbs1xqct1RoVWQWpQE3JirKCspSC7kXv3Xv32z9+58L07swdd72zs8y8X8nkzu/Mb++cw7nMZ845vwe6aaj1T+Dh3TPMPs4uFihJB4JhAd3I4qgN7Jpf9HwESerDsADYdT/MPoW5hUVmD/NEK0laybCAboH7qA3sml9i1pGFJO3FsIAuLGY3MOc0lCT1ZVgsLcIjD3bTUPOLjiwkqQ/D4pEHgHKBW5JWYVjMboDLb6OefWEbWbjALUkr+TX6kBk45mTmdy+xp3AaSpL6cGTR7Jrvztx2GkqS9mZYNHMtLDyDW5L2Zlg0yyMLp6EkaW+GRTM3vwQ4DSVJ/RgWzaPTUB4NJUl7MSwaF7glaTDDoplzzUKSBjIsGhe4JWkww6JZXuCeXe+ahSStZFg0cwuLHL7uEA6d8T+JJK3kJ2PjRQQlaTDDovHy5JI0mGHRzM0veqkPSRrAsGichpKkwQyLZm5+ybO3JWkAw6JxzUKSBhtpWCQ5J8lPktyV5Io+r78hyc4kt7bHm3peW+op3zLKeoLTUJK0mpF9OiaZAa4B/hLYAdycZEtV3bFi189W1Vv7/IrfVtXpo6rfSo4sJGmwUY4szgTuqqrtVbUAfAa4YITvt9/27CnmFpYMC0kaYJRhcQJwT8/2jla20oVJbktyQ5ITe8oPT7ItyfeSvLzfGyS5tO2zbefOnftd0Ud2L9/LwgVuSepnlGGRPmW1YvtfgVOq6jTgG8D1Pa+dVFWbgVcDVyV52l6/rOraqtpcVZs3bNiw3xX1irOStLpRhsUOoHeksBG4t3eHqvqfqppvmx8Fnt/z2r3t53bg34EzRlVR72UhSasbZVjcDGxKcmqS9cDFwP87qinJ8T2b5wN3tvJjkhzWnh8LvBBYuTC+Zh4dWXgGtyT1NbJPx6paTPJW4KvADHBdVd2e5O+AbVW1BbgsyfnAIvAg8Ib2z58JfCTJHrpA+8c+R1GtGe9lIUmrG+mnY1V9GfjyirL39Dy/Eriyz7/7DvCcUdat1/K9LJyGkqT+PIOb3gVuj4aSpH4MC1zglqRhDAseG1kcaVhIUl+GBT1hsc5pKEnqx7AAds0vMbt+hkMO6XceoSTJsMCLCErSMIYFsGvBy5NL0moMCxxZSNIwhgXLYeHitiQNYljQncHtNJQkDWZYAHMLTkNJ0moMC1yzkKRhDAu6y304DSVJg019WCwu7eF3u/d4LwtJWsXUh8XcQnd5co+GkqTBpj4sKDj3tOPZdNwTxl0TSTpoTf3cyx8duY5rXv28cVdDkg5qjiwkSUMZFpKkoQwLSdJQhoUkaSjDQpI0lGEhSRrKsJAkDWVYSJKGSlWNuw5rIslO4Gd/wK84FnhgjarzeDGNbYbpbPc0thmms9372uaTq2rDsJ0mJiz+UEm2VdXmcdfjQJrGNsN0tnsa2wzT2e5RtdlpKEnSUIaFJGkow+Ix1467AmMwjW2G6Wz3NLYZprPdI2mzaxaSpKEcWUiShjIsJElDTX1YJDknyU+S3JXkinHXZ1SSnJjkxiR3Jrk9yeWt/ElJvp7kv9vPY8Zd17WWZCbJLUm+1LZPTXJTa/Nnk6wfdx3XWpKjk9yQ5L9an//ZpPd1kre3v+0fJ/l0ksMnsa+TXJfk/iQ/7inr27fpXN0+325Lst93epvqsEgyA1wDvBR4FvCqJM8ab61GZhF4R1U9EzgLeEtr6xXA1qraBGxt25PmcuDOnu33Ah9obf5f4I1jqdVofRD4SlU9A3guXfsntq+TnABcBmyuqj8FZoCLmcy+/ifgnBVlg/r2pcCm9rgU+PD+vulUhwVwJnBXVW2vqgXgM8AFY67TSFTVfVX1w/b8N3QfHifQtff6ttv1wMvHU8PRSLIROBf4WNsOcDZwQ9tlEtv8ROAvgI8DVNVCVT3EhPc13W2ij0hyKHAkcB8T2NdV9S3gwRXFg/r2AuCT1fkecHSS4/fnfac9LE4A7unZ3tHKJlqSU4AzgJuA46rqPugCBXjK+Go2ElcBfw3sadtPBh6qqsW2PYl9/lRgJ/CJNv32sSSzTHBfV9UvgPcBP6cLiYeBHzD5fb1sUN+u2WfctIdF+pRN9LHESY4C/hl4W1X9etz1GaUk5wH3V9UPeov77DppfX4o8Dzgw1V1BjDHBE059dPm6C8ATgX+GJilm4JZadL6epg1+3uf9rDYAZzYs70RuHdMdRm5JOvoguJTVfX5Vvyr5WFp+3n/uOo3Ai8Ezk9yN90U49l0I42j21QFTGaf7wB2VNVNbfsGuvCY5L5+CfDTqtpZVbuBzwMvYPL7etmgvl2zz7hpD4ubgU3tiIn1dAtiW8Zcp5Foc/UfB+6sqvf3vLQFeH17/nrgXw503Ualqq6sqo1VdQpd3/5bVb0GuBF4RdttotoMUFW/BO5J8iet6MXAHUxwX9NNP52V5Mj2t77c5onu6x6D+nYL8Lp2VNRZwMPL01X7aurP4E7yMrpvmzPAdVX1D2Ou0kgk+XPgP4D/5LH5+3fTrVt8DjiJ7n+4V1bVysWzx70kLwLeWVXnJXkq3UjjScAtwGuran6c9VtrSU6nW9RfD2wHLqH7cjixfZ3kb4GL6I78uwV4E938/ET1dZJPAy+iuxT5r4C/Ab5In75twfkhuqOnHgEuqapt+/W+0x4WkqThpn0aSpL0ezAsJElDGRaSpKEMC0nSUIaFJGkow0LaB0mWktza81izM6OTnNJ7JVHpYHLo8F0k9fhtVZ0+7kpIB5ojC2kNJLk7yXuTfL89nt7KT06ytd1LYGuSk1r5cUm+kORH7fGC9qtmkny03Zfha0mOGFujpB6GhbRvjlgxDXVRz2u/rqoz6c6YvaqVfYjuEtGnAZ8Crm7lVwPfrKrn0l236fZWvgm4pqqeDTwEXDji9ki/F8/glvZBkl1VdVSf8ruBs6tqe7tg4y+r6slJHgCOr6rdrfy+qjo2yU5gY++lJ9ql47/ebmBDkncB66rq70ffMml1jiyktVMDng/ap5/e6xYt4bqiDhKGhbR2Lur5+d32/Dt0V7wFeA3w7fZ8K/BmePQe4U88UJWU9offWqR9c0SSW3u2v1JVy4fPHpbkJrovYa9qZZcB1yX5K7q7113Syi8Hrk3yRroRxJvp7vAmHZRcs5DWQFuz2FxVD4y7LtIoOA0lSRrKkYUkaShHFpKkoQwLSdJQhoUkaSjDQpI0lGEhSRrq/wCxsRRt5Y1rIAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = []\n",
    "val_acc = []\n",
    "for history in history_list:\n",
    "    acc.append(history.history['accuracy'])\n",
    "    val_acc.append(history.history['val_accuracy'])\n",
    "acc = np.array(acc)\n",
    "val_acc = np.array(val_acc)\n",
    "avg_acc = np.mean(acc, axis=0)\n",
    "avg_val_acc = np.mean(val_acc, axis=0)\n",
    "print(avg_val_acc)\n",
    "\n",
    "plt.plot(avg_acc)\n",
    "plt.plot(avg_val_acc)\n",
    "plt.title('RNN Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import CuDNNLSTM\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "\n",
    "n_samples = X_train.shape[0]  # number of data points\n",
    "n_features = X_train.shape[1]  # dimension of feature vector for each sample\n",
    "time_steps = X_train.shape[2] # how many samples across time were taken\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(50, dropout=0.2, recurrent_dropout=0.2, return_sequences=True, kernel_initializer='random_normal', input_shape=(n_features, time_steps)))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=(2), strides=2, padding='valid', data_format=None))\n",
    "\n",
    "model.add(LSTM(40, return_sequences=True))\n",
    "\n",
    "model.add(LSTM(30, return_sequences=False))\n",
    "\n",
    "model.add(Dense(2, activation='softmax', kernel_regularizer=regularizers.l1_l2(l1=0,l2=0.5)))\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "Adam=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, decay=0.99, amsgrad=False)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=100, epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Ajihnp6auW2"
   },
   "source": [
    "Get val and test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "LIU-beqBPHhb",
    "outputId": "aab5739b-1c58-4457-bd29-583a5dc983b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 53ms/step\n",
      "26/26 [==============================] - 1s 43ms/step\n",
      "Validation [loss, accuracy] is  [2.668516440825029, 0.6818181872367859]\n",
      "Test [loss, accuracy] is  [2.6850311022538405, 0.5769230723381042]\n"
     ]
    }
   ],
   "source": [
    "score_val = model.evaluate(X_val, y_val, batch_size=20)\n",
    "score_test = model.evaluate(X_test, y_test, batch_size=20)\n",
    "\n",
    "print('Validation [loss, accuracy] is ', score_val)\n",
    "print('Test [loss, accuracy] is ', score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN on MFCC raw data did pretty much nothing,v but CNN on statistics of raw data was able to classify (standard deviation and mean)\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('RNN Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ECE114_Speech_ML_project_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
